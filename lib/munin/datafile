version v20220328-1368-g35c15e92c6
onmne-jobs-01;onmne-jobs-01:munin_stats.graph_title Munin processing time
onmne-jobs-01;onmne-jobs-01:munin_stats.graph_info This graph shows the run time of the four different processes making up a munin-master run.  Munin-master is run from cron every 5 minutes and we want each of the programmes in munin-master to complete before the next instance starts.  Especially munin-update and munin-graph are time consuming and their run time bears watching. If munin-update uses too long time to run please see the munin-update graph to determine which host is slowing it down.  If munin-graph is running too slow you need to get clever (email the munin-users mailing list) unless you can buy a faster computer with better disks to run munin on.
onmne-jobs-01;onmne-jobs-01:munin_stats.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:munin_stats.graph_scale yes
onmne-jobs-01;onmne-jobs-01:munin_stats.graph_vlabel seconds
onmne-jobs-01;onmne-jobs-01:munin_stats.graph_category munin
onmne-jobs-01;onmne-jobs-01:munin_stats.graph_order update graph html limits
onmne-jobs-01;onmne-jobs-01:munin_stats.graph.critical 285
onmne-jobs-01;onmne-jobs-01:munin_stats.graph.draw AREASTACK
onmne-jobs-01;onmne-jobs-01:munin_stats.graph.update_rate 300
onmne-jobs-01;onmne-jobs-01:munin_stats.graph.warning 240
onmne-jobs-01;onmne-jobs-01:munin_stats.graph.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:munin_stats.graph.label munin graph
onmne-jobs-01;onmne-jobs-01:munin_stats.update.update_rate 300
onmne-jobs-01;onmne-jobs-01:munin_stats.update.warning 240
onmne-jobs-01;onmne-jobs-01:munin_stats.update.draw AREASTACK
onmne-jobs-01;onmne-jobs-01:munin_stats.update.critical 285
onmne-jobs-01;onmne-jobs-01:munin_stats.update.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:munin_stats.update.label munin update
onmne-jobs-01;onmne-jobs-01:munin_stats.html.label munin html
onmne-jobs-01;onmne-jobs-01:munin_stats.html.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:munin_stats.html.draw AREASTACK
onmne-jobs-01;onmne-jobs-01:munin_stats.html.update_rate 300
onmne-jobs-01;onmne-jobs-01:munin_stats.limits.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:munin_stats.limits.label munin limits
onmne-jobs-01;onmne-jobs-01:munin_stats.limits.update_rate 300
onmne-jobs-01;onmne-jobs-01:munin_stats.limits.draw AREASTACK
onmne-jobs-01;onmne-jobs-01:proc_pri.graph_title Processes priority
onmne-jobs-01;onmne-jobs-01:proc_pri.graph_order low high locked high low locked
onmne-jobs-01;onmne-jobs-01:proc_pri.graph_category processes
onmne-jobs-01;onmne-jobs-01:proc_pri.graph_info This graph shows number of processes at each priority
onmne-jobs-01;onmne-jobs-01:proc_pri.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:proc_pri.graph_vlabel Number of processes
onmne-jobs-01;onmne-jobs-01:proc_pri.high.label high priority
onmne-jobs-01;onmne-jobs-01:proc_pri.high.info The number of high-priority processes (tasks)
onmne-jobs-01;onmne-jobs-01:proc_pri.high.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:proc_pri.high.draw STACK
onmne-jobs-01;onmne-jobs-01:proc_pri.high.update_rate 300
onmne-jobs-01;onmne-jobs-01:proc_pri.low.update_rate 300
onmne-jobs-01;onmne-jobs-01:proc_pri.low.draw AREA
onmne-jobs-01;onmne-jobs-01:proc_pri.low.label low priority
onmne-jobs-01;onmne-jobs-01:proc_pri.low.info The number of low-priority processes (tasks)
onmne-jobs-01;onmne-jobs-01:proc_pri.low.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:proc_pri.locked.label locked in memory
onmne-jobs-01;onmne-jobs-01:proc_pri.locked.info The number of processes that have pages locked into memory (for real-time and custom IO)
onmne-jobs-01;onmne-jobs-01:proc_pri.locked.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:proc_pri.locked.update_rate 300
onmne-jobs-01;onmne-jobs-01:proc_pri.locked.draw STACK
onmne-jobs-01;onmne-jobs-01:uptime.graph_title Uptime
onmne-jobs-01;onmne-jobs-01:uptime.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:uptime.graph_scale no
onmne-jobs-01;onmne-jobs-01:uptime.graph_vlabel uptime in days
onmne-jobs-01;onmne-jobs-01:uptime.graph_category system
onmne-jobs-01;onmne-jobs-01:uptime.graph_order uptime
onmne-jobs-01;onmne-jobs-01:uptime.uptime.update_rate 300
onmne-jobs-01;onmne-jobs-01:uptime.uptime.draw AREA
onmne-jobs-01;onmne-jobs-01:uptime.uptime.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:uptime.uptime.label uptime
onmne-jobs-01;onmne-jobs-01:users.graph_title Logged in users
onmne-jobs-01;onmne-jobs-01:users.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:users.graph_vlabel Users
onmne-jobs-01;onmne-jobs-01:users.graph_scale no
onmne-jobs-01;onmne-jobs-01:users.graph_category system
onmne-jobs-01;onmne-jobs-01:users.graph_printf %3.0lf
onmne-jobs-01;onmne-jobs-01:users.graph_order tty pty pts X other
onmne-jobs-01;onmne-jobs-01:users.tty.label tty
onmne-jobs-01;onmne-jobs-01:users.tty.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:users.tty.draw AREASTACK
onmne-jobs-01;onmne-jobs-01:users.tty.update_rate 300
onmne-jobs-01;onmne-jobs-01:users.tty.colour 00FF00
onmne-jobs-01;onmne-jobs-01:users.X.colour 000000
onmne-jobs-01;onmne-jobs-01:users.X.update_rate 300
onmne-jobs-01;onmne-jobs-01:users.X.draw AREASTACK
onmne-jobs-01;onmne-jobs-01:users.X.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:users.X.label X displays
onmne-jobs-01;onmne-jobs-01:users.X.info Users logged in on an X display
onmne-jobs-01;onmne-jobs-01:users.pty.label pty
onmne-jobs-01;onmne-jobs-01:users.pty.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:users.pty.draw AREASTACK
onmne-jobs-01;onmne-jobs-01:users.pty.update_rate 300
onmne-jobs-01;onmne-jobs-01:users.pty.colour 0000FF
onmne-jobs-01;onmne-jobs-01:users.other.colour FF0000
onmne-jobs-01;onmne-jobs-01:users.other.update_rate 300
onmne-jobs-01;onmne-jobs-01:users.other.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:users.other.info Users logged in by indeterminate method
onmne-jobs-01;onmne-jobs-01:users.other.label Other users
onmne-jobs-01;onmne-jobs-01:users.pts.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:users.pts.label pts
onmne-jobs-01;onmne-jobs-01:users.pts.draw AREASTACK
onmne-jobs-01;onmne-jobs-01:users.pts.colour 00FFFF
onmne-jobs-01;onmne-jobs-01:users.pts.update_rate 300
onmne-jobs-01;onmne-jobs-01:threads.graph_title Number of threads
onmne-jobs-01;onmne-jobs-01:threads.graph_vlabel number of threads
onmne-jobs-01;onmne-jobs-01:threads.graph_category processes
onmne-jobs-01;onmne-jobs-01:threads.graph_info This graph shows the number of threads.
onmne-jobs-01;onmne-jobs-01:threads.graph_order threads
onmne-jobs-01;onmne-jobs-01:threads.threads.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:threads.threads.info The current number of threads.
onmne-jobs-01;onmne-jobs-01:threads.threads.label threads
onmne-jobs-01;onmne-jobs-01:threads.threads.update_rate 300
onmne-jobs-01;onmne-jobs-01:processes.graph_title Processes
onmne-jobs-01;onmne-jobs-01:processes.graph_info This graph shows the number of processes
onmne-jobs-01;onmne-jobs-01:processes.graph_category processes
onmne-jobs-01;onmne-jobs-01:processes.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:processes.graph_vlabel Number of processes
onmne-jobs-01;onmne-jobs-01:processes.graph_order sleeping stopped zombie dead paging uninterruptible runnable processes dead paging sleeping uninterruptible zombie stopped runnable processes
onmne-jobs-01;onmne-jobs-01:processes.stopped.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:processes.stopped.info The number of stopped or traced processes.
onmne-jobs-01;onmne-jobs-01:processes.stopped.label stopped
onmne-jobs-01;onmne-jobs-01:processes.stopped.colour cc0000
onmne-jobs-01;onmne-jobs-01:processes.stopped.update_rate 300
onmne-jobs-01;onmne-jobs-01:processes.stopped.draw STACK
onmne-jobs-01;onmne-jobs-01:processes.dead.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:processes.dead.label dead
onmne-jobs-01;onmne-jobs-01:processes.dead.info The number of dead processes.
onmne-jobs-01;onmne-jobs-01:processes.dead.colour ff0000
onmne-jobs-01;onmne-jobs-01:processes.dead.update_rate 300
onmne-jobs-01;onmne-jobs-01:processes.dead.draw STACK
onmne-jobs-01;onmne-jobs-01:processes.processes.draw LINE1
onmne-jobs-01;onmne-jobs-01:processes.processes.colour c0c0c0
onmne-jobs-01;onmne-jobs-01:processes.processes.update_rate 300
onmne-jobs-01;onmne-jobs-01:processes.processes.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:processes.processes.label total
onmne-jobs-01;onmne-jobs-01:processes.processes.info The total number of processes.
onmne-jobs-01;onmne-jobs-01:processes.sleeping.info The number of sleeping processes.
onmne-jobs-01;onmne-jobs-01:processes.sleeping.label sleeping
onmne-jobs-01;onmne-jobs-01:processes.sleeping.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:processes.sleeping.draw AREA
onmne-jobs-01;onmne-jobs-01:processes.sleeping.update_rate 300
onmne-jobs-01;onmne-jobs-01:processes.sleeping.colour 0022ff
onmne-jobs-01;onmne-jobs-01:processes.zombie.colour 990000
onmne-jobs-01;onmne-jobs-01:processes.zombie.update_rate 300
onmne-jobs-01;onmne-jobs-01:processes.zombie.draw STACK
onmne-jobs-01;onmne-jobs-01:processes.zombie.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:processes.zombie.info The number of defunct (zombie) processes (process terminated and parent not waiting).
onmne-jobs-01;onmne-jobs-01:processes.zombie.label zombie
onmne-jobs-01;onmne-jobs-01:processes.paging.update_rate 300
onmne-jobs-01;onmne-jobs-01:processes.paging.colour 00aaaa
onmne-jobs-01;onmne-jobs-01:processes.paging.draw STACK
onmne-jobs-01;onmne-jobs-01:processes.paging.info The number of paging processes (<2.6 kernels only).
onmne-jobs-01;onmne-jobs-01:processes.paging.label paging
onmne-jobs-01;onmne-jobs-01:processes.paging.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:processes.uninterruptible.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:processes.uninterruptible.label uninterruptible
onmne-jobs-01;onmne-jobs-01:processes.uninterruptible.info The number of uninterruptible processes (usually IO).
onmne-jobs-01;onmne-jobs-01:processes.uninterruptible.colour ffa500
onmne-jobs-01;onmne-jobs-01:processes.uninterruptible.update_rate 300
onmne-jobs-01;onmne-jobs-01:processes.uninterruptible.draw STACK
onmne-jobs-01;onmne-jobs-01:processes.runnable.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:processes.runnable.label runnable
onmne-jobs-01;onmne-jobs-01:processes.runnable.info The number of runnable processes (on the run queue).
onmne-jobs-01;onmne-jobs-01:processes.runnable.draw STACK
onmne-jobs-01;onmne-jobs-01:processes.runnable.colour 22ff22
onmne-jobs-01;onmne-jobs-01:processes.runnable.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_docker0.graph_order down up down up
onmne-jobs-01;onmne-jobs-01:if_docker0.graph_title docker0 traffic
onmne-jobs-01;onmne-jobs-01:if_docker0.graph_args --base 1000
onmne-jobs-01;onmne-jobs-01:if_docker0.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-jobs-01;onmne-jobs-01:if_docker0.graph_category network
onmne-jobs-01;onmne-jobs-01:if_docker0.graph_info This graph shows the traffic of the docker0 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-jobs-01;onmne-jobs-01:if_docker0.up.info Traffic of the docker0 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-jobs-01;onmne-jobs-01:if_docker0.up.label bps
onmne-jobs-01;onmne-jobs-01:if_docker0.up.cdef up,8,*
onmne-jobs-01;onmne-jobs-01:if_docker0.up.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_docker0.up.type DERIVE
onmne-jobs-01;onmne-jobs-01:if_docker0.up.min 0
onmne-jobs-01;onmne-jobs-01:if_docker0.up.negative down
onmne-jobs-01;onmne-jobs-01:if_docker0.up.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_docker0.down.graph no
onmne-jobs-01;onmne-jobs-01:if_docker0.down.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_docker0.down.min 0
onmne-jobs-01;onmne-jobs-01:if_docker0.down.type DERIVE
onmne-jobs-01;onmne-jobs-01:if_docker0.down.cdef down,8,*
onmne-jobs-01;onmne-jobs-01:if_docker0.down.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_docker0.down.label received
onmne-jobs-01;onmne-jobs-01:interrupts.graph_title Interrupts and context switches
onmne-jobs-01;onmne-jobs-01:interrupts.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:interrupts.graph_vlabel interrupts & ctx switches / ${graph_period}
onmne-jobs-01;onmne-jobs-01:interrupts.graph_category system
onmne-jobs-01;onmne-jobs-01:interrupts.graph_info This graph shows the number of interrupts and context switches on the system. These are typically high on a busy system.
onmne-jobs-01;onmne-jobs-01:interrupts.graph_order intr ctx
onmne-jobs-01;onmne-jobs-01:interrupts.intr.max 100000
onmne-jobs-01;onmne-jobs-01:interrupts.intr.update_rate 300
onmne-jobs-01;onmne-jobs-01:interrupts.intr.type DERIVE
onmne-jobs-01;onmne-jobs-01:interrupts.intr.min 0
onmne-jobs-01;onmne-jobs-01:interrupts.intr.info Interrupts are events that alter sequence of instructions executed by a processor. They can come from either hardware (exceptions, NMI, IRQ) or software.
onmne-jobs-01;onmne-jobs-01:interrupts.intr.label interrupts
onmne-jobs-01;onmne-jobs-01:interrupts.intr.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:interrupts.ctx.max 100000
onmne-jobs-01;onmne-jobs-01:interrupts.ctx.update_rate 300
onmne-jobs-01;onmne-jobs-01:interrupts.ctx.min 0
onmne-jobs-01;onmne-jobs-01:interrupts.ctx.type DERIVE
onmne-jobs-01;onmne-jobs-01:interrupts.ctx.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:interrupts.ctx.label context switches
onmne-jobs-01;onmne-jobs-01:interrupts.ctx.info A context switch occurs when a multitasking operatings system suspends the currently running process, and starts executing another.
onmne-jobs-01;onmne-jobs-01:df.graph_title Disk usage in percent
onmne-jobs-01;onmne-jobs-01:df.graph_args --upper-limit 100 -l 0
onmne-jobs-01;onmne-jobs-01:df.graph_vlabel %
onmne-jobs-01;onmne-jobs-01:df.graph_scale no
onmne-jobs-01;onmne-jobs-01:df.graph_category disk
onmne-jobs-01;onmne-jobs-01:df.graph_order overlay _dev _sys_fs_cgroup shm _dev_mapper_ubuntu_vL _rootfs_dev_shm _rootfs_run _rootfs_run_lock _dev_sda1
onmne-jobs-01;onmne-jobs-01:df.shm.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df.shm.label /dev/shm
onmne-jobs-01;onmne-jobs-01:df.shm.update_rate 300
onmne-jobs-01;onmne-jobs-01:df.shm.warning 92
onmne-jobs-01;onmne-jobs-01:df.shm.critical 98
onmne-jobs-01;onmne-jobs-01:df._rootfs_run_lock.label /rootfs/run/lock
onmne-jobs-01;onmne-jobs-01:df._rootfs_run_lock.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df._rootfs_run_lock.update_rate 300
onmne-jobs-01;onmne-jobs-01:df._rootfs_run_lock.warning 92
onmne-jobs-01;onmne-jobs-01:df._rootfs_run_lock.critical 98
onmne-jobs-01;onmne-jobs-01:df._sys_fs_cgroup.critical 98
onmne-jobs-01;onmne-jobs-01:df._sys_fs_cgroup.update_rate 300
onmne-jobs-01;onmne-jobs-01:df._sys_fs_cgroup.warning 92
onmne-jobs-01;onmne-jobs-01:df._sys_fs_cgroup.label /sys/fs/cgroup
onmne-jobs-01;onmne-jobs-01:df._sys_fs_cgroup.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df._dev.label /dev
onmne-jobs-01;onmne-jobs-01:df._dev.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df._dev.critical 98
onmne-jobs-01;onmne-jobs-01:df._dev.update_rate 300
onmne-jobs-01;onmne-jobs-01:df._dev.warning 92
onmne-jobs-01;onmne-jobs-01:df._rootfs_dev_shm.critical 98
onmne-jobs-01;onmne-jobs-01:df._rootfs_dev_shm.warning 92
onmne-jobs-01;onmne-jobs-01:df._rootfs_dev_shm.update_rate 300
onmne-jobs-01;onmne-jobs-01:df._rootfs_dev_shm.label /rootfs/dev/shm
onmne-jobs-01;onmne-jobs-01:df._rootfs_dev_shm.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df._rootfs_run.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df._rootfs_run.label /rootfs/run
onmne-jobs-01;onmne-jobs-01:df._rootfs_run.critical 98
onmne-jobs-01;onmne-jobs-01:df._rootfs_run.update_rate 300
onmne-jobs-01;onmne-jobs-01:df._rootfs_run.warning 92
onmne-jobs-01;onmne-jobs-01:df.overlay.critical 98
onmne-jobs-01;onmne-jobs-01:df.overlay.update_rate 300
onmne-jobs-01;onmne-jobs-01:df.overlay.warning 92
onmne-jobs-01;onmne-jobs-01:df.overlay.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df.overlay.label /
onmne-jobs-01;onmne-jobs-01:df._dev_sda1.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df._dev_sda1.label /rootfs/boot
onmne-jobs-01;onmne-jobs-01:df._dev_sda1.critical 98
onmne-jobs-01;onmne-jobs-01:df._dev_sda1.update_rate 300
onmne-jobs-01;onmne-jobs-01:df._dev_sda1.warning 92
onmne-jobs-01;onmne-jobs-01:df._dev_mapper_ubuntu_vL.label /rootfs
onmne-jobs-01;onmne-jobs-01:df._dev_mapper_ubuntu_vL.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df._dev_mapper_ubuntu_vL.critical 98
onmne-jobs-01;onmne-jobs-01:df._dev_mapper_ubuntu_vL.warning 92
onmne-jobs-01;onmne-jobs-01:df._dev_mapper_ubuntu_vL.update_rate 300
onmne-jobs-01;onmne-jobs-01:df_inode.graph_title Inode usage in percent
onmne-jobs-01;onmne-jobs-01:df_inode.graph_args --upper-limit 100 -l 0
onmne-jobs-01;onmne-jobs-01:df_inode.graph_vlabel %
onmne-jobs-01;onmne-jobs-01:df_inode.graph_scale no
onmne-jobs-01;onmne-jobs-01:df_inode.graph_category disk
onmne-jobs-01;onmne-jobs-01:df_inode.graph_order overlay _dev _sys_fs_cgroup shm _dev_mapper_ubuntu_vL _rootfs_dev _rootfs_dev_shm _rootfs_run _rootfs_run_lock _dev_sda1
onmne-jobs-01;onmne-jobs-01:df_inode._dev_sda1.label /rootfs/boot
onmne-jobs-01;onmne-jobs-01:df_inode._dev_sda1.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df_inode._dev_sda1.warning 92
onmne-jobs-01;onmne-jobs-01:df_inode._dev_sda1.update_rate 300
onmne-jobs-01;onmne-jobs-01:df_inode._dev_sda1.critical 98
onmne-jobs-01;onmne-jobs-01:df_inode.overlay.update_rate 300
onmne-jobs-01;onmne-jobs-01:df_inode.overlay.warning 92
onmne-jobs-01;onmne-jobs-01:df_inode.overlay.critical 98
onmne-jobs-01;onmne-jobs-01:df_inode.overlay.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df_inode.overlay.label /
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_dev.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_dev.label /rootfs/dev
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_dev.update_rate 300
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_dev.warning 92
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_dev.critical 98
onmne-jobs-01;onmne-jobs-01:df_inode._dev_mapper_ubuntu_vL.label /rootfs
onmne-jobs-01;onmne-jobs-01:df_inode._dev_mapper_ubuntu_vL.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df_inode._dev_mapper_ubuntu_vL.warning 92
onmne-jobs-01;onmne-jobs-01:df_inode._dev_mapper_ubuntu_vL.update_rate 300
onmne-jobs-01;onmne-jobs-01:df_inode._dev_mapper_ubuntu_vL.critical 98
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_dev_shm.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_dev_shm.label /rootfs/dev/shm
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_dev_shm.update_rate 300
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_dev_shm.warning 92
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_dev_shm.critical 98
onmne-jobs-01;onmne-jobs-01:df_inode._dev.label /dev
onmne-jobs-01;onmne-jobs-01:df_inode._dev.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df_inode._dev.critical 98
onmne-jobs-01;onmne-jobs-01:df_inode._dev.warning 92
onmne-jobs-01;onmne-jobs-01:df_inode._dev.update_rate 300
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_run.update_rate 300
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_run.warning 92
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_run.critical 98
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_run.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_run.label /rootfs/run
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_run_lock.critical 98
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_run_lock.warning 92
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_run_lock.update_rate 300
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_run_lock.label /rootfs/run/lock
onmne-jobs-01;onmne-jobs-01:df_inode._rootfs_run_lock.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df_inode._sys_fs_cgroup.warning 92
onmne-jobs-01;onmne-jobs-01:df_inode._sys_fs_cgroup.update_rate 300
onmne-jobs-01;onmne-jobs-01:df_inode._sys_fs_cgroup.critical 98
onmne-jobs-01;onmne-jobs-01:df_inode._sys_fs_cgroup.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df_inode._sys_fs_cgroup.label /sys/fs/cgroup
onmne-jobs-01;onmne-jobs-01:df_inode.shm.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:df_inode.shm.label /dev/shm
onmne-jobs-01;onmne-jobs-01:df_inode.shm.warning 92
onmne-jobs-01;onmne-jobs-01:df_inode.shm.update_rate 300
onmne-jobs-01;onmne-jobs-01:df_inode.shm.critical 98
onmne-jobs-01;onmne-jobs-01:open_inodes.graph_title Inode table usage
onmne-jobs-01;onmne-jobs-01:open_inodes.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:open_inodes.graph_vlabel number of open inodes
onmne-jobs-01;onmne-jobs-01:open_inodes.graph_category system
onmne-jobs-01;onmne-jobs-01:open_inodes.graph_info This graph monitors the Linux open inode table.
onmne-jobs-01;onmne-jobs-01:open_inodes.graph_order used max
onmne-jobs-01;onmne-jobs-01:open_inodes.used.label open inodes
onmne-jobs-01;onmne-jobs-01:open_inodes.used.info The number of currently open inodes.
onmne-jobs-01;onmne-jobs-01:open_inodes.used.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:open_inodes.used.update_rate 300
onmne-jobs-01;onmne-jobs-01:open_inodes.max.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:open_inodes.max.info The size of the system inode table. This is dynamically adjusted by the kernel.
onmne-jobs-01;onmne-jobs-01:open_inodes.max.label inode table size
onmne-jobs-01;onmne-jobs-01:open_inodes.max.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_docker0.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-jobs-01;onmne-jobs-01:if_err_docker0.graph_title docker0 errors
onmne-jobs-01;onmne-jobs-01:if_err_docker0.graph_args --base 1000
onmne-jobs-01;onmne-jobs-01:if_err_docker0.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-jobs-01;onmne-jobs-01:if_err_docker0.graph_category network
onmne-jobs-01;onmne-jobs-01:if_err_docker0.graph_info This graph shows the amount of errors, packet drops, and collisions on the docker0 network interface.
onmne-jobs-01;onmne-jobs-01:if_err_docker0.rxdrop.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_docker0.rxdrop.label drops
onmne-jobs-01;onmne-jobs-01:if_err_docker0.rxdrop.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_docker0.rxdrop.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_docker0.rxdrop.graph no
onmne-jobs-01;onmne-jobs-01:if_err_docker0.trans.negative rcvd
onmne-jobs-01;onmne-jobs-01:if_err_docker0.trans.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_docker0.trans.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_docker0.trans.label errors
onmne-jobs-01;onmne-jobs-01:if_err_docker0.trans.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_docker0.trans.warning 1
onmne-jobs-01;onmne-jobs-01:if_err_docker0.collisions.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_docker0.collisions.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_docker0.collisions.label collisions
onmne-jobs-01;onmne-jobs-01:if_err_docker0.collisions.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_docker0.txdrop.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_docker0.txdrop.negative rxdrop
onmne-jobs-01;onmne-jobs-01:if_err_docker0.txdrop.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_docker0.txdrop.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_docker0.txdrop.label drops
onmne-jobs-01;onmne-jobs-01:if_err_docker0.rcvd.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_docker0.rcvd.label errors
onmne-jobs-01;onmne-jobs-01:if_err_docker0.rcvd.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_docker0.rcvd.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_docker0.rcvd.warning 1
onmne-jobs-01;onmne-jobs-01:if_err_docker0.rcvd.graph no
onmne-jobs-01;onmne-jobs-01:swap.graph_title Swap in/out
onmne-jobs-01;onmne-jobs-01:swap.graph_args -l 0 --base 1000
onmne-jobs-01;onmne-jobs-01:swap.graph_vlabel pages per ${graph_period} in (-) / out (+)
onmne-jobs-01;onmne-jobs-01:swap.graph_category system
onmne-jobs-01;onmne-jobs-01:swap.graph_order swap_in swap_out
onmne-jobs-01;onmne-jobs-01:swap.swap_out.max 100000
onmne-jobs-01;onmne-jobs-01:swap.swap_out.update_rate 300
onmne-jobs-01;onmne-jobs-01:swap.swap_out.type DERIVE
onmne-jobs-01;onmne-jobs-01:swap.swap_out.negative swap_in
onmne-jobs-01;onmne-jobs-01:swap.swap_out.min 0
onmne-jobs-01;onmne-jobs-01:swap.swap_out.label swap
onmne-jobs-01;onmne-jobs-01:swap.swap_out.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:swap.swap_in.update_rate 300
onmne-jobs-01;onmne-jobs-01:swap.swap_in.max 100000
onmne-jobs-01;onmne-jobs-01:swap.swap_in.graph no
onmne-jobs-01;onmne-jobs-01:swap.swap_in.type DERIVE
onmne-jobs-01;onmne-jobs-01:swap.swap_in.min 0
onmne-jobs-01;onmne-jobs-01:swap.swap_in.label swap
onmne-jobs-01;onmne-jobs-01:swap.swap_in.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.graph_title br-fb545fb16b26 errors
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.graph_args --base 1000
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.graph_category network
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.graph_info This graph shows the amount of errors, packet drops, and collisions on the br-fb545fb16b26 network interface.
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.trans.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.trans.warning 1
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.trans.negative rcvd
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.trans.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.trans.label errors
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.trans.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.rxdrop.label drops
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.rxdrop.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.rxdrop.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.rxdrop.graph no
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.rxdrop.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.collisions.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.collisions.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.collisions.label collisions
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.collisions.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.txdrop.negative rxdrop
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.txdrop.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.txdrop.label drops
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.txdrop.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.txdrop.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.rcvd.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.rcvd.warning 1
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.rcvd.graph no
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.rcvd.label errors
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.rcvd.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_br_fb545fb16b26.rcvd.type COUNTER
onmne-jobs-01;onmne-jobs-01:open_files.graph_title File table usage
onmne-jobs-01;onmne-jobs-01:open_files.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:open_files.graph_vlabel number of open files
onmne-jobs-01;onmne-jobs-01:open_files.graph_category system
onmne-jobs-01;onmne-jobs-01:open_files.graph_info This graph monitors the Linux open files table.
onmne-jobs-01;onmne-jobs-01:open_files.graph_order used max
onmne-jobs-01;onmne-jobs-01:open_files.max.update_rate 300
onmne-jobs-01;onmne-jobs-01:open_files.max.info The maximum supported number of open files. Tune by modifying /proc/sys/fs/file-max.
onmne-jobs-01;onmne-jobs-01:open_files.max.label max open files
onmne-jobs-01;onmne-jobs-01:open_files.max.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:open_files.used.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:open_files.used.info The number of currently open files.
onmne-jobs-01;onmne-jobs-01:open_files.used.label open files
onmne-jobs-01;onmne-jobs-01:open_files.used.update_rate 300
onmne-jobs-01;onmne-jobs-01:open_files.used.warning 8485502273906394112
onmne-jobs-01;onmne-jobs-01:open_files.used.critical 9038904596117680128
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.graph_order down up down up
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.graph_title br-fb545fb16b26 traffic
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.graph_args --base 1000
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.graph_category network
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.graph_info This graph shows the traffic of the br-fb545fb16b26 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.up.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.up.type DERIVE
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.up.min 0
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.up.negative down
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.up.label bps
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.up.info Traffic of the br-fb545fb16b26 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.up.cdef up,8,*
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.up.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.down.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.down.graph no
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.down.label received
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.down.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.down.cdef down,8,*
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.down.min 0
onmne-jobs-01;onmne-jobs-01:if_br_fb545fb16b26.down.type DERIVE
onmne-jobs-01;onmne-jobs-01:forks.graph_title Fork rate
onmne-jobs-01;onmne-jobs-01:forks.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:forks.graph_vlabel forks / ${graph_period}
onmne-jobs-01;onmne-jobs-01:forks.graph_category processes
onmne-jobs-01;onmne-jobs-01:forks.graph_info This graph shows the number of forks (new processes started) per second.
onmne-jobs-01;onmne-jobs-01:forks.graph_order forks
onmne-jobs-01;onmne-jobs-01:forks.forks.min 0
onmne-jobs-01;onmne-jobs-01:forks.forks.type DERIVE
onmne-jobs-01;onmne-jobs-01:forks.forks.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:forks.forks.info The number of forks per second.
onmne-jobs-01;onmne-jobs-01:forks.forks.label forks
onmne-jobs-01;onmne-jobs-01:forks.forks.max 100000
onmne-jobs-01;onmne-jobs-01:forks.forks.update_rate 300
onmne-jobs-01;onmne-jobs-01:entropy.graph_title Available entropy
onmne-jobs-01;onmne-jobs-01:entropy.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:entropy.graph_vlabel entropy (bytes)
onmne-jobs-01;onmne-jobs-01:entropy.graph_scale no
onmne-jobs-01;onmne-jobs-01:entropy.graph_category system
onmne-jobs-01;onmne-jobs-01:entropy.graph_info This graph shows the amount of entropy available in the system.
onmne-jobs-01;onmne-jobs-01:entropy.graph_order entropy
onmne-jobs-01;onmne-jobs-01:entropy.entropy.update_rate 300
onmne-jobs-01;onmne-jobs-01:entropy.entropy.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:entropy.entropy.info The number of random bytes available. This is typically used by cryptographic applications.
onmne-jobs-01;onmne-jobs-01:entropy.entropy.label entropy
onmne-jobs-01;onmne-jobs-01:if_ens160.graph_order down up down up
onmne-jobs-01;onmne-jobs-01:if_ens160.graph_title ens160 traffic
onmne-jobs-01;onmne-jobs-01:if_ens160.graph_args --base 1000
onmne-jobs-01;onmne-jobs-01:if_ens160.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-jobs-01;onmne-jobs-01:if_ens160.graph_category network
onmne-jobs-01;onmne-jobs-01:if_ens160.graph_info This graph shows the traffic of the ens160 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-jobs-01;onmne-jobs-01:if_ens160.down.min 0
onmne-jobs-01;onmne-jobs-01:if_ens160.down.type DERIVE
onmne-jobs-01;onmne-jobs-01:if_ens160.down.cdef down,8,*
onmne-jobs-01;onmne-jobs-01:if_ens160.down.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_ens160.down.label received
onmne-jobs-01;onmne-jobs-01:if_ens160.down.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_ens160.down.graph no
onmne-jobs-01;onmne-jobs-01:if_ens160.down.max 10000000000
onmne-jobs-01;onmne-jobs-01:if_ens160.up.max 10000000000
onmne-jobs-01;onmne-jobs-01:if_ens160.up.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_ens160.up.negative down
onmne-jobs-01;onmne-jobs-01:if_ens160.up.type DERIVE
onmne-jobs-01;onmne-jobs-01:if_ens160.up.min 0
onmne-jobs-01;onmne-jobs-01:if_ens160.up.label bps
onmne-jobs-01;onmne-jobs-01:if_ens160.up.info Traffic of the ens160 interface. Maximum speed is 10000 Mb/s.
onmne-jobs-01;onmne-jobs-01:if_ens160.up.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_ens160.up.cdef up,8,*
onmne-jobs-01;onmne-jobs-01:load.graph_title Load average
onmne-jobs-01;onmne-jobs-01:load.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:load.graph_vlabel load
onmne-jobs-01;onmne-jobs-01:load.graph_scale no
onmne-jobs-01;onmne-jobs-01:load.graph_category system
onmne-jobs-01;onmne-jobs-01:load.graph_info The load average of the machine describes how many processes are in the run-queue (scheduled to run "immediately").
onmne-jobs-01;onmne-jobs-01:load.graph_order load
onmne-jobs-01;onmne-jobs-01:load.load.update_rate 300
onmne-jobs-01;onmne-jobs-01:load.load.info 5 minute load average
onmne-jobs-01;onmne-jobs-01:load.load.label load
onmne-jobs-01;onmne-jobs-01:load.load.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.graph_title Individual interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.graph_args --base 1000 --logarithmic
onmne-jobs-01;onmne-jobs-01:irqstats.graph_vlabel interrupts / ${graph_period}
onmne-jobs-01;onmne-jobs-01:irqstats.graph_category system
onmne-jobs-01;onmne-jobs-01:irqstats.graph_info Shows the number of different IRQs received by the kernel.  High disk or network traffic can cause a high number of interrupts (with good hardware and drivers this will be less so). Sudden high interrupt activity with no associated higher system activity is not normal.
onmne-jobs-01;onmne-jobs-01:irqstats.graph_order i0 i1 i8 i9 i12 i14 i15 i16 i17 i24 i25 i26 i27 i28 i29 i30 i31 i32 i33 i34 i35 i36 i37 i38 i39 i40 i41 i42 i43 i44 i45 i46 i47 i48 i49 i50 i51 i52 i53 i54 i55 i56 i57 i58 i59 i60 i61 i62 i63 iNMI iLOC iSPU iPMI iIWI iRTR iRES iCAL iTLB iTRM iTHR iDFR iMCE iMCP iERR iMIS iPIN iNPI iPIW i0 i1 i8 i9 i12 i14 i15 i16 i17 i24 i25 i26 i27 i28 i29 i30 i31 i32 i33 i34 i35 i36 i37 i38 i39 i40 i41 i42 i43 i44 i45 i46 i47 i48 i49 i50 i51 i52 i53 i54 i55 i56 i57 i58 i59 i60 i61 i62 i63 iNMI iLOC iSPU iPMI iIWI iRTR iRES iCAL iTLB iTRM iTHR iDFR iMCE iMCP iERR iMIS iPIN iNPI iPIW
onmne-jobs-01;onmne-jobs-01:irqstats.iMCE.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iMCE.label Machine check exceptions
onmne-jobs-01;onmne-jobs-01:irqstats.iMCE.info Interrupt MCE, for device(s): Machine check exceptions
onmne-jobs-01;onmne-jobs-01:irqstats.iMCE.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iMCE.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iMCE.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iTHR.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iTHR.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iTHR.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iTHR.label Threshold APIC interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iTHR.info Interrupt THR, for device(s): Threshold APIC interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iTHR.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i52.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i52.info Interrupt 52, for device(s): 401408-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i52.label 401408-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i52.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i52.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i52.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i32.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i32.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i32.info Interrupt 32, for device(s): 360448-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i32.label 360448-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i32.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i32.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i58.label 1572866-edge      ens160-rxtx-2
onmne-jobs-01;onmne-jobs-01:irqstats.i58.info Interrupt 58, for device(s): 1572866-edge      ens160-rxtx-2
onmne-jobs-01;onmne-jobs-01:irqstats.i58.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i58.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i58.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i58.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i38.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i38.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i38.label 372736-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i38.info Interrupt 38, for device(s): 372736-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i38.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i38.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i37.label 370688-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i37.info Interrupt 37, for device(s): 370688-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i37.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i37.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i37.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i37.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i57.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i57.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i57.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i57.label 1572865-edge      ens160-rxtx-1
onmne-jobs-01;onmne-jobs-01:irqstats.i57.info Interrupt 57, for device(s): 1572865-edge      ens160-rxtx-1
onmne-jobs-01;onmne-jobs-01:irqstats.i57.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i36.label 368640-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i36.info Interrupt 36, for device(s): 368640-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i36.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i36.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i36.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i36.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i56.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i56.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i56.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i56.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i56.label 1572864-edge      ens160-rxtx-0
onmne-jobs-01;onmne-jobs-01:irqstats.i56.info Interrupt 56, for device(s): 1572864-edge      ens160-rxtx-0
onmne-jobs-01;onmne-jobs-01:irqstats.i43.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i43.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i43.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i43.info Interrupt 43, for device(s): 382976-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i43.label 382976-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i43.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i16.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i16.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i16.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i16.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i16.info Interrupt 16, for device(s): 16-fasteoi   vmwgfx
onmne-jobs-01;onmne-jobs-01:irqstats.i16.label 16-fasteoi   vmwgfx
onmne-jobs-01;onmne-jobs-01:irqstats.i45.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i45.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i45.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i45.info Interrupt 45, for device(s): 387072-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i45.label 387072-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i45.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i12.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i12.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i12.info Interrupt 12, for device(s): 12-edge      i8042
onmne-jobs-01;onmne-jobs-01:irqstats.i12.label 12-edge      i8042
onmne-jobs-01;onmne-jobs-01:irqstats.i12.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i12.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iIWI.info Interrupt IWI, for device(s): IRQ work interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iIWI.label IRQ work interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iIWI.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iIWI.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iIWI.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iIWI.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i17.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i17.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i17.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i17.label 17-fasteoi   ioc0
onmne-jobs-01;onmne-jobs-01:irqstats.i17.info Interrupt 17, for device(s): 17-fasteoi   ioc0
onmne-jobs-01;onmne-jobs-01:irqstats.i17.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i9.info Interrupt 9, for device(s): 9-fasteoi   acpi
onmne-jobs-01;onmne-jobs-01:irqstats.i9.label 9-fasteoi   acpi
onmne-jobs-01;onmne-jobs-01:irqstats.i9.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i9.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i9.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i9.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i39.info Interrupt 39, for device(s): 374784-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i39.label 374784-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i39.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i39.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i39.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i39.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iDFR.label Deferred Error APIC interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iDFR.info Interrupt DFR, for device(s): Deferred Error APIC interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iDFR.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iDFR.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iDFR.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iDFR.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i59.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i59.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i59.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i59.info Interrupt 59, for device(s): 1572867-edge      ens160-rxtx-3
onmne-jobs-01;onmne-jobs-01:irqstats.i59.label 1572867-edge      ens160-rxtx-3
onmne-jobs-01;onmne-jobs-01:irqstats.i59.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i25.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i25.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i25.label 346112-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i25.info Interrupt 25, for device(s): 346112-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i25.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i25.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i1.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i1.label 1-edge      i8042
onmne-jobs-01;onmne-jobs-01:irqstats.i1.info Interrupt 1, for device(s): 1-edge      i8042
onmne-jobs-01;onmne-jobs-01:irqstats.i1.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i1.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i1.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iRTR.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iRTR.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iRTR.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iRTR.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iRTR.label APIC ICR read retries
onmne-jobs-01;onmne-jobs-01:irqstats.iRTR.info Interrupt RTR, for device(s): APIC ICR read retries
onmne-jobs-01;onmne-jobs-01:irqstats.iPIN.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iPIN.info Interrupt PIN, for device(s): Posted-interrupt notification event
onmne-jobs-01;onmne-jobs-01:irqstats.iPIN.label Posted-interrupt notification event
onmne-jobs-01;onmne-jobs-01:irqstats.iPIN.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iPIN.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iPIN.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i41.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i41.label 378880-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i41.info Interrupt 41, for device(s): 378880-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i41.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i41.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i41.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i40.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i40.label 376832-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i40.info Interrupt 40, for device(s): 376832-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i40.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i40.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i40.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iRES.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iRES.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iRES.label Rescheduling interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iRES.info Interrupt RES, for device(s): Rescheduling interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iRES.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iRES.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iLOC.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iLOC.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iLOC.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iLOC.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iLOC.info Interrupt LOC, for device(s): Local timer interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iLOC.label Local timer interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.i44.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i44.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i44.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i44.info Interrupt 44, for device(s): 385024-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i44.label 385024-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i44.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i62.info Interrupt 62, for device(s): 129024-edge      vmw_vmci
onmne-jobs-01;onmne-jobs-01:irqstats.i62.label 129024-edge      vmw_vmci
onmne-jobs-01;onmne-jobs-01:irqstats.i62.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i62.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i62.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i62.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iTLB.info Interrupt TLB, for device(s): TLB shootdowns
onmne-jobs-01;onmne-jobs-01:irqstats.iTLB.label TLB shootdowns
onmne-jobs-01;onmne-jobs-01:irqstats.iTLB.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iTLB.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iTLB.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iTLB.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i24.info Interrupt 24, for device(s): 344064-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i24.label 344064-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i24.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i24.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i24.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i24.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i29.info Interrupt 29, for device(s): 354304-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i29.label 354304-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i29.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i29.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i29.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i29.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i35.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i35.label 366592-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i35.info Interrupt 35, for device(s): 366592-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i35.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i35.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i35.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i55.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i55.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i55.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i55.info Interrupt 55, for device(s): 407552-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i55.label 407552-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i55.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i60.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i60.info Interrupt 60, for device(s): 1572868-edge      ens160-event-4
onmne-jobs-01;onmne-jobs-01:irqstats.i60.label 1572868-edge      ens160-event-4
onmne-jobs-01;onmne-jobs-01:irqstats.i60.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i60.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i60.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iSPU.label Spurious interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iSPU.info Interrupt SPU, for device(s): Spurious interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iSPU.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iSPU.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iSPU.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iSPU.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iTRM.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iTRM.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iTRM.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iTRM.label Thermal event interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iTRM.info Interrupt TRM, for device(s): Thermal event interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iTRM.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iNMI.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iNMI.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iNMI.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iNMI.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iNMI.info Interrupt NMI, for device(s): Non-maskable interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iNMI.label Non-maskable interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iERR.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iERR.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iERR.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iERR.label ERR
onmne-jobs-01;onmne-jobs-01:irqstats.iERR.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i49.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i49.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i49.label 395264-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i49.info Interrupt 49, for device(s): 395264-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i49.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i49.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i0.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i0.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i0.info Interrupt 0, for device(s): 2-edge      timer
onmne-jobs-01;onmne-jobs-01:irqstats.i0.label 2-edge      timer
onmne-jobs-01;onmne-jobs-01:irqstats.i0.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i0.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iCAL.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iCAL.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iCAL.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iCAL.info Interrupt CAL, for device(s): Function call interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iCAL.label Function call interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iCAL.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i61.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i61.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i61.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i61.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i61.label 1064960-edge      ahci[0000:02:01.0]
onmne-jobs-01;onmne-jobs-01:irqstats.i61.info Interrupt 61, for device(s): 1064960-edge      ahci[0000:02:01.0]
onmne-jobs-01;onmne-jobs-01:irqstats.i28.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i28.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i28.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i28.label 352256-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i28.info Interrupt 28, for device(s): 352256-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i28.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i27.label 350208-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i27.info Interrupt 27, for device(s): 350208-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i27.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i27.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i27.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i27.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i26.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i26.info Interrupt 26, for device(s): 348160-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i26.label 348160-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i26.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i26.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i26.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iPIW.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iPIW.info Interrupt PIW, for device(s): Posted-interrupt wakeup event
onmne-jobs-01;onmne-jobs-01:irqstats.iPIW.label Posted-interrupt wakeup event
onmne-jobs-01;onmne-jobs-01:irqstats.iPIW.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iPIW.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iPIW.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i33.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i33.label 362496-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i33.info Interrupt 33, for device(s): 362496-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i33.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i33.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i33.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i53.label 403456-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i53.info Interrupt 53, for device(s): 403456-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i53.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i53.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i53.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i53.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i15.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i15.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i15.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i15.label 15-edge      ata_piix
onmne-jobs-01;onmne-jobs-01:irqstats.i15.info Interrupt 15, for device(s): 15-edge      ata_piix
onmne-jobs-01;onmne-jobs-01:irqstats.i15.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iPMI.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iPMI.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iPMI.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iPMI.info Interrupt PMI, for device(s): Performance monitoring interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iPMI.label Performance monitoring interrupts
onmne-jobs-01;onmne-jobs-01:irqstats.iPMI.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i46.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i46.info Interrupt 46, for device(s): 389120-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i46.label 389120-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i46.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i46.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i46.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.iMIS.label MIS
onmne-jobs-01;onmne-jobs-01:irqstats.iMIS.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iMIS.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iMIS.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iMIS.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i47.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i47.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i47.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i47.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i47.info Interrupt 47, for device(s): 391168-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i47.label 391168-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i42.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i42.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i42.label 380928-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i42.info Interrupt 42, for device(s): 380928-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i42.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i42.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i48.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i48.info Interrupt 48, for device(s): 393216-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i48.label 393216-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i48.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i48.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i48.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iMCP.label Machine check polls
onmne-jobs-01;onmne-jobs-01:irqstats.iMCP.info Interrupt MCP, for device(s): Machine check polls
onmne-jobs-01;onmne-jobs-01:irqstats.iMCP.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iMCP.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iMCP.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iMCP.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i34.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i34.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i34.info Interrupt 34, for device(s): 364544-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i34.label 364544-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i34.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i34.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i54.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i54.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i54.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i54.label 405504-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i54.info Interrupt 54, for device(s): 405504-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i54.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i63.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i63.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i63.info Interrupt 63, for device(s): 129025-edge      vmw_vmci
onmne-jobs-01;onmne-jobs-01:irqstats.i63.label 129025-edge      vmw_vmci
onmne-jobs-01;onmne-jobs-01:irqstats.i63.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i63.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i8.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i8.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i8.info Interrupt 8, for device(s): 8-edge      rtc0
onmne-jobs-01;onmne-jobs-01:irqstats.i8.label 8-edge      rtc0
onmne-jobs-01;onmne-jobs-01:irqstats.i8.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i8.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iNPI.label Nested posted-interrupt event
onmne-jobs-01;onmne-jobs-01:irqstats.iNPI.info Interrupt NPI, for device(s): Nested posted-interrupt event
onmne-jobs-01;onmne-jobs-01:irqstats.iNPI.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.iNPI.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.iNPI.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.iNPI.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i50.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i50.label 397312-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i50.info Interrupt 50, for device(s): 397312-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i50.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i50.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i50.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i30.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i30.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i30.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i30.info Interrupt 30, for device(s): 356352-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i30.label 356352-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i30.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i14.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i14.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i14.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i14.label 14-edge      ata_piix
onmne-jobs-01;onmne-jobs-01:irqstats.i14.info Interrupt 14, for device(s): 14-edge      ata_piix
onmne-jobs-01;onmne-jobs-01:irqstats.i14.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i31.update_rate 300
onmne-jobs-01;onmne-jobs-01:irqstats.i31.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i31.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i31.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i31.info Interrupt 31, for device(s): 358400-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i31.label 358400-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i51.info Interrupt 51, for device(s): 399360-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i51.label 399360-edge      PCIe PME, pciehp
onmne-jobs-01;onmne-jobs-01:irqstats.i51.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:irqstats.i51.min 0
onmne-jobs-01;onmne-jobs-01:irqstats.i51.type DERIVE
onmne-jobs-01;onmne-jobs-01:irqstats.i51.update_rate 300
onmne-jobs-01;onmne-jobs-01:cpu.graph_title CPU usage
onmne-jobs-01;onmne-jobs-01:cpu.graph_order system user nice idle iowait irq softirq system user nice idle iowait irq softirq steal guest
onmne-jobs-01;onmne-jobs-01:cpu.graph_args --base 1000 -r --lower-limit 0 --upper-limit 400
onmne-jobs-01;onmne-jobs-01:cpu.graph_vlabel %
onmne-jobs-01;onmne-jobs-01:cpu.graph_scale no
onmne-jobs-01;onmne-jobs-01:cpu.graph_info This graph shows how CPU time is spent.
onmne-jobs-01;onmne-jobs-01:cpu.graph_category system
onmne-jobs-01;onmne-jobs-01:cpu.graph_period second
onmne-jobs-01;onmne-jobs-01:cpu.user.update_rate 300
onmne-jobs-01;onmne-jobs-01:cpu.user.draw STACK
onmne-jobs-01;onmne-jobs-01:cpu.user.type DERIVE
onmne-jobs-01;onmne-jobs-01:cpu.user.min 0
onmne-jobs-01;onmne-jobs-01:cpu.user.info CPU time spent by normal programs and daemons
onmne-jobs-01;onmne-jobs-01:cpu.user.label user
onmne-jobs-01;onmne-jobs-01:cpu.user.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:cpu.softirq.label softirq
onmne-jobs-01;onmne-jobs-01:cpu.softirq.info CPU time spent handling "batched" interrupts
onmne-jobs-01;onmne-jobs-01:cpu.softirq.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:cpu.softirq.min 0
onmne-jobs-01;onmne-jobs-01:cpu.softirq.type DERIVE
onmne-jobs-01;onmne-jobs-01:cpu.softirq.update_rate 300
onmne-jobs-01;onmne-jobs-01:cpu.softirq.draw STACK
onmne-jobs-01;onmne-jobs-01:cpu.steal.draw STACK
onmne-jobs-01;onmne-jobs-01:cpu.steal.update_rate 300
onmne-jobs-01;onmne-jobs-01:cpu.steal.type DERIVE
onmne-jobs-01;onmne-jobs-01:cpu.steal.min 0
onmne-jobs-01;onmne-jobs-01:cpu.steal.info The time that a virtual CPU had runnable tasks, but the virtual CPU itself was not running
onmne-jobs-01;onmne-jobs-01:cpu.steal.label steal
onmne-jobs-01;onmne-jobs-01:cpu.steal.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:cpu.idle.update_rate 300
onmne-jobs-01;onmne-jobs-01:cpu.idle.draw STACK
onmne-jobs-01;onmne-jobs-01:cpu.idle.type DERIVE
onmne-jobs-01;onmne-jobs-01:cpu.idle.min 0
onmne-jobs-01;onmne-jobs-01:cpu.idle.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:cpu.idle.info Idle CPU time
onmne-jobs-01;onmne-jobs-01:cpu.idle.label idle
onmne-jobs-01;onmne-jobs-01:cpu.irq.update_rate 300
onmne-jobs-01;onmne-jobs-01:cpu.irq.draw STACK
onmne-jobs-01;onmne-jobs-01:cpu.irq.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:cpu.irq.info CPU time spent handling interrupts
onmne-jobs-01;onmne-jobs-01:cpu.irq.label irq
onmne-jobs-01;onmne-jobs-01:cpu.irq.min 0
onmne-jobs-01;onmne-jobs-01:cpu.irq.type DERIVE
onmne-jobs-01;onmne-jobs-01:cpu.guest.label guest
onmne-jobs-01;onmne-jobs-01:cpu.guest.info The time spent running a virtual CPU for guest operating systems under the control of the Linux kernel.
onmne-jobs-01;onmne-jobs-01:cpu.guest.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:cpu.guest.min 0
onmne-jobs-01;onmne-jobs-01:cpu.guest.type DERIVE
onmne-jobs-01;onmne-jobs-01:cpu.guest.update_rate 300
onmne-jobs-01;onmne-jobs-01:cpu.guest.draw STACK
onmne-jobs-01;onmne-jobs-01:cpu.iowait.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:cpu.iowait.label iowait
onmne-jobs-01;onmne-jobs-01:cpu.iowait.info CPU time spent waiting for I/O operations to finish when there is nothing else to do.
onmne-jobs-01;onmne-jobs-01:cpu.iowait.type DERIVE
onmne-jobs-01;onmne-jobs-01:cpu.iowait.min 0
onmne-jobs-01;onmne-jobs-01:cpu.iowait.draw STACK
onmne-jobs-01;onmne-jobs-01:cpu.iowait.update_rate 300
onmne-jobs-01;onmne-jobs-01:cpu.system.min 0
onmne-jobs-01;onmne-jobs-01:cpu.system.type DERIVE
onmne-jobs-01;onmne-jobs-01:cpu.system.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:cpu.system.label system
onmne-jobs-01;onmne-jobs-01:cpu.system.info CPU time spent by the kernel in system activities
onmne-jobs-01;onmne-jobs-01:cpu.system.update_rate 300
onmne-jobs-01;onmne-jobs-01:cpu.system.draw AREA
onmne-jobs-01;onmne-jobs-01:cpu.nice.draw STACK
onmne-jobs-01;onmne-jobs-01:cpu.nice.update_rate 300
onmne-jobs-01;onmne-jobs-01:cpu.nice.min 0
onmne-jobs-01;onmne-jobs-01:cpu.nice.type DERIVE
onmne-jobs-01;onmne-jobs-01:cpu.nice.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:cpu.nice.label nice
onmne-jobs-01;onmne-jobs-01:cpu.nice.info CPU time spent by nice(1)d programs
onmne-jobs-01;onmne-jobs-01:memory.graph_args --base 1024 -l 0 --upper-limit 8348418048
onmne-jobs-01;onmne-jobs-01:memory.graph_vlabel Bytes
onmne-jobs-01;onmne-jobs-01:memory.graph_title Memory usage
onmne-jobs-01;onmne-jobs-01:memory.graph_category system
onmne-jobs-01;onmne-jobs-01:memory.graph_info This graph shows what the machine uses memory for.
onmne-jobs-01;onmne-jobs-01:memory.graph_order apps page_tables swap_cache slab cached buffers free swap apps buffers swap cached free slab swap_cache page_tables vmalloc_used committed mapped active inactive
onmne-jobs-01;onmne-jobs-01:memory.apps.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.apps.info Memory used by user-space applications.
onmne-jobs-01;onmne-jobs-01:memory.apps.label apps
onmne-jobs-01;onmne-jobs-01:memory.apps.draw AREA
onmne-jobs-01;onmne-jobs-01:memory.apps.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.buffers.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.buffers.draw STACK
onmne-jobs-01;onmne-jobs-01:memory.buffers.info Block device (e.g. harddisk) cache. Also where "dirty" blocks are stored until written.
onmne-jobs-01;onmne-jobs-01:memory.buffers.label buffers
onmne-jobs-01;onmne-jobs-01:memory.buffers.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.vmalloc_used.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.vmalloc_used.label vmalloc_used
onmne-jobs-01;onmne-jobs-01:memory.vmalloc_used.info 'VMalloc' (kernel) memory used
onmne-jobs-01;onmne-jobs-01:memory.vmalloc_used.draw LINE2
onmne-jobs-01;onmne-jobs-01:memory.vmalloc_used.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.cached.draw STACK
onmne-jobs-01;onmne-jobs-01:memory.cached.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.cached.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.cached.info Parked file data (file content) cache.
onmne-jobs-01;onmne-jobs-01:memory.cached.label cache
onmne-jobs-01;onmne-jobs-01:memory.inactive.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.inactive.draw LINE2
onmne-jobs-01;onmne-jobs-01:memory.inactive.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.inactive.info Memory not currently used.
onmne-jobs-01;onmne-jobs-01:memory.inactive.label inactive
onmne-jobs-01;onmne-jobs-01:memory.swap_cache.draw STACK
onmne-jobs-01;onmne-jobs-01:memory.swap_cache.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.swap_cache.info A piece of memory that keeps track of pages that have been fetched from swap but not yet been modified.
onmne-jobs-01;onmne-jobs-01:memory.swap_cache.label swap_cache
onmne-jobs-01;onmne-jobs-01:memory.swap_cache.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.page_tables.info Memory used to map between virtual and physical memory addresses.
onmne-jobs-01;onmne-jobs-01:memory.page_tables.label page_tables
onmne-jobs-01;onmne-jobs-01:memory.page_tables.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.page_tables.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.page_tables.draw STACK
onmne-jobs-01;onmne-jobs-01:memory.slab.draw STACK
onmne-jobs-01;onmne-jobs-01:memory.slab.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.slab.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.slab.info Memory used by the kernel (major users  are caches like inode, dentry, etc).
onmne-jobs-01;onmne-jobs-01:memory.slab.label slab_cache
onmne-jobs-01;onmne-jobs-01:memory.free.info Wasted memory. Memory that is not used for anything at all.
onmne-jobs-01;onmne-jobs-01:memory.free.label unused
onmne-jobs-01;onmne-jobs-01:memory.free.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.free.draw STACK
onmne-jobs-01;onmne-jobs-01:memory.free.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.committed.draw LINE2
onmne-jobs-01;onmne-jobs-01:memory.committed.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.committed.info The amount of memory allocated to programs. Overcommitting is normal, but may indicate memory leaks.
onmne-jobs-01;onmne-jobs-01:memory.committed.label committed
onmne-jobs-01;onmne-jobs-01:memory.committed.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.mapped.draw LINE2
onmne-jobs-01;onmne-jobs-01:memory.mapped.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.mapped.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.mapped.label mapped
onmne-jobs-01;onmne-jobs-01:memory.mapped.info All mmap()ed pages.
onmne-jobs-01;onmne-jobs-01:memory.swap.info Swap space used.
onmne-jobs-01;onmne-jobs-01:memory.swap.label swap
onmne-jobs-01;onmne-jobs-01:memory.swap.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.swap.draw STACK
onmne-jobs-01;onmne-jobs-01:memory.swap.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.active.label active
onmne-jobs-01;onmne-jobs-01:memory.active.info Memory recently used. Not reclaimed unless absolutely necessary.
onmne-jobs-01;onmne-jobs-01:memory.active.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:memory.active.update_rate 300
onmne-jobs-01;onmne-jobs-01:memory.active.draw LINE2
onmne-jobs-01;onmne-jobs-01:vmstat.graph_title VMstat
onmne-jobs-01;onmne-jobs-01:vmstat.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:vmstat.graph_vlabel process states
onmne-jobs-01;onmne-jobs-01:vmstat.graph_category processes
onmne-jobs-01;onmne-jobs-01:vmstat.graph_order wait sleep
onmne-jobs-01;onmne-jobs-01:vmstat.sleep.update_rate 300
onmne-jobs-01;onmne-jobs-01:vmstat.sleep.max 500000
onmne-jobs-01;onmne-jobs-01:vmstat.sleep.label I/O sleep
onmne-jobs-01;onmne-jobs-01:vmstat.sleep.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:vmstat.sleep.type GAUGE
onmne-jobs-01;onmne-jobs-01:vmstat.wait.update_rate 300
onmne-jobs-01;onmne-jobs-01:vmstat.wait.max 500000
onmne-jobs-01;onmne-jobs-01:vmstat.wait.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:vmstat.wait.label running
onmne-jobs-01;onmne-jobs-01:vmstat.wait.type GAUGE
onmne-jobs-01;onmne-jobs-01:netstat.graph_title Netstat
onmne-jobs-01;onmne-jobs-01:netstat.graph_args --base 1000 --logarithmic
onmne-jobs-01;onmne-jobs-01:netstat.graph_vlabel TCP connections
onmne-jobs-01;onmne-jobs-01:netstat.graph_category network
onmne-jobs-01;onmne-jobs-01:netstat.graph_period second
onmne-jobs-01;onmne-jobs-01:netstat.graph_info This graph shows the TCP activity of all the network interfaces combined.
onmne-jobs-01;onmne-jobs-01:netstat.graph_order active passive failed resets established
onmne-jobs-01;onmne-jobs-01:netstat.passive.update_rate 300
onmne-jobs-01;onmne-jobs-01:netstat.passive.max 50000
onmne-jobs-01;onmne-jobs-01:netstat.passive.min 0
onmne-jobs-01;onmne-jobs-01:netstat.passive.type DERIVE
onmne-jobs-01;onmne-jobs-01:netstat.passive.info The number of passive TCP openings per second.
onmne-jobs-01;onmne-jobs-01:netstat.passive.label passive
onmne-jobs-01;onmne-jobs-01:netstat.passive.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:netstat.established.type GAUGE
onmne-jobs-01;onmne-jobs-01:netstat.established.info The number of currently open connections.
onmne-jobs-01;onmne-jobs-01:netstat.established.label established
onmne-jobs-01;onmne-jobs-01:netstat.established.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:netstat.established.update_rate 300
onmne-jobs-01;onmne-jobs-01:netstat.established.max 50000
onmne-jobs-01;onmne-jobs-01:netstat.active.min 0
onmne-jobs-01;onmne-jobs-01:netstat.active.type DERIVE
onmne-jobs-01;onmne-jobs-01:netstat.active.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:netstat.active.label active
onmne-jobs-01;onmne-jobs-01:netstat.active.info The number of active TCP openings per second.
onmne-jobs-01;onmne-jobs-01:netstat.active.update_rate 300
onmne-jobs-01;onmne-jobs-01:netstat.active.max 50000
onmne-jobs-01;onmne-jobs-01:netstat.failed.min 0
onmne-jobs-01;onmne-jobs-01:netstat.failed.type DERIVE
onmne-jobs-01;onmne-jobs-01:netstat.failed.info The number of failed TCP connection attempts per second.
onmne-jobs-01;onmne-jobs-01:netstat.failed.label failed
onmne-jobs-01;onmne-jobs-01:netstat.failed.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:netstat.failed.max 50000
onmne-jobs-01;onmne-jobs-01:netstat.failed.update_rate 300
onmne-jobs-01;onmne-jobs-01:netstat.resets.type DERIVE
onmne-jobs-01;onmne-jobs-01:netstat.resets.min 0
onmne-jobs-01;onmne-jobs-01:netstat.resets.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:netstat.resets.info The number of TCP connection resets.
onmne-jobs-01;onmne-jobs-01:netstat.resets.label resets
onmne-jobs-01;onmne-jobs-01:netstat.resets.max 50000
onmne-jobs-01;onmne-jobs-01:netstat.resets.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_ens160.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-jobs-01;onmne-jobs-01:if_err_ens160.graph_title ens160 errors
onmne-jobs-01;onmne-jobs-01:if_err_ens160.graph_args --base 1000
onmne-jobs-01;onmne-jobs-01:if_err_ens160.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-jobs-01;onmne-jobs-01:if_err_ens160.graph_category network
onmne-jobs-01;onmne-jobs-01:if_err_ens160.graph_info This graph shows the amount of errors, packet drops, and collisions on the ens160 network interface.
onmne-jobs-01;onmne-jobs-01:if_err_ens160.collisions.label collisions
onmne-jobs-01;onmne-jobs-01:if_err_ens160.collisions.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_ens160.collisions.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_ens160.collisions.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_ens160.trans.label errors
onmne-jobs-01;onmne-jobs-01:if_err_ens160.trans.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_ens160.trans.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_ens160.trans.negative rcvd
onmne-jobs-01;onmne-jobs-01:if_err_ens160.trans.warning 1
onmne-jobs-01;onmne-jobs-01:if_err_ens160.trans.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_ens160.rxdrop.label drops
onmne-jobs-01;onmne-jobs-01:if_err_ens160.rxdrop.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_ens160.rxdrop.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_ens160.rxdrop.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_ens160.rxdrop.graph no
onmne-jobs-01;onmne-jobs-01:if_err_ens160.rcvd.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_ens160.rcvd.label errors
onmne-jobs-01;onmne-jobs-01:if_err_ens160.rcvd.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_ens160.rcvd.graph no
onmne-jobs-01;onmne-jobs-01:if_err_ens160.rcvd.warning 1
onmne-jobs-01;onmne-jobs-01:if_err_ens160.rcvd.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_ens160.txdrop.update_rate 300
onmne-jobs-01;onmne-jobs-01:if_err_ens160.txdrop.label drops
onmne-jobs-01;onmne-jobs-01:if_err_ens160.txdrop.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:if_err_ens160.txdrop.type COUNTER
onmne-jobs-01;onmne-jobs-01:if_err_ens160.txdrop.negative rxdrop
onmne-jobs-01;onmne-jobs-01:fw_packets.graph_title Firewall Throughput
onmne-jobs-01;onmne-jobs-01:fw_packets.graph_args --base 1000 -l 0
onmne-jobs-01;onmne-jobs-01:fw_packets.graph_vlabel Packets/${graph_period}
onmne-jobs-01;onmne-jobs-01:fw_packets.graph_category network
onmne-jobs-01;onmne-jobs-01:fw_packets.graph_order received forwarded
onmne-jobs-01;onmne-jobs-01:fw_packets.received.draw AREA
onmne-jobs-01;onmne-jobs-01:fw_packets.received.update_rate 300
onmne-jobs-01;onmne-jobs-01:fw_packets.received.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:fw_packets.received.label Received
onmne-jobs-01;onmne-jobs-01:fw_packets.received.type DERIVE
onmne-jobs-01;onmne-jobs-01:fw_packets.received.min 0
onmne-jobs-01;onmne-jobs-01:fw_packets.forwarded.min 0
onmne-jobs-01;onmne-jobs-01:fw_packets.forwarded.type DERIVE
onmne-jobs-01;onmne-jobs-01:fw_packets.forwarded.label Forwarded
onmne-jobs-01;onmne-jobs-01:fw_packets.forwarded.graph_data_size normal
onmne-jobs-01;onmne-jobs-01:fw_packets.forwarded.draw LINE2
onmne-jobs-01;onmne-jobs-01:fw_packets.forwarded.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.graph_title veth119b0ed errors
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.graph_category network
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth119b0ed network interface.
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth119b0ed.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth8a0274d.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_veth8a0274d.graph_title veth8a0274d traffic
onmne-fr-02;onmne-fr-02:if_veth8a0274d.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_veth8a0274d.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_veth8a0274d.graph_category network
onmne-fr-02;onmne-fr-02:if_veth8a0274d.graph_info This graph shows the traffic of the veth8a0274d network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_veth8a0274d.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth8a0274d.up.label bps
onmne-fr-02;onmne-fr-02:if_veth8a0274d.up.info Traffic of the veth8a0274d interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_veth8a0274d.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_veth8a0274d.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth8a0274d.up.negative down
onmne-fr-02;onmne-fr-02:if_veth8a0274d.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth8a0274d.up.min 0
onmne-fr-02;onmne-fr-02:if_veth8a0274d.down.label received
onmne-fr-02;onmne-fr-02:if_veth8a0274d.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_veth8a0274d.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth8a0274d.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth8a0274d.down.min 0
onmne-fr-02;onmne-fr-02:if_veth8a0274d.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth8a0274d.down.graph no
onmne-fr-02;onmne-fr-02:if_veth47a05f8.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_veth47a05f8.graph_title veth47a05f8 traffic
onmne-fr-02;onmne-fr-02:if_veth47a05f8.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_veth47a05f8.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_veth47a05f8.graph_category network
onmne-fr-02;onmne-fr-02:if_veth47a05f8.graph_info This graph shows the traffic of the veth47a05f8 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_veth47a05f8.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth47a05f8.down.graph no
onmne-fr-02;onmne-fr-02:if_veth47a05f8.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_veth47a05f8.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth47a05f8.down.label received
onmne-fr-02;onmne-fr-02:if_veth47a05f8.down.min 0
onmne-fr-02;onmne-fr-02:if_veth47a05f8.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth47a05f8.up.min 0
onmne-fr-02;onmne-fr-02:if_veth47a05f8.up.negative down
onmne-fr-02;onmne-fr-02:if_veth47a05f8.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth47a05f8.up.label bps
onmne-fr-02;onmne-fr-02:if_veth47a05f8.up.info Traffic of the veth47a05f8 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_veth47a05f8.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_veth47a05f8.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth47a05f8.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.graph_title veth4e23216 errors
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.graph_category network
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth4e23216 network interface.
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth4e23216.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.graph_title vethccfd4e3 traffic
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.graph_category network
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.graph_info This graph shows the traffic of the vethccfd4e3 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.down.graph no
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.down.min 0
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.down.label received
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.up.negative down
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.up.min 0
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.up.info Traffic of the vethccfd4e3 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.up.label bps
onmne-fr-02;onmne-fr-02:if_vethccfd4e3.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth4e23216.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_veth4e23216.graph_title veth4e23216 traffic
onmne-fr-02;onmne-fr-02:if_veth4e23216.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_veth4e23216.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_veth4e23216.graph_category network
onmne-fr-02;onmne-fr-02:if_veth4e23216.graph_info This graph shows the traffic of the veth4e23216 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_veth4e23216.up.negative down
onmne-fr-02;onmne-fr-02:if_veth4e23216.up.min 0
onmne-fr-02;onmne-fr-02:if_veth4e23216.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth4e23216.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth4e23216.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_veth4e23216.up.info Traffic of the veth4e23216 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_veth4e23216.up.label bps
onmne-fr-02;onmne-fr-02:if_veth4e23216.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth4e23216.down.graph no
onmne-fr-02;onmne-fr-02:if_veth4e23216.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth4e23216.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_veth4e23216.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth4e23216.down.label received
onmne-fr-02;onmne-fr-02:if_veth4e23216.down.min 0
onmne-fr-02;onmne-fr-02:if_veth4e23216.down.type DERIVE
onmne-fr-02;onmne-fr-02:processes.graph_title Processes
onmne-fr-02;onmne-fr-02:processes.graph_info This graph shows the number of processes
onmne-fr-02;onmne-fr-02:processes.graph_category processes
onmne-fr-02;onmne-fr-02:processes.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:processes.graph_vlabel Number of processes
onmne-fr-02;onmne-fr-02:processes.graph_order sleeping stopped zombie dead paging uninterruptible runnable processes dead paging sleeping uninterruptible zombie stopped runnable processes
onmne-fr-02;onmne-fr-02:processes.zombie.draw STACK
onmne-fr-02;onmne-fr-02:processes.zombie.update_rate 300
onmne-fr-02;onmne-fr-02:processes.zombie.colour 990000
onmne-fr-02;onmne-fr-02:processes.zombie.info The number of defunct (zombie) processes (process terminated and parent not waiting).
onmne-fr-02;onmne-fr-02:processes.zombie.label zombie
onmne-fr-02;onmne-fr-02:processes.zombie.graph_data_size normal
onmne-fr-02;onmne-fr-02:processes.sleeping.info The number of sleeping processes.
onmne-fr-02;onmne-fr-02:processes.sleeping.label sleeping
onmne-fr-02;onmne-fr-02:processes.sleeping.graph_data_size normal
onmne-fr-02;onmne-fr-02:processes.sleeping.draw AREA
onmne-fr-02;onmne-fr-02:processes.sleeping.update_rate 300
onmne-fr-02;onmne-fr-02:processes.sleeping.colour 0022ff
onmne-fr-02;onmne-fr-02:processes.paging.update_rate 300
onmne-fr-02;onmne-fr-02:processes.paging.colour 00aaaa
onmne-fr-02;onmne-fr-02:processes.paging.draw STACK
onmne-fr-02;onmne-fr-02:processes.paging.info The number of paging processes (<2.6 kernels only).
onmne-fr-02;onmne-fr-02:processes.paging.label paging
onmne-fr-02;onmne-fr-02:processes.paging.graph_data_size normal
onmne-fr-02;onmne-fr-02:processes.uninterruptible.graph_data_size normal
onmne-fr-02;onmne-fr-02:processes.uninterruptible.label uninterruptible
onmne-fr-02;onmne-fr-02:processes.uninterruptible.info The number of uninterruptible processes (usually IO).
onmne-fr-02;onmne-fr-02:processes.uninterruptible.draw STACK
onmne-fr-02;onmne-fr-02:processes.uninterruptible.colour ffa500
onmne-fr-02;onmne-fr-02:processes.uninterruptible.update_rate 300
onmne-fr-02;onmne-fr-02:processes.runnable.colour 22ff22
onmne-fr-02;onmne-fr-02:processes.runnable.update_rate 300
onmne-fr-02;onmne-fr-02:processes.runnable.draw STACK
onmne-fr-02;onmne-fr-02:processes.runnable.graph_data_size normal
onmne-fr-02;onmne-fr-02:processes.runnable.info The number of runnable processes (on the run queue).
onmne-fr-02;onmne-fr-02:processes.runnable.label runnable
onmne-fr-02;onmne-fr-02:processes.dead.label dead
onmne-fr-02;onmne-fr-02:processes.dead.info The number of dead processes.
onmne-fr-02;onmne-fr-02:processes.dead.graph_data_size normal
onmne-fr-02;onmne-fr-02:processes.dead.update_rate 300
onmne-fr-02;onmne-fr-02:processes.dead.colour ff0000
onmne-fr-02;onmne-fr-02:processes.dead.draw STACK
onmne-fr-02;onmne-fr-02:processes.stopped.graph_data_size normal
onmne-fr-02;onmne-fr-02:processes.stopped.info The number of stopped or traced processes.
onmne-fr-02;onmne-fr-02:processes.stopped.label stopped
onmne-fr-02;onmne-fr-02:processes.stopped.draw STACK
onmne-fr-02;onmne-fr-02:processes.stopped.colour cc0000
onmne-fr-02;onmne-fr-02:processes.stopped.update_rate 300
onmne-fr-02;onmne-fr-02:processes.processes.draw LINE1
onmne-fr-02;onmne-fr-02:processes.processes.colour c0c0c0
onmne-fr-02;onmne-fr-02:processes.processes.update_rate 300
onmne-fr-02;onmne-fr-02:processes.processes.graph_data_size normal
onmne-fr-02;onmne-fr-02:processes.processes.info The total number of processes.
onmne-fr-02;onmne-fr-02:processes.processes.label total
onmne-fr-02;onmne-fr-02:if_veth3ae0421.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_veth3ae0421.graph_title veth3ae0421 traffic
onmne-fr-02;onmne-fr-02:if_veth3ae0421.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_veth3ae0421.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_veth3ae0421.graph_category network
onmne-fr-02;onmne-fr-02:if_veth3ae0421.graph_info This graph shows the traffic of the veth3ae0421 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_veth3ae0421.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth3ae0421.down.graph no
onmne-fr-02;onmne-fr-02:if_veth3ae0421.down.min 0
onmne-fr-02;onmne-fr-02:if_veth3ae0421.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth3ae0421.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth3ae0421.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_veth3ae0421.down.label received
onmne-fr-02;onmne-fr-02:if_veth3ae0421.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth3ae0421.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_veth3ae0421.up.info Traffic of the veth3ae0421 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_veth3ae0421.up.label bps
onmne-fr-02;onmne-fr-02:if_veth3ae0421.up.min 0
onmne-fr-02;onmne-fr-02:if_veth3ae0421.up.negative down
onmne-fr-02;onmne-fr-02:if_veth3ae0421.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth3ae0421.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_docker0.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_docker0.graph_title docker0 traffic
onmne-fr-02;onmne-fr-02:if_docker0.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_docker0.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_docker0.graph_category network
onmne-fr-02;onmne-fr-02:if_docker0.graph_info This graph shows the traffic of the docker0 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_docker0.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_docker0.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_docker0.up.info Traffic of the docker0 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_docker0.up.label bps
onmne-fr-02;onmne-fr-02:if_docker0.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_docker0.up.negative down
onmne-fr-02;onmne-fr-02:if_docker0.up.min 0
onmne-fr-02;onmne-fr-02:if_docker0.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_docker0.down.min 0
onmne-fr-02;onmne-fr-02:if_docker0.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_docker0.down.label received
onmne-fr-02;onmne-fr-02:if_docker0.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_docker0.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_docker0.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_docker0.down.graph no
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.graph_title veth47a05f8 errors
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.graph_category network
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth47a05f8 network interface.
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth47a05f8.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.graph_title veth9db3ad2 errors
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.graph_category network
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth9db3ad2 network interface.
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth9db3ad2.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:proc_pri.graph_title Processes priority
onmne-fr-02;onmne-fr-02:proc_pri.graph_order low high locked high low locked
onmne-fr-02;onmne-fr-02:proc_pri.graph_category processes
onmne-fr-02;onmne-fr-02:proc_pri.graph_info This graph shows number of processes at each priority
onmne-fr-02;onmne-fr-02:proc_pri.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:proc_pri.graph_vlabel Number of processes
onmne-fr-02;onmne-fr-02:proc_pri.locked.update_rate 300
onmne-fr-02;onmne-fr-02:proc_pri.locked.draw STACK
onmne-fr-02;onmne-fr-02:proc_pri.locked.info The number of processes that have pages locked into memory (for real-time and custom IO)
onmne-fr-02;onmne-fr-02:proc_pri.locked.label locked in memory
onmne-fr-02;onmne-fr-02:proc_pri.locked.graph_data_size normal
onmne-fr-02;onmne-fr-02:proc_pri.low.update_rate 300
onmne-fr-02;onmne-fr-02:proc_pri.low.draw AREA
onmne-fr-02;onmne-fr-02:proc_pri.low.label low priority
onmne-fr-02;onmne-fr-02:proc_pri.low.info The number of low-priority processes (tasks)
onmne-fr-02;onmne-fr-02:proc_pri.low.graph_data_size normal
onmne-fr-02;onmne-fr-02:proc_pri.high.graph_data_size normal
onmne-fr-02;onmne-fr-02:proc_pri.high.info The number of high-priority processes (tasks)
onmne-fr-02;onmne-fr-02:proc_pri.high.label high priority
onmne-fr-02;onmne-fr-02:proc_pri.high.update_rate 300
onmne-fr-02;onmne-fr-02:proc_pri.high.draw STACK
onmne-fr-02;onmne-fr-02:munin_stats.graph_title Munin processing time
onmne-fr-02;onmne-fr-02:munin_stats.graph_info This graph shows the run time of the four different processes making up a munin-master run.  Munin-master is run from cron every 5 minutes and we want each of the programmes in munin-master to complete before the next instance starts.  Especially munin-update and munin-graph are time consuming and their run time bears watching. If munin-update uses too long time to run please see the munin-update graph to determine which host is slowing it down.  If munin-graph is running too slow you need to get clever (email the munin-users mailing list) unless you can buy a faster computer with better disks to run munin on.
onmne-fr-02;onmne-fr-02:munin_stats.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:munin_stats.graph_scale yes
onmne-fr-02;onmne-fr-02:munin_stats.graph_vlabel seconds
onmne-fr-02;onmne-fr-02:munin_stats.graph_category munin
onmne-fr-02;onmne-fr-02:munin_stats.graph_order update graph html limits
onmne-fr-02;onmne-fr-02:munin_stats.graph.draw AREASTACK
onmne-fr-02;onmne-fr-02:munin_stats.graph.update_rate 300
onmne-fr-02;onmne-fr-02:munin_stats.graph.warning 240
onmne-fr-02;onmne-fr-02:munin_stats.graph.critical 285
onmne-fr-02;onmne-fr-02:munin_stats.graph.label munin graph
onmne-fr-02;onmne-fr-02:munin_stats.graph.graph_data_size normal
onmne-fr-02;onmne-fr-02:munin_stats.update.critical 285
onmne-fr-02;onmne-fr-02:munin_stats.update.draw AREASTACK
onmne-fr-02;onmne-fr-02:munin_stats.update.update_rate 300
onmne-fr-02;onmne-fr-02:munin_stats.update.warning 240
onmne-fr-02;onmne-fr-02:munin_stats.update.label munin update
onmne-fr-02;onmne-fr-02:munin_stats.update.graph_data_size normal
onmne-fr-02;onmne-fr-02:munin_stats.html.label munin html
onmne-fr-02;onmne-fr-02:munin_stats.html.graph_data_size normal
onmne-fr-02;onmne-fr-02:munin_stats.html.draw AREASTACK
onmne-fr-02;onmne-fr-02:munin_stats.html.update_rate 300
onmne-fr-02;onmne-fr-02:munin_stats.limits.draw AREASTACK
onmne-fr-02;onmne-fr-02:munin_stats.limits.update_rate 300
onmne-fr-02;onmne-fr-02:munin_stats.limits.label munin limits
onmne-fr-02;onmne-fr-02:munin_stats.limits.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_vethcf23a91.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_vethcf23a91.graph_title vethcf23a91 traffic
onmne-fr-02;onmne-fr-02:if_vethcf23a91.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_vethcf23a91.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_vethcf23a91.graph_category network
onmne-fr-02;onmne-fr-02:if_vethcf23a91.graph_info This graph shows the traffic of the vethcf23a91 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_vethcf23a91.down.graph no
onmne-fr-02;onmne-fr-02:if_vethcf23a91.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_vethcf23a91.down.min 0
onmne-fr-02;onmne-fr-02:if_vethcf23a91.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_vethcf23a91.down.label received
onmne-fr-02;onmne-fr-02:if_vethcf23a91.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_vethcf23a91.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_vethcf23a91.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_vethcf23a91.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_vethcf23a91.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_vethcf23a91.up.label bps
onmne-fr-02;onmne-fr-02:if_vethcf23a91.up.info Traffic of the vethcf23a91 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_vethcf23a91.up.min 0
onmne-fr-02;onmne-fr-02:if_vethcf23a91.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_vethcf23a91.up.negative down
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.graph_title vethcf23a91 errors
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.graph_category network
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.graph_info This graph shows the amount of errors, packet drops, and collisions on the vethcf23a91 network interface.
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_vethcf23a91.trans.type COUNTER
onmne-fr-02;onmne-fr-02:vmstat.graph_title VMstat
onmne-fr-02;onmne-fr-02:vmstat.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:vmstat.graph_vlabel process states
onmne-fr-02;onmne-fr-02:vmstat.graph_category processes
onmne-fr-02;onmne-fr-02:vmstat.graph_order wait sleep
onmne-fr-02;onmne-fr-02:vmstat.wait.update_rate 300
onmne-fr-02;onmne-fr-02:vmstat.wait.max 500000
onmne-fr-02;onmne-fr-02:vmstat.wait.graph_data_size normal
onmne-fr-02;onmne-fr-02:vmstat.wait.label running
onmne-fr-02;onmne-fr-02:vmstat.wait.type GAUGE
onmne-fr-02;onmne-fr-02:vmstat.sleep.update_rate 300
onmne-fr-02;onmne-fr-02:vmstat.sleep.max 500000
onmne-fr-02;onmne-fr-02:vmstat.sleep.label I/O sleep
onmne-fr-02;onmne-fr-02:vmstat.sleep.graph_data_size normal
onmne-fr-02;onmne-fr-02:vmstat.sleep.type GAUGE
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.graph_title br-3088bfbd5594 traffic
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.graph_category network
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.graph_info This graph shows the traffic of the br-3088bfbd5594 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.up.negative down
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.up.min 0
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.up.label bps
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.up.info Traffic of the br-3088bfbd5594 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.down.label received
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.down.min 0
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_br_3088bfbd5594.down.graph no
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.graph_title br-d31e64799aec traffic
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.graph_category network
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.graph_info This graph shows the traffic of the br-d31e64799aec network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.up.label bps
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.up.info Traffic of the br-d31e64799aec interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.up.negative down
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.up.min 0
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.down.min 0
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.down.label received
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.down.graph no
onmne-fr-02;onmne-fr-02:if_br_d31e64799aec.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_ens160.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_ens160.graph_title ens160 errors
onmne-fr-02;onmne-fr-02:if_err_ens160.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_ens160.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_ens160.graph_category network
onmne-fr-02;onmne-fr-02:if_err_ens160.graph_info This graph shows the amount of errors, packet drops, and collisions on the ens160 network interface.
onmne-fr-02;onmne-fr-02:if_err_ens160.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_ens160.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_ens160.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_ens160.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_ens160.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_ens160.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_ens160.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_ens160.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_ens160.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_ens160.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_ens160.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_ens160.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_ens160.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_ens160.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_ens160.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_ens160.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_ens160.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_ens160.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_ens160.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_ens160.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_ens160.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_ens160.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_ens160.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_ens160.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_ens160.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_ens160.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:fw_packets.graph_title Firewall Throughput
onmne-fr-02;onmne-fr-02:fw_packets.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:fw_packets.graph_vlabel Packets/${graph_period}
onmne-fr-02;onmne-fr-02:fw_packets.graph_category network
onmne-fr-02;onmne-fr-02:fw_packets.graph_order received forwarded
onmne-fr-02;onmne-fr-02:fw_packets.forwarded.draw LINE2
onmne-fr-02;onmne-fr-02:fw_packets.forwarded.update_rate 300
onmne-fr-02;onmne-fr-02:fw_packets.forwarded.graph_data_size normal
onmne-fr-02;onmne-fr-02:fw_packets.forwarded.label Forwarded
onmne-fr-02;onmne-fr-02:fw_packets.forwarded.type DERIVE
onmne-fr-02;onmne-fr-02:fw_packets.forwarded.min 0
onmne-fr-02;onmne-fr-02:fw_packets.received.draw AREA
onmne-fr-02;onmne-fr-02:fw_packets.received.update_rate 300
onmne-fr-02;onmne-fr-02:fw_packets.received.label Received
onmne-fr-02;onmne-fr-02:fw_packets.received.graph_data_size normal
onmne-fr-02;onmne-fr-02:fw_packets.received.min 0
onmne-fr-02;onmne-fr-02:fw_packets.received.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth119b0ed.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_veth119b0ed.graph_title veth119b0ed traffic
onmne-fr-02;onmne-fr-02:if_veth119b0ed.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_veth119b0ed.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_veth119b0ed.graph_category network
onmne-fr-02;onmne-fr-02:if_veth119b0ed.graph_info This graph shows the traffic of the veth119b0ed network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_veth119b0ed.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth119b0ed.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_veth119b0ed.down.label received
onmne-fr-02;onmne-fr-02:if_veth119b0ed.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth119b0ed.down.min 0
onmne-fr-02;onmne-fr-02:if_veth119b0ed.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth119b0ed.down.graph no
onmne-fr-02;onmne-fr-02:if_veth119b0ed.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth119b0ed.up.label bps
onmne-fr-02;onmne-fr-02:if_veth119b0ed.up.info Traffic of the veth119b0ed interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_veth119b0ed.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth119b0ed.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_veth119b0ed.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth119b0ed.up.min 0
onmne-fr-02;onmne-fr-02:if_veth119b0ed.up.negative down
onmne-fr-02;onmne-fr-02:if_veth62a0c46.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_veth62a0c46.graph_title veth62a0c46 traffic
onmne-fr-02;onmne-fr-02:if_veth62a0c46.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_veth62a0c46.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_veth62a0c46.graph_category network
onmne-fr-02;onmne-fr-02:if_veth62a0c46.graph_info This graph shows the traffic of the veth62a0c46 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_veth62a0c46.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth62a0c46.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth62a0c46.up.min 0
onmne-fr-02;onmne-fr-02:if_veth62a0c46.up.negative down
onmne-fr-02;onmne-fr-02:if_veth62a0c46.up.info Traffic of the veth62a0c46 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_veth62a0c46.up.label bps
onmne-fr-02;onmne-fr-02:if_veth62a0c46.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_veth62a0c46.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth62a0c46.down.graph no
onmne-fr-02;onmne-fr-02:if_veth62a0c46.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth62a0c46.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_veth62a0c46.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth62a0c46.down.label received
onmne-fr-02;onmne-fr-02:if_veth62a0c46.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth62a0c46.down.min 0
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.graph_title veth9db3ad2 traffic
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.graph_category network
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.graph_info This graph shows the traffic of the veth9db3ad2 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.up.negative down
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.up.min 0
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.up.info Traffic of the veth9db3ad2 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.up.label bps
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.down.min 0
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.down.label received
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth9db3ad2.down.graph no
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.graph_title veth62a0c46 errors
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.graph_category network
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth62a0c46 network interface.
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth62a0c46.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.graph_title Individual interrupts
onmne-fr-02;onmne-fr-02:irqstats.graph_args --base 1000 --logarithmic
onmne-fr-02;onmne-fr-02:irqstats.graph_vlabel interrupts / ${graph_period}
onmne-fr-02;onmne-fr-02:irqstats.graph_category system
onmne-fr-02;onmne-fr-02:irqstats.graph_info Shows the number of different IRQs received by the kernel.  High disk or network traffic can cause a high number of interrupts (with good hardware and drivers this will be less so). Sudden high interrupt activity with no associated higher system activity is not normal.
onmne-fr-02;onmne-fr-02:irqstats.graph_order i0 i1 i8 i9 i12 i14 i15 i16 i17 i24 i25 i26 i27 i28 i29 i30 i31 i32 i33 i34 i35 i36 i37 i38 i39 i40 i41 i42 i43 i44 i45 i46 i47 i48 i49 i50 i51 i52 i53 i54 i55 i56 i57 i58 i59 i60 i61 i62 i63 i64 i65 i66 i67 iNMI iLOC iSPU iPMI iIWI iRTR iRES iCAL iTLB iTRM iTHR iDFR iMCE iMCP iERR iMIS iPIN iNPI iPIW i0 i1 i8 i9 i12 i14 i15 i16 i17 i24 i25 i26 i27 i28 i29 i30 i31 i32 i33 i34 i35 i36 i37 i38 i39 i40 i41 i42 i43 i44 i45 i46 i47 i48 i49 i50 i51 i52 i53 i54 i55 i56 i57 i58 i59 i60 i61 i62 i63 i64 i65 i66 i67 iNMI iLOC iSPU iPMI iIWI iRTR iRES iCAL iTLB iTRM iTHR iDFR iMCE iMCP iERR iMIS iPIN iNPI iPIW
onmne-fr-02;onmne-fr-02:irqstats.i12.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i12.label 12-edge      i8042
onmne-fr-02;onmne-fr-02:irqstats.i12.info Interrupt 12, for device(s): 12-edge      i8042
onmne-fr-02;onmne-fr-02:irqstats.i12.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i12.min 0
onmne-fr-02;onmne-fr-02:irqstats.i12.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iIWI.min 0
onmne-fr-02;onmne-fr-02:irqstats.iIWI.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iIWI.label IRQ work interrupts
onmne-fr-02;onmne-fr-02:irqstats.iIWI.info Interrupt IWI, for device(s): IRQ work interrupts
onmne-fr-02;onmne-fr-02:irqstats.iIWI.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iIWI.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i17.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i17.min 0
onmne-fr-02;onmne-fr-02:irqstats.i17.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i17.label 17-fasteoi   ioc0
onmne-fr-02;onmne-fr-02:irqstats.i17.info Interrupt 17, for device(s): 17-fasteoi   ioc0
onmne-fr-02;onmne-fr-02:irqstats.i17.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i16.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i16.min 0
onmne-fr-02;onmne-fr-02:irqstats.i16.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i16.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i16.info Interrupt 16, for device(s): 16-fasteoi   vmwgfx
onmne-fr-02;onmne-fr-02:irqstats.i16.label 16-fasteoi   vmwgfx
onmne-fr-02;onmne-fr-02:irqstats.i45.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i45.label 387072-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i45.info Interrupt 45, for device(s): 387072-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i45.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i45.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i45.min 0
onmne-fr-02;onmne-fr-02:irqstats.i25.label 346112-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i25.info Interrupt 25, for device(s): 346112-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i25.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i25.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i25.min 0
onmne-fr-02;onmne-fr-02:irqstats.i25.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i39.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i39.label 374784-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i39.info Interrupt 39, for device(s): 374784-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i39.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i39.min 0
onmne-fr-02;onmne-fr-02:irqstats.i39.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i59.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i59.min 0
onmne-fr-02;onmne-fr-02:irqstats.i59.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i59.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i59.info Interrupt 59, for device(s): 1572866-edge      ens160-rxtx-2
onmne-fr-02;onmne-fr-02:irqstats.i59.label 1572866-edge      ens160-rxtx-2
onmne-fr-02;onmne-fr-02:irqstats.iDFR.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iDFR.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iDFR.label Deferred Error APIC interrupts
onmne-fr-02;onmne-fr-02:irqstats.iDFR.info Interrupt DFR, for device(s): Deferred Error APIC interrupts
onmne-fr-02;onmne-fr-02:irqstats.iDFR.min 0
onmne-fr-02;onmne-fr-02:irqstats.iDFR.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i9.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i9.min 0
onmne-fr-02;onmne-fr-02:irqstats.i9.label 9-fasteoi   acpi
onmne-fr-02;onmne-fr-02:irqstats.i9.info Interrupt 9, for device(s): 9-fasteoi   acpi
onmne-fr-02;onmne-fr-02:irqstats.i9.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i9.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iMCE.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iMCE.min 0
onmne-fr-02;onmne-fr-02:irqstats.iMCE.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iMCE.label Machine check exceptions
onmne-fr-02;onmne-fr-02:irqstats.iMCE.info Interrupt MCE, for device(s): Machine check exceptions
onmne-fr-02;onmne-fr-02:irqstats.iMCE.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i56.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i56.min 0
onmne-fr-02;onmne-fr-02:irqstats.i56.label 1064960-edge      ahci[0000:02:01.0]
onmne-fr-02;onmne-fr-02:irqstats.i56.info Interrupt 56, for device(s): 1064960-edge      ahci[0000:02:01.0]
onmne-fr-02;onmne-fr-02:irqstats.i56.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i56.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i36.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i36.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i36.info Interrupt 36, for device(s): 368640-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i36.label 368640-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i36.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i36.min 0
onmne-fr-02;onmne-fr-02:irqstats.i43.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i43.min 0
onmne-fr-02;onmne-fr-02:irqstats.i43.info Interrupt 43, for device(s): 382976-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i43.label 382976-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i43.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i43.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i38.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i38.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i38.info Interrupt 38, for device(s): 372736-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i38.label 372736-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i38.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i38.min 0
onmne-fr-02;onmne-fr-02:irqstats.i58.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i58.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i58.min 0
onmne-fr-02;onmne-fr-02:irqstats.i58.info Interrupt 58, for device(s): 1572865-edge      ens160-rxtx-1
onmne-fr-02;onmne-fr-02:irqstats.i58.label 1572865-edge      ens160-rxtx-1
onmne-fr-02;onmne-fr-02:irqstats.i58.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i32.min 0
onmne-fr-02;onmne-fr-02:irqstats.i32.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i32.info Interrupt 32, for device(s): 360448-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i32.label 360448-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i32.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i32.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i52.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i52.min 0
onmne-fr-02;onmne-fr-02:irqstats.i52.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i52.info Interrupt 52, for device(s): 401408-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i52.label 401408-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i52.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iTHR.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iTHR.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iTHR.info Interrupt THR, for device(s): Threshold APIC interrupts
onmne-fr-02;onmne-fr-02:irqstats.iTHR.label Threshold APIC interrupts
onmne-fr-02;onmne-fr-02:irqstats.iTHR.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iTHR.min 0
onmne-fr-02;onmne-fr-02:irqstats.i57.label 1572864-edge      ens160-rxtx-0
onmne-fr-02;onmne-fr-02:irqstats.i57.info Interrupt 57, for device(s): 1572864-edge      ens160-rxtx-0
onmne-fr-02;onmne-fr-02:irqstats.i57.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i57.min 0
onmne-fr-02;onmne-fr-02:irqstats.i57.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i57.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i37.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i37.min 0
onmne-fr-02;onmne-fr-02:irqstats.i37.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i37.label 370688-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i37.info Interrupt 37, for device(s): 370688-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i37.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i44.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i44.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i44.min 0
onmne-fr-02;onmne-fr-02:irqstats.i44.info Interrupt 44, for device(s): 385024-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i44.label 385024-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i44.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iLOC.min 0
onmne-fr-02;onmne-fr-02:irqstats.iLOC.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iLOC.info Interrupt LOC, for device(s): Local timer interrupts
onmne-fr-02;onmne-fr-02:irqstats.iLOC.label Local timer interrupts
onmne-fr-02;onmne-fr-02:irqstats.iLOC.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iLOC.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iRES.info Interrupt RES, for device(s): Rescheduling interrupts
onmne-fr-02;onmne-fr-02:irqstats.iRES.label Rescheduling interrupts
onmne-fr-02;onmne-fr-02:irqstats.iRES.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iRES.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iRES.min 0
onmne-fr-02;onmne-fr-02:irqstats.iRES.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i66.min 0
onmne-fr-02;onmne-fr-02:irqstats.i66.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i66.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i66.label 129024-edge      vmw_vmci
onmne-fr-02;onmne-fr-02:irqstats.i66.info Interrupt 66, for device(s): 129024-edge      vmw_vmci
onmne-fr-02;onmne-fr-02:irqstats.i66.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iTLB.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iTLB.min 0
onmne-fr-02;onmne-fr-02:irqstats.iTLB.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iTLB.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iTLB.label TLB shootdowns
onmne-fr-02;onmne-fr-02:irqstats.iTLB.info Interrupt TLB, for device(s): TLB shootdowns
onmne-fr-02;onmne-fr-02:irqstats.i62.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i62.min 0
onmne-fr-02;onmne-fr-02:irqstats.i62.label 1572869-edge      ens160-rxtx-5
onmne-fr-02;onmne-fr-02:irqstats.i62.info Interrupt 62, for device(s): 1572869-edge      ens160-rxtx-5
onmne-fr-02;onmne-fr-02:irqstats.i62.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i62.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i67.min 0
onmne-fr-02;onmne-fr-02:irqstats.i67.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i67.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i67.info Interrupt 67, for device(s): 129025-edge      vmw_vmci
onmne-fr-02;onmne-fr-02:irqstats.i67.label 129025-edge      vmw_vmci
onmne-fr-02;onmne-fr-02:irqstats.i67.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i24.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i24.info Interrupt 24, for device(s): 344064-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i24.label 344064-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i24.min 0
onmne-fr-02;onmne-fr-02:irqstats.i24.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i24.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iPIN.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iPIN.min 0
onmne-fr-02;onmne-fr-02:irqstats.iPIN.info Interrupt PIN, for device(s): Posted-interrupt notification event
onmne-fr-02;onmne-fr-02:irqstats.iPIN.label Posted-interrupt notification event
onmne-fr-02;onmne-fr-02:irqstats.iPIN.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iPIN.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iRTR.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iRTR.label APIC ICR read retries
onmne-fr-02;onmne-fr-02:irqstats.iRTR.info Interrupt RTR, for device(s): APIC ICR read retries
onmne-fr-02;onmne-fr-02:irqstats.iRTR.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iRTR.min 0
onmne-fr-02;onmne-fr-02:irqstats.iRTR.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i1.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i1.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i1.min 0
onmne-fr-02;onmne-fr-02:irqstats.i1.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i1.label 1-edge      i8042
onmne-fr-02;onmne-fr-02:irqstats.i1.info Interrupt 1, for device(s): 1-edge      i8042
onmne-fr-02;onmne-fr-02:irqstats.i40.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i40.min 0
onmne-fr-02;onmne-fr-02:irqstats.i40.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i40.info Interrupt 40, for device(s): 376832-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i40.label 376832-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i40.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i41.min 0
onmne-fr-02;onmne-fr-02:irqstats.i41.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i41.info Interrupt 41, for device(s): 378880-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i41.label 378880-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i41.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i41.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i26.label 348160-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i26.info Interrupt 26, for device(s): 348160-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i26.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i26.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i26.min 0
onmne-fr-02;onmne-fr-02:irqstats.i26.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iPIW.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iPIW.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iPIW.min 0
onmne-fr-02;onmne-fr-02:irqstats.iPIW.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iPIW.info Interrupt PIW, for device(s): Posted-interrupt wakeup event
onmne-fr-02;onmne-fr-02:irqstats.iPIW.label Posted-interrupt wakeup event
onmne-fr-02;onmne-fr-02:irqstats.i28.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i28.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i28.min 0
onmne-fr-02;onmne-fr-02:irqstats.i28.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i28.label 352256-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i28.info Interrupt 28, for device(s): 352256-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i64.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i64.label 1572871-edge      ens160-rxtx-7
onmne-fr-02;onmne-fr-02:irqstats.i64.info Interrupt 64, for device(s): 1572871-edge      ens160-rxtx-7
onmne-fr-02;onmne-fr-02:irqstats.i64.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i64.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i64.min 0
onmne-fr-02;onmne-fr-02:irqstats.i27.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i27.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i27.info Interrupt 27, for device(s): 350208-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i27.label 350208-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i27.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i27.min 0
onmne-fr-02;onmne-fr-02:irqstats.i47.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i47.info Interrupt 47, for device(s): 391168-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i47.label 391168-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i47.min 0
onmne-fr-02;onmne-fr-02:irqstats.i47.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i47.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i48.min 0
onmne-fr-02;onmne-fr-02:irqstats.i48.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i48.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i48.label 393216-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i48.info Interrupt 48, for device(s): 393216-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i48.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i42.info Interrupt 42, for device(s): 380928-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i42.label 380928-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i42.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i42.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i42.min 0
onmne-fr-02;onmne-fr-02:irqstats.i42.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iPMI.label Performance monitoring interrupts
onmne-fr-02;onmne-fr-02:irqstats.iPMI.info Interrupt PMI, for device(s): Performance monitoring interrupts
onmne-fr-02;onmne-fr-02:irqstats.iPMI.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iPMI.min 0
onmne-fr-02;onmne-fr-02:irqstats.iPMI.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iPMI.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i53.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i53.min 0
onmne-fr-02;onmne-fr-02:irqstats.i53.label 403456-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i53.info Interrupt 53, for device(s): 403456-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i53.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i53.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i33.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i33.min 0
onmne-fr-02;onmne-fr-02:irqstats.i33.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i33.label 362496-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i33.info Interrupt 33, for device(s): 362496-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i33.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i15.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i15.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i15.label 15-edge      ata_piix
onmne-fr-02;onmne-fr-02:irqstats.i15.info Interrupt 15, for device(s): 15-edge      ata_piix
onmne-fr-02;onmne-fr-02:irqstats.i15.min 0
onmne-fr-02;onmne-fr-02:irqstats.i15.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iMIS.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iMIS.label MIS
onmne-fr-02;onmne-fr-02:irqstats.iMIS.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iMIS.min 0
onmne-fr-02;onmne-fr-02:irqstats.iMIS.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i46.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i46.min 0
onmne-fr-02;onmne-fr-02:irqstats.i46.label 389120-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i46.info Interrupt 46, for device(s): 389120-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i46.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i46.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i35.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i35.info Interrupt 35, for device(s): 366592-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i35.label 366592-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i35.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i35.min 0
onmne-fr-02;onmne-fr-02:irqstats.i35.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i55.min 0
onmne-fr-02;onmne-fr-02:irqstats.i55.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i55.info Interrupt 55, for device(s): 407552-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i55.label 407552-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i55.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i55.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i29.info Interrupt 29, for device(s): 354304-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i29.label 354304-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i29.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i29.min 0
onmne-fr-02;onmne-fr-02:irqstats.i29.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i29.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i49.min 0
onmne-fr-02;onmne-fr-02:irqstats.i49.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i49.info Interrupt 49, for device(s): 395264-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i49.label 395264-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i49.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i49.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i0.min 0
onmne-fr-02;onmne-fr-02:irqstats.i0.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i0.info Interrupt 0, for device(s): 2-edge      timer
onmne-fr-02;onmne-fr-02:irqstats.i0.label 2-edge      timer
onmne-fr-02;onmne-fr-02:irqstats.i0.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i0.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iERR.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iERR.label ERR
onmne-fr-02;onmne-fr-02:irqstats.iERR.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iERR.min 0
onmne-fr-02;onmne-fr-02:irqstats.iERR.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i61.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i61.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i61.label 1572868-edge      ens160-rxtx-4
onmne-fr-02;onmne-fr-02:irqstats.i61.info Interrupt 61, for device(s): 1572868-edge      ens160-rxtx-4
onmne-fr-02;onmne-fr-02:irqstats.i61.min 0
onmne-fr-02;onmne-fr-02:irqstats.i61.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iCAL.label Function call interrupts
onmne-fr-02;onmne-fr-02:irqstats.iCAL.info Interrupt CAL, for device(s): Function call interrupts
onmne-fr-02;onmne-fr-02:irqstats.iCAL.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iCAL.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iCAL.min 0
onmne-fr-02;onmne-fr-02:irqstats.iCAL.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iTRM.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iTRM.min 0
onmne-fr-02;onmne-fr-02:irqstats.iTRM.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iTRM.label Thermal event interrupts
onmne-fr-02;onmne-fr-02:irqstats.iTRM.info Interrupt TRM, for device(s): Thermal event interrupts
onmne-fr-02;onmne-fr-02:irqstats.iTRM.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iSPU.info Interrupt SPU, for device(s): Spurious interrupts
onmne-fr-02;onmne-fr-02:irqstats.iSPU.label Spurious interrupts
onmne-fr-02;onmne-fr-02:irqstats.iSPU.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iSPU.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iSPU.min 0
onmne-fr-02;onmne-fr-02:irqstats.iSPU.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i60.label 1572867-edge      ens160-rxtx-3
onmne-fr-02;onmne-fr-02:irqstats.i60.info Interrupt 60, for device(s): 1572867-edge      ens160-rxtx-3
onmne-fr-02;onmne-fr-02:irqstats.i60.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i60.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i60.min 0
onmne-fr-02;onmne-fr-02:irqstats.i60.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iNMI.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iNMI.label Non-maskable interrupts
onmne-fr-02;onmne-fr-02:irqstats.iNMI.info Interrupt NMI, for device(s): Non-maskable interrupts
onmne-fr-02;onmne-fr-02:irqstats.iNMI.min 0
onmne-fr-02;onmne-fr-02:irqstats.iNMI.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iNMI.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i65.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i65.min 0
onmne-fr-02;onmne-fr-02:irqstats.i65.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i65.info Interrupt 65, for device(s): 1572872-edge      ens160-event-8
onmne-fr-02;onmne-fr-02:irqstats.i65.label 1572872-edge      ens160-event-8
onmne-fr-02;onmne-fr-02:irqstats.i65.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iNPI.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iNPI.min 0
onmne-fr-02;onmne-fr-02:irqstats.iNPI.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.iNPI.label Nested posted-interrupt event
onmne-fr-02;onmne-fr-02:irqstats.iNPI.info Interrupt NPI, for device(s): Nested posted-interrupt event
onmne-fr-02;onmne-fr-02:irqstats.iNPI.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i31.label 358400-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i31.info Interrupt 31, for device(s): 358400-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i31.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i31.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i31.min 0
onmne-fr-02;onmne-fr-02:irqstats.i31.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i51.min 0
onmne-fr-02;onmne-fr-02:irqstats.i51.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i51.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i51.info Interrupt 51, for device(s): 399360-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i51.label 399360-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i51.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i14.info Interrupt 14, for device(s): 14-edge      ata_piix
onmne-fr-02;onmne-fr-02:irqstats.i14.label 14-edge      ata_piix
onmne-fr-02;onmne-fr-02:irqstats.i14.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i14.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i14.min 0
onmne-fr-02;onmne-fr-02:irqstats.i14.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i50.min 0
onmne-fr-02;onmne-fr-02:irqstats.i50.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i50.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i50.info Interrupt 50, for device(s): 397312-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i50.label 397312-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i50.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i30.info Interrupt 30, for device(s): 356352-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i30.label 356352-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i30.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i30.min 0
onmne-fr-02;onmne-fr-02:irqstats.i30.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i30.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iMCP.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.iMCP.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.iMCP.info Interrupt MCP, for device(s): Machine check polls
onmne-fr-02;onmne-fr-02:irqstats.iMCP.label Machine check polls
onmne-fr-02;onmne-fr-02:irqstats.iMCP.min 0
onmne-fr-02;onmne-fr-02:irqstats.iMCP.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i34.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i34.label 364544-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i34.info Interrupt 34, for device(s): 364544-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i34.min 0
onmne-fr-02;onmne-fr-02:irqstats.i34.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i34.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i54.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i54.info Interrupt 54, for device(s): 405504-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i54.label 405504-edge      PCIe PME, pciehp
onmne-fr-02;onmne-fr-02:irqstats.i54.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i54.min 0
onmne-fr-02;onmne-fr-02:irqstats.i54.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i63.min 0
onmne-fr-02;onmne-fr-02:irqstats.i63.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i63.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i63.label 1572870-edge      ens160-rxtx-6
onmne-fr-02;onmne-fr-02:irqstats.i63.info Interrupt 63, for device(s): 1572870-edge      ens160-rxtx-6
onmne-fr-02;onmne-fr-02:irqstats.i63.update_rate 300
onmne-fr-02;onmne-fr-02:irqstats.i8.info Interrupt 8, for device(s): 8-edge      rtc0
onmne-fr-02;onmne-fr-02:irqstats.i8.label 8-edge      rtc0
onmne-fr-02;onmne-fr-02:irqstats.i8.graph_data_size normal
onmne-fr-02;onmne-fr-02:irqstats.i8.type DERIVE
onmne-fr-02;onmne-fr-02:irqstats.i8.min 0
onmne-fr-02;onmne-fr-02:irqstats.i8.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth678ae1f.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_veth678ae1f.graph_title veth678ae1f traffic
onmne-fr-02;onmne-fr-02:if_veth678ae1f.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_veth678ae1f.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_veth678ae1f.graph_category network
onmne-fr-02;onmne-fr-02:if_veth678ae1f.graph_info This graph shows the traffic of the veth678ae1f network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_veth678ae1f.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth678ae1f.down.graph no
onmne-fr-02;onmne-fr-02:if_veth678ae1f.down.max 10000000000
onmne-fr-02;onmne-fr-02:if_veth678ae1f.down.label received
onmne-fr-02;onmne-fr-02:if_veth678ae1f.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_veth678ae1f.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth678ae1f.down.min 0
onmne-fr-02;onmne-fr-02:if_veth678ae1f.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth678ae1f.up.max 10000000000
onmne-fr-02;onmne-fr-02:if_veth678ae1f.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth678ae1f.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_veth678ae1f.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth678ae1f.up.label bps
onmne-fr-02;onmne-fr-02:if_veth678ae1f.up.info Traffic of the veth678ae1f interface. Maximum speed is 10000 Mb/s.
onmne-fr-02;onmne-fr-02:if_veth678ae1f.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth678ae1f.up.min 0
onmne-fr-02;onmne-fr-02:if_veth678ae1f.up.negative down
onmne-fr-02;onmne-fr-02:cpu.graph_title CPU usage
onmne-fr-02;onmne-fr-02:cpu.graph_order system user nice idle iowait irq softirq system user nice idle iowait irq softirq steal guest
onmne-fr-02;onmne-fr-02:cpu.graph_args --base 1000 -r --lower-limit 0 --upper-limit 800
onmne-fr-02;onmne-fr-02:cpu.graph_vlabel %
onmne-fr-02;onmne-fr-02:cpu.graph_scale no
onmne-fr-02;onmne-fr-02:cpu.graph_info This graph shows how CPU time is spent.
onmne-fr-02;onmne-fr-02:cpu.graph_category system
onmne-fr-02;onmne-fr-02:cpu.graph_period second
onmne-fr-02;onmne-fr-02:cpu.irq.update_rate 300
onmne-fr-02;onmne-fr-02:cpu.irq.draw STACK
onmne-fr-02;onmne-fr-02:cpu.irq.graph_data_size normal
onmne-fr-02;onmne-fr-02:cpu.irq.label irq
onmne-fr-02;onmne-fr-02:cpu.irq.info CPU time spent handling interrupts
onmne-fr-02;onmne-fr-02:cpu.irq.type DERIVE
onmne-fr-02;onmne-fr-02:cpu.irq.min 0
onmne-fr-02;onmne-fr-02:cpu.nice.graph_data_size normal
onmne-fr-02;onmne-fr-02:cpu.nice.label nice
onmne-fr-02;onmne-fr-02:cpu.nice.info CPU time spent by nice(1)d programs
onmne-fr-02;onmne-fr-02:cpu.nice.type DERIVE
onmne-fr-02;onmne-fr-02:cpu.nice.min 0
onmne-fr-02;onmne-fr-02:cpu.nice.update_rate 300
onmne-fr-02;onmne-fr-02:cpu.nice.draw STACK
onmne-fr-02;onmne-fr-02:cpu.guest.type DERIVE
onmne-fr-02;onmne-fr-02:cpu.guest.min 0
onmne-fr-02;onmne-fr-02:cpu.guest.info The time spent running a virtual CPU for guest operating systems under the control of the Linux kernel.
onmne-fr-02;onmne-fr-02:cpu.guest.label guest
onmne-fr-02;onmne-fr-02:cpu.guest.graph_data_size normal
onmne-fr-02;onmne-fr-02:cpu.guest.draw STACK
onmne-fr-02;onmne-fr-02:cpu.guest.update_rate 300
onmne-fr-02;onmne-fr-02:cpu.iowait.graph_data_size normal
onmne-fr-02;onmne-fr-02:cpu.iowait.info CPU time spent waiting for I/O operations to finish when there is nothing else to do.
onmne-fr-02;onmne-fr-02:cpu.iowait.label iowait
onmne-fr-02;onmne-fr-02:cpu.iowait.type DERIVE
onmne-fr-02;onmne-fr-02:cpu.iowait.min 0
onmne-fr-02;onmne-fr-02:cpu.iowait.draw STACK
onmne-fr-02;onmne-fr-02:cpu.iowait.update_rate 300
onmne-fr-02;onmne-fr-02:cpu.system.update_rate 300
onmne-fr-02;onmne-fr-02:cpu.system.draw AREA
onmne-fr-02;onmne-fr-02:cpu.system.type DERIVE
onmne-fr-02;onmne-fr-02:cpu.system.min 0
onmne-fr-02;onmne-fr-02:cpu.system.graph_data_size normal
onmne-fr-02;onmne-fr-02:cpu.system.label system
onmne-fr-02;onmne-fr-02:cpu.system.info CPU time spent by the kernel in system activities
onmne-fr-02;onmne-fr-02:cpu.softirq.update_rate 300
onmne-fr-02;onmne-fr-02:cpu.softirq.draw STACK
onmne-fr-02;onmne-fr-02:cpu.softirq.type DERIVE
onmne-fr-02;onmne-fr-02:cpu.softirq.min 0
onmne-fr-02;onmne-fr-02:cpu.softirq.graph_data_size normal
onmne-fr-02;onmne-fr-02:cpu.softirq.info CPU time spent handling "batched" interrupts
onmne-fr-02;onmne-fr-02:cpu.softirq.label softirq
onmne-fr-02;onmne-fr-02:cpu.user.info CPU time spent by normal programs and daemons
onmne-fr-02;onmne-fr-02:cpu.user.label user
onmne-fr-02;onmne-fr-02:cpu.user.graph_data_size normal
onmne-fr-02;onmne-fr-02:cpu.user.type DERIVE
onmne-fr-02;onmne-fr-02:cpu.user.min 0
onmne-fr-02;onmne-fr-02:cpu.user.update_rate 300
onmne-fr-02;onmne-fr-02:cpu.user.draw STACK
onmne-fr-02;onmne-fr-02:cpu.idle.info Idle CPU time
onmne-fr-02;onmne-fr-02:cpu.idle.label idle
onmne-fr-02;onmne-fr-02:cpu.idle.graph_data_size normal
onmne-fr-02;onmne-fr-02:cpu.idle.type DERIVE
onmne-fr-02;onmne-fr-02:cpu.idle.min 0
onmne-fr-02;onmne-fr-02:cpu.idle.draw STACK
onmne-fr-02;onmne-fr-02:cpu.idle.update_rate 300
onmne-fr-02;onmne-fr-02:cpu.steal.draw STACK
onmne-fr-02;onmne-fr-02:cpu.steal.update_rate 300
onmne-fr-02;onmne-fr-02:cpu.steal.type DERIVE
onmne-fr-02;onmne-fr-02:cpu.steal.min 0
onmne-fr-02;onmne-fr-02:cpu.steal.label steal
onmne-fr-02;onmne-fr-02:cpu.steal.info The time that a virtual CPU had runnable tasks, but the virtual CPU itself was not running
onmne-fr-02;onmne-fr-02:cpu.steal.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.graph_title veth3ae0421 errors
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.graph_category network
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth3ae0421 network interface.
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_veth3ae0421.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:entropy.graph_title Available entropy
onmne-fr-02;onmne-fr-02:entropy.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:entropy.graph_vlabel entropy (bytes)
onmne-fr-02;onmne-fr-02:entropy.graph_scale no
onmne-fr-02;onmne-fr-02:entropy.graph_category system
onmne-fr-02;onmne-fr-02:entropy.graph_info This graph shows the amount of entropy available in the system.
onmne-fr-02;onmne-fr-02:entropy.graph_order entropy
onmne-fr-02;onmne-fr-02:entropy.entropy.label entropy
onmne-fr-02;onmne-fr-02:entropy.entropy.info The number of random bytes available. This is typically used by cryptographic applications.
onmne-fr-02;onmne-fr-02:entropy.entropy.graph_data_size normal
onmne-fr-02;onmne-fr-02:entropy.entropy.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth0c4f704.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_veth0c4f704.graph_title veth0c4f704 traffic
onmne-fr-02;onmne-fr-02:if_veth0c4f704.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_veth0c4f704.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_veth0c4f704.graph_category network
onmne-fr-02;onmne-fr-02:if_veth0c4f704.graph_info This graph shows the traffic of the veth0c4f704 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_veth0c4f704.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth0c4f704.up.negative down
onmne-fr-02;onmne-fr-02:if_veth0c4f704.up.min 0
onmne-fr-02;onmne-fr-02:if_veth0c4f704.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_veth0c4f704.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth0c4f704.up.info Traffic of the veth0c4f704 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_veth0c4f704.up.label bps
onmne-fr-02;onmne-fr-02:if_veth0c4f704.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth0c4f704.down.min 0
onmne-fr-02;onmne-fr-02:if_veth0c4f704.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth0c4f704.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_veth0c4f704.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth0c4f704.down.label received
onmne-fr-02;onmne-fr-02:if_veth0c4f704.down.graph no
onmne-fr-02;onmne-fr-02:if_veth0c4f704.down.update_rate 300
onmne-fr-02;onmne-fr-02:swap.graph_title Swap in/out
onmne-fr-02;onmne-fr-02:swap.graph_args -l 0 --base 1000
onmne-fr-02;onmne-fr-02:swap.graph_vlabel pages per ${graph_period} in (-) / out (+)
onmne-fr-02;onmne-fr-02:swap.graph_category system
onmne-fr-02;onmne-fr-02:swap.graph_order swap_in swap_out
onmne-fr-02;onmne-fr-02:swap.swap_out.update_rate 300
onmne-fr-02;onmne-fr-02:swap.swap_out.max 100000
onmne-fr-02;onmne-fr-02:swap.swap_out.graph_data_size normal
onmne-fr-02;onmne-fr-02:swap.swap_out.label swap
onmne-fr-02;onmne-fr-02:swap.swap_out.min 0
onmne-fr-02;onmne-fr-02:swap.swap_out.type DERIVE
onmne-fr-02;onmne-fr-02:swap.swap_out.negative swap_in
onmne-fr-02;onmne-fr-02:swap.swap_in.min 0
onmne-fr-02;onmne-fr-02:swap.swap_in.type DERIVE
onmne-fr-02;onmne-fr-02:swap.swap_in.graph_data_size normal
onmne-fr-02;onmne-fr-02:swap.swap_in.label swap
onmne-fr-02;onmne-fr-02:swap.swap_in.update_rate 300
onmne-fr-02;onmne-fr-02:swap.swap_in.max 100000
onmne-fr-02;onmne-fr-02:swap.swap_in.graph no
onmne-fr-02;onmne-fr-02:open_files.graph_title File table usage
onmne-fr-02;onmne-fr-02:open_files.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:open_files.graph_vlabel number of open files
onmne-fr-02;onmne-fr-02:open_files.graph_category system
onmne-fr-02;onmne-fr-02:open_files.graph_info This graph monitors the Linux open files table.
onmne-fr-02;onmne-fr-02:open_files.graph_order used max
onmne-fr-02;onmne-fr-02:open_files.max.graph_data_size normal
onmne-fr-02;onmne-fr-02:open_files.max.label max open files
onmne-fr-02;onmne-fr-02:open_files.max.info The maximum supported number of open files. Tune by modifying /proc/sys/fs/file-max.
onmne-fr-02;onmne-fr-02:open_files.max.update_rate 300
onmne-fr-02;onmne-fr-02:open_files.used.graph_data_size normal
onmne-fr-02;onmne-fr-02:open_files.used.info The number of currently open files.
onmne-fr-02;onmne-fr-02:open_files.used.label open files
onmne-fr-02;onmne-fr-02:open_files.used.warning 8485502273906394112
onmne-fr-02;onmne-fr-02:open_files.used.update_rate 300
onmne-fr-02;onmne-fr-02:open_files.used.critical 9038904596117680128
onmne-fr-02;onmne-fr-02:if_err_docker0.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_docker0.graph_title docker0 errors
onmne-fr-02;onmne-fr-02:if_err_docker0.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_docker0.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_docker0.graph_category network
onmne-fr-02;onmne-fr-02:if_err_docker0.graph_info This graph shows the amount of errors, packet drops, and collisions on the docker0 network interface.
onmne-fr-02;onmne-fr-02:if_err_docker0.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_docker0.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_docker0.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_docker0.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_docker0.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_docker0.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_docker0.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_docker0.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_docker0.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_docker0.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_docker0.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_docker0.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_docker0.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_docker0.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_docker0.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_docker0.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_docker0.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_docker0.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_docker0.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_docker0.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_docker0.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_docker0.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_docker0.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_docker0.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_docker0.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_docker0.trans.type COUNTER
onmne-fr-02;onmne-fr-02:df_inode.graph_title Inode usage in percent
onmne-fr-02;onmne-fr-02:df_inode.graph_args --upper-limit 100 -l 0
onmne-fr-02;onmne-fr-02:df_inode.graph_vlabel %
onmne-fr-02;onmne-fr-02:df_inode.graph_scale no
onmne-fr-02;onmne-fr-02:df_inode.graph_category disk
onmne-fr-02;onmne-fr-02:df_inode.graph_order overlay _dev _sys_fs_cgroup shm _dev_mapper_ubuntu_vL _rootfs_dev _rootfs_dev_shm _rootfs_run _rootfs_run_lock _dev_sda1
onmne-fr-02;onmne-fr-02:df_inode._dev.critical 98
onmne-fr-02;onmne-fr-02:df_inode._dev.update_rate 300
onmne-fr-02;onmne-fr-02:df_inode._dev.warning 92
onmne-fr-02;onmne-fr-02:df_inode._dev.label /dev
onmne-fr-02;onmne-fr-02:df_inode._dev.graph_data_size normal
onmne-fr-02;onmne-fr-02:df_inode._rootfs_dev_shm.critical 98
onmne-fr-02;onmne-fr-02:df_inode._rootfs_dev_shm.warning 92
onmne-fr-02;onmne-fr-02:df_inode._rootfs_dev_shm.update_rate 300
onmne-fr-02;onmne-fr-02:df_inode._rootfs_dev_shm.label /rootfs/dev/shm
onmne-fr-02;onmne-fr-02:df_inode._rootfs_dev_shm.graph_data_size normal
onmne-fr-02;onmne-fr-02:df_inode._rootfs_run.warning 92
onmne-fr-02;onmne-fr-02:df_inode._rootfs_run.update_rate 300
onmne-fr-02;onmne-fr-02:df_inode._rootfs_run.critical 98
onmne-fr-02;onmne-fr-02:df_inode._rootfs_run.graph_data_size normal
onmne-fr-02;onmne-fr-02:df_inode._rootfs_run.label /rootfs/run
onmne-fr-02;onmne-fr-02:df_inode.overlay.graph_data_size normal
onmne-fr-02;onmne-fr-02:df_inode.overlay.label /
onmne-fr-02;onmne-fr-02:df_inode.overlay.update_rate 300
onmne-fr-02;onmne-fr-02:df_inode.overlay.warning 92
onmne-fr-02;onmne-fr-02:df_inode.overlay.critical 98
onmne-fr-02;onmne-fr-02:df_inode._dev_sda1.label /rootfs/boot
onmne-fr-02;onmne-fr-02:df_inode._dev_sda1.graph_data_size normal
onmne-fr-02;onmne-fr-02:df_inode._dev_sda1.critical 98
onmne-fr-02;onmne-fr-02:df_inode._dev_sda1.update_rate 300
onmne-fr-02;onmne-fr-02:df_inode._dev_sda1.warning 92
onmne-fr-02;onmne-fr-02:df_inode._dev_mapper_ubuntu_vL.graph_data_size normal
onmne-fr-02;onmne-fr-02:df_inode._dev_mapper_ubuntu_vL.label /rootfs
onmne-fr-02;onmne-fr-02:df_inode._dev_mapper_ubuntu_vL.update_rate 300
onmne-fr-02;onmne-fr-02:df_inode._dev_mapper_ubuntu_vL.warning 92
onmne-fr-02;onmne-fr-02:df_inode._dev_mapper_ubuntu_vL.critical 98
onmne-fr-02;onmne-fr-02:df_inode._rootfs_dev.graph_data_size normal
onmne-fr-02;onmne-fr-02:df_inode._rootfs_dev.label /rootfs/dev
onmne-fr-02;onmne-fr-02:df_inode._rootfs_dev.critical 98
onmne-fr-02;onmne-fr-02:df_inode._rootfs_dev.update_rate 300
onmne-fr-02;onmne-fr-02:df_inode._rootfs_dev.warning 92
onmne-fr-02;onmne-fr-02:df_inode.shm.graph_data_size normal
onmne-fr-02;onmne-fr-02:df_inode.shm.label /dev/shm
onmne-fr-02;onmne-fr-02:df_inode.shm.warning 92
onmne-fr-02;onmne-fr-02:df_inode.shm.update_rate 300
onmne-fr-02;onmne-fr-02:df_inode.shm.critical 98
onmne-fr-02;onmne-fr-02:df_inode._rootfs_run_lock.critical 98
onmne-fr-02;onmne-fr-02:df_inode._rootfs_run_lock.warning 92
onmne-fr-02;onmne-fr-02:df_inode._rootfs_run_lock.update_rate 300
onmne-fr-02;onmne-fr-02:df_inode._rootfs_run_lock.label /rootfs/run/lock
onmne-fr-02;onmne-fr-02:df_inode._rootfs_run_lock.graph_data_size normal
onmne-fr-02;onmne-fr-02:df_inode._sys_fs_cgroup.label /sys/fs/cgroup
onmne-fr-02;onmne-fr-02:df_inode._sys_fs_cgroup.graph_data_size normal
onmne-fr-02;onmne-fr-02:df_inode._sys_fs_cgroup.update_rate 300
onmne-fr-02;onmne-fr-02:df_inode._sys_fs_cgroup.warning 92
onmne-fr-02;onmne-fr-02:df_inode._sys_fs_cgroup.critical 98
onmne-fr-02;onmne-fr-02:df.graph_title Disk usage in percent
onmne-fr-02;onmne-fr-02:df.graph_args --upper-limit 100 -l 0
onmne-fr-02;onmne-fr-02:df.graph_vlabel %
onmne-fr-02;onmne-fr-02:df.graph_scale no
onmne-fr-02;onmne-fr-02:df.graph_category disk
onmne-fr-02;onmne-fr-02:df.graph_order overlay _dev _sys_fs_cgroup shm _dev_mapper_ubuntu_vL _rootfs_dev_shm _rootfs_run _rootfs_run_lock _dev_sda1
onmne-fr-02;onmne-fr-02:df._sys_fs_cgroup.graph_data_size normal
onmne-fr-02;onmne-fr-02:df._sys_fs_cgroup.label /sys/fs/cgroup
onmne-fr-02;onmne-fr-02:df._sys_fs_cgroup.update_rate 300
onmne-fr-02;onmne-fr-02:df._sys_fs_cgroup.warning 92
onmne-fr-02;onmne-fr-02:df._sys_fs_cgroup.critical 98
onmne-fr-02;onmne-fr-02:df._rootfs_run_lock.critical 98
onmne-fr-02;onmne-fr-02:df._rootfs_run_lock.warning 92
onmne-fr-02;onmne-fr-02:df._rootfs_run_lock.update_rate 300
onmne-fr-02;onmne-fr-02:df._rootfs_run_lock.graph_data_size normal
onmne-fr-02;onmne-fr-02:df._rootfs_run_lock.label /rootfs/run/lock
onmne-fr-02;onmne-fr-02:df.shm.update_rate 300
onmne-fr-02;onmne-fr-02:df.shm.warning 92
onmne-fr-02;onmne-fr-02:df.shm.critical 98
onmne-fr-02;onmne-fr-02:df.shm.graph_data_size normal
onmne-fr-02;onmne-fr-02:df.shm.label /dev/shm
onmne-fr-02;onmne-fr-02:df._dev_mapper_ubuntu_vL.critical 98
onmne-fr-02;onmne-fr-02:df._dev_mapper_ubuntu_vL.warning 92
onmne-fr-02;onmne-fr-02:df._dev_mapper_ubuntu_vL.update_rate 300
onmne-fr-02;onmne-fr-02:df._dev_mapper_ubuntu_vL.graph_data_size normal
onmne-fr-02;onmne-fr-02:df._dev_mapper_ubuntu_vL.label /rootfs
onmne-fr-02;onmne-fr-02:df.overlay.graph_data_size normal
onmne-fr-02;onmne-fr-02:df.overlay.label /
onmne-fr-02;onmne-fr-02:df.overlay.critical 98
onmne-fr-02;onmne-fr-02:df.overlay.warning 92
onmne-fr-02;onmne-fr-02:df.overlay.update_rate 300
onmne-fr-02;onmne-fr-02:df._dev_sda1.critical 98
onmne-fr-02;onmne-fr-02:df._dev_sda1.update_rate 300
onmne-fr-02;onmne-fr-02:df._dev_sda1.warning 92
onmne-fr-02;onmne-fr-02:df._dev_sda1.label /rootfs/boot
onmne-fr-02;onmne-fr-02:df._dev_sda1.graph_data_size normal
onmne-fr-02;onmne-fr-02:df._rootfs_run.label /rootfs/run
onmne-fr-02;onmne-fr-02:df._rootfs_run.graph_data_size normal
onmne-fr-02;onmne-fr-02:df._rootfs_run.critical 98
onmne-fr-02;onmne-fr-02:df._rootfs_run.warning 92
onmne-fr-02;onmne-fr-02:df._rootfs_run.update_rate 300
onmne-fr-02;onmne-fr-02:df._dev.label /dev
onmne-fr-02;onmne-fr-02:df._dev.graph_data_size normal
onmne-fr-02;onmne-fr-02:df._dev.critical 98
onmne-fr-02;onmne-fr-02:df._dev.update_rate 300
onmne-fr-02;onmne-fr-02:df._dev.warning 92
onmne-fr-02;onmne-fr-02:df._rootfs_dev_shm.graph_data_size normal
onmne-fr-02;onmne-fr-02:df._rootfs_dev_shm.label /rootfs/dev/shm
onmne-fr-02;onmne-fr-02:df._rootfs_dev_shm.critical 98
onmne-fr-02;onmne-fr-02:df._rootfs_dev_shm.warning 92
onmne-fr-02;onmne-fr-02:df._rootfs_dev_shm.update_rate 300
onmne-fr-02;onmne-fr-02:if_br_06077239836b.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_br_06077239836b.graph_title br-06077239836b traffic
onmne-fr-02;onmne-fr-02:if_br_06077239836b.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_br_06077239836b.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_br_06077239836b.graph_category network
onmne-fr-02;onmne-fr-02:if_br_06077239836b.graph_info This graph shows the traffic of the br-06077239836b network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_br_06077239836b.down.graph no
onmne-fr-02;onmne-fr-02:if_br_06077239836b.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_br_06077239836b.down.label received
onmne-fr-02;onmne-fr-02:if_br_06077239836b.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_br_06077239836b.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_br_06077239836b.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_br_06077239836b.down.min 0
onmne-fr-02;onmne-fr-02:if_br_06077239836b.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_br_06077239836b.up.negative down
onmne-fr-02;onmne-fr-02:if_br_06077239836b.up.min 0
onmne-fr-02;onmne-fr-02:if_br_06077239836b.up.info Traffic of the br-06077239836b interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_br_06077239836b.up.label bps
onmne-fr-02;onmne-fr-02:if_br_06077239836b.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_br_06077239836b.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_br_06077239836b.up.update_rate 300
onmne-fr-02;onmne-fr-02:interrupts.graph_title Interrupts and context switches
onmne-fr-02;onmne-fr-02:interrupts.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:interrupts.graph_vlabel interrupts & ctx switches / ${graph_period}
onmne-fr-02;onmne-fr-02:interrupts.graph_category system
onmne-fr-02;onmne-fr-02:interrupts.graph_info This graph shows the number of interrupts and context switches on the system. These are typically high on a busy system.
onmne-fr-02;onmne-fr-02:interrupts.graph_order intr ctx
onmne-fr-02;onmne-fr-02:interrupts.intr.update_rate 300
onmne-fr-02;onmne-fr-02:interrupts.intr.max 100000
onmne-fr-02;onmne-fr-02:interrupts.intr.label interrupts
onmne-fr-02;onmne-fr-02:interrupts.intr.info Interrupts are events that alter sequence of instructions executed by a processor. They can come from either hardware (exceptions, NMI, IRQ) or software.
onmne-fr-02;onmne-fr-02:interrupts.intr.graph_data_size normal
onmne-fr-02;onmne-fr-02:interrupts.intr.type DERIVE
onmne-fr-02;onmne-fr-02:interrupts.intr.min 0
onmne-fr-02;onmne-fr-02:interrupts.ctx.max 100000
onmne-fr-02;onmne-fr-02:interrupts.ctx.update_rate 300
onmne-fr-02;onmne-fr-02:interrupts.ctx.label context switches
onmne-fr-02;onmne-fr-02:interrupts.ctx.info A context switch occurs when a multitasking operatings system suspends the currently running process, and starts executing another.
onmne-fr-02;onmne-fr-02:interrupts.ctx.graph_data_size normal
onmne-fr-02;onmne-fr-02:interrupts.ctx.type DERIVE
onmne-fr-02;onmne-fr-02:interrupts.ctx.min 0
onmne-fr-02;onmne-fr-02:open_inodes.graph_title Inode table usage
onmne-fr-02;onmne-fr-02:open_inodes.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:open_inodes.graph_vlabel number of open inodes
onmne-fr-02;onmne-fr-02:open_inodes.graph_category system
onmne-fr-02;onmne-fr-02:open_inodes.graph_info This graph monitors the Linux open inode table.
onmne-fr-02;onmne-fr-02:open_inodes.graph_order used max
onmne-fr-02;onmne-fr-02:open_inodes.used.label open inodes
onmne-fr-02;onmne-fr-02:open_inodes.used.info The number of currently open inodes.
onmne-fr-02;onmne-fr-02:open_inodes.used.graph_data_size normal
onmne-fr-02;onmne-fr-02:open_inodes.used.update_rate 300
onmne-fr-02;onmne-fr-02:open_inodes.max.update_rate 300
onmne-fr-02;onmne-fr-02:open_inodes.max.label inode table size
onmne-fr-02;onmne-fr-02:open_inodes.max.info The size of the system inode table. This is dynamically adjusted by the kernel.
onmne-fr-02;onmne-fr-02:open_inodes.max.graph_data_size normal
onmne-fr-02;onmne-fr-02:threads.graph_title Number of threads
onmne-fr-02;onmne-fr-02:threads.graph_vlabel number of threads
onmne-fr-02;onmne-fr-02:threads.graph_category processes
onmne-fr-02;onmne-fr-02:threads.graph_info This graph shows the number of threads.
onmne-fr-02;onmne-fr-02:threads.graph_order threads
onmne-fr-02;onmne-fr-02:threads.threads.update_rate 300
onmne-fr-02;onmne-fr-02:threads.threads.graph_data_size normal
onmne-fr-02;onmne-fr-02:threads.threads.label threads
onmne-fr-02;onmne-fr-02:threads.threads.info The current number of threads.
onmne-fr-02;onmne-fr-02:users.graph_title Logged in users
onmne-fr-02;onmne-fr-02:users.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:users.graph_vlabel Users
onmne-fr-02;onmne-fr-02:users.graph_scale no
onmne-fr-02;onmne-fr-02:users.graph_category system
onmne-fr-02;onmne-fr-02:users.graph_printf %3.0lf
onmne-fr-02;onmne-fr-02:users.graph_order tty pty pts X other
onmne-fr-02;onmne-fr-02:users.pty.graph_data_size normal
onmne-fr-02;onmne-fr-02:users.pty.label pty
onmne-fr-02;onmne-fr-02:users.pty.draw AREASTACK
onmne-fr-02;onmne-fr-02:users.pty.colour 0000FF
onmne-fr-02;onmne-fr-02:users.pty.update_rate 300
onmne-fr-02;onmne-fr-02:users.other.graph_data_size normal
onmne-fr-02;onmne-fr-02:users.other.label Other users
onmne-fr-02;onmne-fr-02:users.other.info Users logged in by indeterminate method
onmne-fr-02;onmne-fr-02:users.other.colour FF0000
onmne-fr-02;onmne-fr-02:users.other.update_rate 300
onmne-fr-02;onmne-fr-02:users.pts.graph_data_size normal
onmne-fr-02;onmne-fr-02:users.pts.label pts
onmne-fr-02;onmne-fr-02:users.pts.draw AREASTACK
onmne-fr-02;onmne-fr-02:users.pts.colour 00FFFF
onmne-fr-02;onmne-fr-02:users.pts.update_rate 300
onmne-fr-02;onmne-fr-02:users.X.info Users logged in on an X display
onmne-fr-02;onmne-fr-02:users.X.label X displays
onmne-fr-02;onmne-fr-02:users.X.graph_data_size normal
onmne-fr-02;onmne-fr-02:users.X.update_rate 300
onmne-fr-02;onmne-fr-02:users.X.colour 000000
onmne-fr-02;onmne-fr-02:users.X.draw AREASTACK
onmne-fr-02;onmne-fr-02:users.tty.label tty
onmne-fr-02;onmne-fr-02:users.tty.graph_data_size normal
onmne-fr-02;onmne-fr-02:users.tty.draw AREASTACK
onmne-fr-02;onmne-fr-02:users.tty.update_rate 300
onmne-fr-02;onmne-fr-02:users.tty.colour 00FF00
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.graph_title veth8a0274d errors
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.graph_category network
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth8a0274d network interface.
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_veth8a0274d.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_veth9724b6a.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_veth9724b6a.graph_title veth9724b6a traffic
onmne-fr-02;onmne-fr-02:if_veth9724b6a.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_veth9724b6a.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_veth9724b6a.graph_category network
onmne-fr-02;onmne-fr-02:if_veth9724b6a.graph_info This graph shows the traffic of the veth9724b6a network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_veth9724b6a.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_veth9724b6a.down.graph no
onmne-fr-02;onmne-fr-02:if_veth9724b6a.down.min 0
onmne-fr-02;onmne-fr-02:if_veth9724b6a.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth9724b6a.down.label received
onmne-fr-02;onmne-fr-02:if_veth9724b6a.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth9724b6a.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_veth9724b6a.up.min 0
onmne-fr-02;onmne-fr-02:if_veth9724b6a.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_veth9724b6a.up.negative down
onmne-fr-02;onmne-fr-02:if_veth9724b6a.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_veth9724b6a.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_veth9724b6a.up.label bps
onmne-fr-02;onmne-fr-02:if_veth9724b6a.up.info Traffic of the veth9724b6a interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_veth9724b6a.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.graph_title br-1469d238c2f9 traffic
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.graph_category network
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.graph_info This graph shows the traffic of the br-1469d238c2f9 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.down.graph no
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.down.min 0
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.down.label received
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.up.label bps
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.up.info Traffic of the br-1469d238c2f9 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.up.negative down
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.up.min 0
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_br_1469d238c2f9.up.update_rate 300
onmne-fr-02;onmne-fr-02:uptime.graph_title Uptime
onmne-fr-02;onmne-fr-02:uptime.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:uptime.graph_scale no
onmne-fr-02;onmne-fr-02:uptime.graph_vlabel uptime in days
onmne-fr-02;onmne-fr-02:uptime.graph_category system
onmne-fr-02;onmne-fr-02:uptime.graph_order uptime
onmne-fr-02;onmne-fr-02:uptime.uptime.label uptime
onmne-fr-02;onmne-fr-02:uptime.uptime.graph_data_size normal
onmne-fr-02;onmne-fr-02:uptime.uptime.draw AREA
onmne-fr-02;onmne-fr-02:uptime.uptime.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.graph_title br-1469d238c2f9 errors
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.graph_category network
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.graph_info This graph shows the amount of errors, packet drops, and collisions on the br-1469d238c2f9 network interface.
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_1469d238c2f9.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.graph_title vethccfd4e3 errors
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.graph_category network
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.graph_info This graph shows the amount of errors, packet drops, and collisions on the vethccfd4e3 network interface.
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_vethccfd4e3.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.graph_title br-06077239836b errors
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.graph_category network
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.graph_info This graph shows the amount of errors, packet drops, and collisions on the br-06077239836b network interface.
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_br_06077239836b.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:netstat.graph_title Netstat
onmne-fr-02;onmne-fr-02:netstat.graph_args --base 1000 --logarithmic
onmne-fr-02;onmne-fr-02:netstat.graph_vlabel TCP connections
onmne-fr-02;onmne-fr-02:netstat.graph_category network
onmne-fr-02;onmne-fr-02:netstat.graph_period second
onmne-fr-02;onmne-fr-02:netstat.graph_info This graph shows the TCP activity of all the network interfaces combined.
onmne-fr-02;onmne-fr-02:netstat.graph_order active passive failed resets established
onmne-fr-02;onmne-fr-02:netstat.established.graph_data_size normal
onmne-fr-02;onmne-fr-02:netstat.established.label established
onmne-fr-02;onmne-fr-02:netstat.established.info The number of currently open connections.
onmne-fr-02;onmne-fr-02:netstat.established.type GAUGE
onmne-fr-02;onmne-fr-02:netstat.established.max 50000
onmne-fr-02;onmne-fr-02:netstat.established.update_rate 300
onmne-fr-02;onmne-fr-02:netstat.passive.type DERIVE
onmne-fr-02;onmne-fr-02:netstat.passive.min 0
onmne-fr-02;onmne-fr-02:netstat.passive.label passive
onmne-fr-02;onmne-fr-02:netstat.passive.info The number of passive TCP openings per second.
onmne-fr-02;onmne-fr-02:netstat.passive.graph_data_size normal
onmne-fr-02;onmne-fr-02:netstat.passive.max 50000
onmne-fr-02;onmne-fr-02:netstat.passive.update_rate 300
onmne-fr-02;onmne-fr-02:netstat.resets.label resets
onmne-fr-02;onmne-fr-02:netstat.resets.info The number of TCP connection resets.
onmne-fr-02;onmne-fr-02:netstat.resets.graph_data_size normal
onmne-fr-02;onmne-fr-02:netstat.resets.min 0
onmne-fr-02;onmne-fr-02:netstat.resets.type DERIVE
onmne-fr-02;onmne-fr-02:netstat.resets.max 50000
onmne-fr-02;onmne-fr-02:netstat.resets.update_rate 300
onmne-fr-02;onmne-fr-02:netstat.failed.max 50000
onmne-fr-02;onmne-fr-02:netstat.failed.update_rate 300
onmne-fr-02;onmne-fr-02:netstat.failed.info The number of failed TCP connection attempts per second.
onmne-fr-02;onmne-fr-02:netstat.failed.label failed
onmne-fr-02;onmne-fr-02:netstat.failed.graph_data_size normal
onmne-fr-02;onmne-fr-02:netstat.failed.min 0
onmne-fr-02;onmne-fr-02:netstat.failed.type DERIVE
onmne-fr-02;onmne-fr-02:netstat.active.info The number of active TCP openings per second.
onmne-fr-02;onmne-fr-02:netstat.active.label active
onmne-fr-02;onmne-fr-02:netstat.active.graph_data_size normal
onmne-fr-02;onmne-fr-02:netstat.active.type DERIVE
onmne-fr-02;onmne-fr-02:netstat.active.min 0
onmne-fr-02;onmne-fr-02:netstat.active.max 50000
onmne-fr-02;onmne-fr-02:netstat.active.update_rate 300
onmne-fr-02;onmne-fr-02:if_ens160.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_ens160.graph_title ens160 traffic
onmne-fr-02;onmne-fr-02:if_ens160.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_ens160.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_ens160.graph_category network
onmne-fr-02;onmne-fr-02:if_ens160.graph_info This graph shows the traffic of the ens160 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_ens160.up.min 0
onmne-fr-02;onmne-fr-02:if_ens160.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_ens160.up.negative down
onmne-fr-02;onmne-fr-02:if_ens160.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_ens160.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_ens160.up.info Traffic of the ens160 interface. Maximum speed is 10000 Mb/s.
onmne-fr-02;onmne-fr-02:if_ens160.up.label bps
onmne-fr-02;onmne-fr-02:if_ens160.up.max 10000000000
onmne-fr-02;onmne-fr-02:if_ens160.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_ens160.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_ens160.down.max 10000000000
onmne-fr-02;onmne-fr-02:if_ens160.down.graph no
onmne-fr-02;onmne-fr-02:if_ens160.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_ens160.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_ens160.down.label received
onmne-fr-02;onmne-fr-02:if_ens160.down.min 0
onmne-fr-02;onmne-fr-02:if_ens160.down.type DERIVE
onmne-fr-02;onmne-fr-02:memory.graph_args --base 1024 -l 0 --upper-limit 16790622208
onmne-fr-02;onmne-fr-02:memory.graph_vlabel Bytes
onmne-fr-02;onmne-fr-02:memory.graph_title Memory usage
onmne-fr-02;onmne-fr-02:memory.graph_category system
onmne-fr-02;onmne-fr-02:memory.graph_info This graph shows what the machine uses memory for.
onmne-fr-02;onmne-fr-02:memory.graph_order apps page_tables swap_cache slab cached buffers free swap apps buffers swap cached free slab swap_cache page_tables vmalloc_used committed mapped active inactive
onmne-fr-02;onmne-fr-02:memory.swap.label swap
onmne-fr-02;onmne-fr-02:memory.swap.info Swap space used.
onmne-fr-02;onmne-fr-02:memory.swap.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.swap.draw STACK
onmne-fr-02;onmne-fr-02:memory.swap.update_rate 300
onmne-fr-02;onmne-fr-02:memory.active.label active
onmne-fr-02;onmne-fr-02:memory.active.info Memory recently used. Not reclaimed unless absolutely necessary.
onmne-fr-02;onmne-fr-02:memory.active.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.active.draw LINE2
onmne-fr-02;onmne-fr-02:memory.active.update_rate 300
onmne-fr-02;onmne-fr-02:memory.mapped.draw LINE2
onmne-fr-02;onmne-fr-02:memory.mapped.update_rate 300
onmne-fr-02;onmne-fr-02:memory.mapped.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.mapped.label mapped
onmne-fr-02;onmne-fr-02:memory.mapped.info All mmap()ed pages.
onmne-fr-02;onmne-fr-02:memory.committed.update_rate 300
onmne-fr-02;onmne-fr-02:memory.committed.draw LINE2
onmne-fr-02;onmne-fr-02:memory.committed.label committed
onmne-fr-02;onmne-fr-02:memory.committed.info The amount of memory allocated to programs. Overcommitting is normal, but may indicate memory leaks.
onmne-fr-02;onmne-fr-02:memory.committed.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.free.draw STACK
onmne-fr-02;onmne-fr-02:memory.free.update_rate 300
onmne-fr-02;onmne-fr-02:memory.free.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.free.info Wasted memory. Memory that is not used for anything at all.
onmne-fr-02;onmne-fr-02:memory.free.label unused
onmne-fr-02;onmne-fr-02:memory.slab.label slab_cache
onmne-fr-02;onmne-fr-02:memory.slab.info Memory used by the kernel (major users  are caches like inode, dentry, etc).
onmne-fr-02;onmne-fr-02:memory.slab.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.slab.update_rate 300
onmne-fr-02;onmne-fr-02:memory.slab.draw STACK
onmne-fr-02;onmne-fr-02:memory.page_tables.update_rate 300
onmne-fr-02;onmne-fr-02:memory.page_tables.draw STACK
onmne-fr-02;onmne-fr-02:memory.page_tables.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.page_tables.label page_tables
onmne-fr-02;onmne-fr-02:memory.page_tables.info Memory used to map between virtual and physical memory addresses.
onmne-fr-02;onmne-fr-02:memory.inactive.update_rate 300
onmne-fr-02;onmne-fr-02:memory.inactive.draw LINE2
onmne-fr-02;onmne-fr-02:memory.inactive.label inactive
onmne-fr-02;onmne-fr-02:memory.inactive.info Memory not currently used.
onmne-fr-02;onmne-fr-02:memory.inactive.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.swap_cache.label swap_cache
onmne-fr-02;onmne-fr-02:memory.swap_cache.info A piece of memory that keeps track of pages that have been fetched from swap but not yet been modified.
onmne-fr-02;onmne-fr-02:memory.swap_cache.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.swap_cache.update_rate 300
onmne-fr-02;onmne-fr-02:memory.swap_cache.draw STACK
onmne-fr-02;onmne-fr-02:memory.cached.draw STACK
onmne-fr-02;onmne-fr-02:memory.cached.update_rate 300
onmne-fr-02;onmne-fr-02:memory.cached.label cache
onmne-fr-02;onmne-fr-02:memory.cached.info Parked file data (file content) cache.
onmne-fr-02;onmne-fr-02:memory.cached.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.apps.label apps
onmne-fr-02;onmne-fr-02:memory.apps.info Memory used by user-space applications.
onmne-fr-02;onmne-fr-02:memory.apps.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.apps.update_rate 300
onmne-fr-02;onmne-fr-02:memory.apps.draw AREA
onmne-fr-02;onmne-fr-02:memory.buffers.draw STACK
onmne-fr-02;onmne-fr-02:memory.buffers.update_rate 300
onmne-fr-02;onmne-fr-02:memory.buffers.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.buffers.info Block device (e.g. harddisk) cache. Also where "dirty" blocks are stored until written.
onmne-fr-02;onmne-fr-02:memory.buffers.label buffers
onmne-fr-02;onmne-fr-02:memory.vmalloc_used.draw LINE2
onmne-fr-02;onmne-fr-02:memory.vmalloc_used.update_rate 300
onmne-fr-02;onmne-fr-02:memory.vmalloc_used.graph_data_size normal
onmne-fr-02;onmne-fr-02:memory.vmalloc_used.info 'VMalloc' (kernel) memory used
onmne-fr-02;onmne-fr-02:memory.vmalloc_used.label vmalloc_used
onmne-fr-02;onmne-fr-02:load.graph_title Load average
onmne-fr-02;onmne-fr-02:load.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:load.graph_vlabel load
onmne-fr-02;onmne-fr-02:load.graph_scale no
onmne-fr-02;onmne-fr-02:load.graph_category system
onmne-fr-02;onmne-fr-02:load.graph_info The load average of the machine describes how many processes are in the run-queue (scheduled to run "immediately").
onmne-fr-02;onmne-fr-02:load.graph_order load
onmne-fr-02;onmne-fr-02:load.load.graph_data_size normal
onmne-fr-02;onmne-fr-02:load.load.label load
onmne-fr-02;onmne-fr-02:load.load.info 5 minute load average
onmne-fr-02;onmne-fr-02:load.load.update_rate 300
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.graph_order down up down up
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.graph_title br-9aa173f9573c traffic
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.graph_category network
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.graph_info This graph shows the traffic of the br-9aa173f9573c network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.up.update_rate 300
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.up.type DERIVE
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.up.negative down
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.up.min 0
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.up.cdef up,8,*
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.up.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.up.label bps
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.up.info Traffic of the br-9aa173f9573c interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.down.type DERIVE
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.down.min 0
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.down.label received
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.down.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.down.cdef down,8,*
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.down.update_rate 300
onmne-fr-02;onmne-fr-02:if_br_9aa173f9573c.down.graph no
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.graph_title veth9724b6a errors
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.graph_category network
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth9724b6a network interface.
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth9724b6a.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.graph_title br-9aa173f9573c errors
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.graph_category network
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.graph_info This graph shows the amount of errors, packet drops, and collisions on the br-9aa173f9573c network interface.
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_9aa173f9573c.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.graph_title veth0c4f704 errors
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.graph_category network
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth0c4f704 network interface.
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth0c4f704.collisions.label collisions
onmne-fr-02;onmne-fr-02:forks.graph_title Fork rate
onmne-fr-02;onmne-fr-02:forks.graph_args --base 1000 -l 0
onmne-fr-02;onmne-fr-02:forks.graph_vlabel forks / ${graph_period}
onmne-fr-02;onmne-fr-02:forks.graph_category processes
onmne-fr-02;onmne-fr-02:forks.graph_info This graph shows the number of forks (new processes started) per second.
onmne-fr-02;onmne-fr-02:forks.graph_order forks
onmne-fr-02;onmne-fr-02:forks.forks.update_rate 300
onmne-fr-02;onmne-fr-02:forks.forks.max 100000
onmne-fr-02;onmne-fr-02:forks.forks.info The number of forks per second.
onmne-fr-02;onmne-fr-02:forks.forks.label forks
onmne-fr-02;onmne-fr-02:forks.forks.graph_data_size normal
onmne-fr-02;onmne-fr-02:forks.forks.type DERIVE
onmne-fr-02;onmne-fr-02:forks.forks.min 0
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.graph_title br-d31e64799aec errors
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.graph_category network
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.graph_info This graph shows the amount of errors, packet drops, and collisions on the br-d31e64799aec network interface.
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_br_d31e64799aec.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.graph_title veth678ae1f errors
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.graph_category network
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth678ae1f network interface.
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.txdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_veth678ae1f.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.graph_title br-3088bfbd5594 errors
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.graph_args --base 1000
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.graph_category network
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.graph_info This graph shows the amount of errors, packet drops, and collisions on the br-3088bfbd5594 network interface.
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.collisions.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.collisions.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.collisions.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.collisions.label collisions
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.rxdrop.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.rxdrop.graph no
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.rxdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.rxdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.rxdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.trans.label errors
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.trans.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.trans.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.trans.negative rcvd
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.trans.warning 1
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.trans.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.rcvd.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.rcvd.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.rcvd.label errors
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.rcvd.graph no
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.rcvd.warning 1
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.rcvd.update_rate 300
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.txdrop.negative rxdrop
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.txdrop.type COUNTER
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.txdrop.label drops
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.txdrop.graph_data_size normal
onmne-fr-02;onmne-fr-02:if_err_br_3088bfbd5594.txdrop.update_rate 300
onmne-db-01;onmne-db-01:if_vethb8bc272.graph_order down up down up
onmne-db-01;onmne-db-01:if_vethb8bc272.graph_title vethb8bc272 traffic
onmne-db-01;onmne-db-01:if_vethb8bc272.graph_args --base 1000
onmne-db-01;onmne-db-01:if_vethb8bc272.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_vethb8bc272.graph_category network
onmne-db-01;onmne-db-01:if_vethb8bc272.graph_info This graph shows the traffic of the vethb8bc272 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-01;onmne-db-01:if_vethb8bc272.up.update_rate 300
onmne-db-01;onmne-db-01:if_vethb8bc272.up.label bps
onmne-db-01;onmne-db-01:if_vethb8bc272.up.info Traffic of the vethb8bc272 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-01;onmne-db-01:if_vethb8bc272.up.graph_data_size normal
onmne-db-01;onmne-db-01:if_vethb8bc272.up.cdef up,8,*
onmne-db-01;onmne-db-01:if_vethb8bc272.up.negative down
onmne-db-01;onmne-db-01:if_vethb8bc272.up.type DERIVE
onmne-db-01;onmne-db-01:if_vethb8bc272.up.min 0
onmne-db-01;onmne-db-01:if_vethb8bc272.down.cdef down,8,*
onmne-db-01;onmne-db-01:if_vethb8bc272.down.graph_data_size normal
onmne-db-01;onmne-db-01:if_vethb8bc272.down.label received
onmne-db-01;onmne-db-01:if_vethb8bc272.down.min 0
onmne-db-01;onmne-db-01:if_vethb8bc272.down.type DERIVE
onmne-db-01;onmne-db-01:if_vethb8bc272.down.graph no
onmne-db-01;onmne-db-01:if_vethb8bc272.down.update_rate 300
onmne-db-01;onmne-db-01:vmstat.graph_title VMstat
onmne-db-01;onmne-db-01:vmstat.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:vmstat.graph_vlabel process states
onmne-db-01;onmne-db-01:vmstat.graph_category processes
onmne-db-01;onmne-db-01:vmstat.graph_order wait sleep
onmne-db-01;onmne-db-01:vmstat.sleep.update_rate 300
onmne-db-01;onmne-db-01:vmstat.sleep.max 500000
onmne-db-01;onmne-db-01:vmstat.sleep.graph_data_size normal
onmne-db-01;onmne-db-01:vmstat.sleep.label I/O sleep
onmne-db-01;onmne-db-01:vmstat.sleep.type GAUGE
onmne-db-01;onmne-db-01:vmstat.wait.type GAUGE
onmne-db-01;onmne-db-01:vmstat.wait.graph_data_size normal
onmne-db-01;onmne-db-01:vmstat.wait.label running
onmne-db-01;onmne-db-01:vmstat.wait.update_rate 300
onmne-db-01;onmne-db-01:vmstat.wait.max 500000
onmne-db-01;onmne-db-01:netstat.graph_title Netstat
onmne-db-01;onmne-db-01:netstat.graph_args --base 1000 --logarithmic
onmne-db-01;onmne-db-01:netstat.graph_vlabel TCP connections
onmne-db-01;onmne-db-01:netstat.graph_category network
onmne-db-01;onmne-db-01:netstat.graph_period second
onmne-db-01;onmne-db-01:netstat.graph_info This graph shows the TCP activity of all the network interfaces combined.
onmne-db-01;onmne-db-01:netstat.graph_order active passive failed resets established
onmne-db-01;onmne-db-01:netstat.active.min 0
onmne-db-01;onmne-db-01:netstat.active.type DERIVE
onmne-db-01;onmne-db-01:netstat.active.graph_data_size normal
onmne-db-01;onmne-db-01:netstat.active.label active
onmne-db-01;onmne-db-01:netstat.active.info The number of active TCP openings per second.
onmne-db-01;onmne-db-01:netstat.active.max 50000
onmne-db-01;onmne-db-01:netstat.active.update_rate 300
onmne-db-01;onmne-db-01:netstat.resets.update_rate 300
onmne-db-01;onmne-db-01:netstat.resets.max 50000
onmne-db-01;onmne-db-01:netstat.resets.label resets
onmne-db-01;onmne-db-01:netstat.resets.info The number of TCP connection resets.
onmne-db-01;onmne-db-01:netstat.resets.graph_data_size normal
onmne-db-01;onmne-db-01:netstat.resets.type DERIVE
onmne-db-01;onmne-db-01:netstat.resets.min 0
onmne-db-01;onmne-db-01:netstat.failed.max 50000
onmne-db-01;onmne-db-01:netstat.failed.update_rate 300
onmne-db-01;onmne-db-01:netstat.failed.min 0
onmne-db-01;onmne-db-01:netstat.failed.type DERIVE
onmne-db-01;onmne-db-01:netstat.failed.graph_data_size normal
onmne-db-01;onmne-db-01:netstat.failed.label failed
onmne-db-01;onmne-db-01:netstat.failed.info The number of failed TCP connection attempts per second.
onmne-db-01;onmne-db-01:netstat.established.update_rate 300
onmne-db-01;onmne-db-01:netstat.established.max 50000
onmne-db-01;onmne-db-01:netstat.established.type GAUGE
onmne-db-01;onmne-db-01:netstat.established.graph_data_size normal
onmne-db-01;onmne-db-01:netstat.established.label established
onmne-db-01;onmne-db-01:netstat.established.info The number of currently open connections.
onmne-db-01;onmne-db-01:netstat.passive.graph_data_size normal
onmne-db-01;onmne-db-01:netstat.passive.info The number of passive TCP openings per second.
onmne-db-01;onmne-db-01:netstat.passive.label passive
onmne-db-01;onmne-db-01:netstat.passive.min 0
onmne-db-01;onmne-db-01:netstat.passive.type DERIVE
onmne-db-01;onmne-db-01:netstat.passive.max 50000
onmne-db-01;onmne-db-01:netstat.passive.update_rate 300
onmne-db-01;onmne-db-01:if_err_ens160.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-01;onmne-db-01:if_err_ens160.graph_title ens160 errors
onmne-db-01;onmne-db-01:if_err_ens160.graph_args --base 1000
onmne-db-01;onmne-db-01:if_err_ens160.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_err_ens160.graph_category network
onmne-db-01;onmne-db-01:if_err_ens160.graph_info This graph shows the amount of errors, packet drops, and collisions on the ens160 network interface.
onmne-db-01;onmne-db-01:if_err_ens160.txdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_ens160.txdrop.negative rxdrop
onmne-db-01;onmne-db-01:if_err_ens160.txdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_ens160.txdrop.label drops
onmne-db-01;onmne-db-01:if_err_ens160.txdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_ens160.rcvd.update_rate 300
onmne-db-01;onmne-db-01:if_err_ens160.rcvd.warning 1
onmne-db-01;onmne-db-01:if_err_ens160.rcvd.graph no
onmne-db-01;onmne-db-01:if_err_ens160.rcvd.type COUNTER
onmne-db-01;onmne-db-01:if_err_ens160.rcvd.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_ens160.rcvd.label errors
onmne-db-01;onmne-db-01:if_err_ens160.rxdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_ens160.rxdrop.label drops
onmne-db-01;onmne-db-01:if_err_ens160.rxdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_ens160.rxdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_ens160.rxdrop.graph no
onmne-db-01;onmne-db-01:if_err_ens160.trans.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_ens160.trans.label errors
onmne-db-01;onmne-db-01:if_err_ens160.trans.type COUNTER
onmne-db-01;onmne-db-01:if_err_ens160.trans.negative rcvd
onmne-db-01;onmne-db-01:if_err_ens160.trans.warning 1
onmne-db-01;onmne-db-01:if_err_ens160.trans.update_rate 300
onmne-db-01;onmne-db-01:if_err_ens160.collisions.update_rate 300
onmne-db-01;onmne-db-01:if_err_ens160.collisions.type COUNTER
onmne-db-01;onmne-db-01:if_err_ens160.collisions.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_ens160.collisions.label collisions
onmne-db-01;onmne-db-01:fw_packets.graph_title Firewall Throughput
onmne-db-01;onmne-db-01:fw_packets.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:fw_packets.graph_vlabel Packets/${graph_period}
onmne-db-01;onmne-db-01:fw_packets.graph_category network
onmne-db-01;onmne-db-01:fw_packets.graph_order received forwarded
onmne-db-01;onmne-db-01:fw_packets.forwarded.update_rate 300
onmne-db-01;onmne-db-01:fw_packets.forwarded.draw LINE2
onmne-db-01;onmne-db-01:fw_packets.forwarded.min 0
onmne-db-01;onmne-db-01:fw_packets.forwarded.type DERIVE
onmne-db-01;onmne-db-01:fw_packets.forwarded.label Forwarded
onmne-db-01;onmne-db-01:fw_packets.forwarded.graph_data_size normal
onmne-db-01;onmne-db-01:fw_packets.received.label Received
onmne-db-01;onmne-db-01:fw_packets.received.graph_data_size normal
onmne-db-01;onmne-db-01:fw_packets.received.type DERIVE
onmne-db-01;onmne-db-01:fw_packets.received.min 0
onmne-db-01;onmne-db-01:fw_packets.received.draw AREA
onmne-db-01;onmne-db-01:fw_packets.received.update_rate 300
onmne-db-01;onmne-db-01:if_ens160.graph_order down up down up
onmne-db-01;onmne-db-01:if_ens160.graph_title ens160 traffic
onmne-db-01;onmne-db-01:if_ens160.graph_args --base 1000
onmne-db-01;onmne-db-01:if_ens160.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_ens160.graph_category network
onmne-db-01;onmne-db-01:if_ens160.graph_info This graph shows the traffic of the ens160 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-01;onmne-db-01:if_ens160.down.graph no
onmne-db-01;onmne-db-01:if_ens160.down.max 10000000000
onmne-db-01;onmne-db-01:if_ens160.down.update_rate 300
onmne-db-01;onmne-db-01:if_ens160.down.type DERIVE
onmne-db-01;onmne-db-01:if_ens160.down.min 0
onmne-db-01;onmne-db-01:if_ens160.down.cdef down,8,*
onmne-db-01;onmne-db-01:if_ens160.down.graph_data_size normal
onmne-db-01;onmne-db-01:if_ens160.down.label received
onmne-db-01;onmne-db-01:if_ens160.up.update_rate 300
onmne-db-01;onmne-db-01:if_ens160.up.max 10000000000
onmne-db-01;onmne-db-01:if_ens160.up.negative down
onmne-db-01;onmne-db-01:if_ens160.up.type DERIVE
onmne-db-01;onmne-db-01:if_ens160.up.min 0
onmne-db-01;onmne-db-01:if_ens160.up.cdef up,8,*
onmne-db-01;onmne-db-01:if_ens160.up.graph_data_size normal
onmne-db-01;onmne-db-01:if_ens160.up.info Traffic of the ens160 interface. Maximum speed is 10000 Mb/s.
onmne-db-01;onmne-db-01:if_ens160.up.label bps
onmne-db-01;onmne-db-01:if_vethf5bf414.graph_order down up down up
onmne-db-01;onmne-db-01:if_vethf5bf414.graph_title vethf5bf414 traffic
onmne-db-01;onmne-db-01:if_vethf5bf414.graph_args --base 1000
onmne-db-01;onmne-db-01:if_vethf5bf414.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_vethf5bf414.graph_category network
onmne-db-01;onmne-db-01:if_vethf5bf414.graph_info This graph shows the traffic of the vethf5bf414 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-01;onmne-db-01:if_vethf5bf414.down.update_rate 300
onmne-db-01;onmne-db-01:if_vethf5bf414.down.graph no
onmne-db-01;onmne-db-01:if_vethf5bf414.down.graph_data_size normal
onmne-db-01;onmne-db-01:if_vethf5bf414.down.cdef down,8,*
onmne-db-01;onmne-db-01:if_vethf5bf414.down.label received
onmne-db-01;onmne-db-01:if_vethf5bf414.down.type DERIVE
onmne-db-01;onmne-db-01:if_vethf5bf414.down.min 0
onmne-db-01;onmne-db-01:if_vethf5bf414.up.type DERIVE
onmne-db-01;onmne-db-01:if_vethf5bf414.up.min 0
onmne-db-01;onmne-db-01:if_vethf5bf414.up.negative down
onmne-db-01;onmne-db-01:if_vethf5bf414.up.label bps
onmne-db-01;onmne-db-01:if_vethf5bf414.up.info Traffic of the vethf5bf414 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-01;onmne-db-01:if_vethf5bf414.up.cdef up,8,*
onmne-db-01;onmne-db-01:if_vethf5bf414.up.graph_data_size normal
onmne-db-01;onmne-db-01:if_vethf5bf414.up.update_rate 300
onmne-db-01;onmne-db-01:load.graph_title Load average
onmne-db-01;onmne-db-01:load.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:load.graph_vlabel load
onmne-db-01;onmne-db-01:load.graph_scale no
onmne-db-01;onmne-db-01:load.graph_category system
onmne-db-01;onmne-db-01:load.graph_info The load average of the machine describes how many processes are in the run-queue (scheduled to run "immediately").
onmne-db-01;onmne-db-01:load.graph_order load
onmne-db-01;onmne-db-01:load.load.graph_data_size normal
onmne-db-01;onmne-db-01:load.load.info 5 minute load average
onmne-db-01;onmne-db-01:load.load.label load
onmne-db-01;onmne-db-01:load.load.update_rate 300
onmne-db-01;onmne-db-01:irqstats.graph_title Individual interrupts
onmne-db-01;onmne-db-01:irqstats.graph_args --base 1000 --logarithmic
onmne-db-01;onmne-db-01:irqstats.graph_vlabel interrupts / ${graph_period}
onmne-db-01;onmne-db-01:irqstats.graph_category system
onmne-db-01;onmne-db-01:irqstats.graph_info Shows the number of different IRQs received by the kernel.  High disk or network traffic can cause a high number of interrupts (with good hardware and drivers this will be less so). Sudden high interrupt activity with no associated higher system activity is not normal.
onmne-db-01;onmne-db-01:irqstats.graph_order i0 i1 i8 i9 i12 i14 i15 i16 i17 i24 i25 i26 i27 i28 i29 i30 i31 i32 i33 i34 i35 i36 i37 i38 i39 i40 i41 i42 i43 i44 i45 i46 i47 i48 i49 i50 i51 i52 i53 i54 i55 i56 i57 i58 i59 i60 i61 i62 i63 i64 i65 i66 i67 iNMI iLOC iSPU iPMI iIWI iRTR iRES iCAL iTLB iTRM iTHR iDFR iMCE iMCP iERR iMIS iPIN iNPI iPIW i0 i1 i8 i9 i12 i14 i15 i16 i17 i24 i25 i26 i27 i28 i29 i30 i31 i32 i33 i34 i35 i36 i37 i38 i39 i40 i41 i42 i43 i44 i45 i46 i47 i48 i49 i50 i51 i52 i53 i54 i55 i56 i57 i58 i59 i60 i61 i62 i63 i64 i65 i66 i67 iNMI iLOC iSPU iPMI iIWI iRTR iRES iCAL iTLB iTRM iTHR iDFR iMCE iMCP iERR iMIS iPIN iNPI iPIW
onmne-db-01;onmne-db-01:irqstats.i35.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i35.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i35.min 0
onmne-db-01;onmne-db-01:irqstats.i35.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i35.label 366592-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i35.info Interrupt 35, for device(s): 366592-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i55.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i55.label 407552-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i55.info Interrupt 55, for device(s): 407552-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i55.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i55.min 0
onmne-db-01;onmne-db-01:irqstats.i55.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i29.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i29.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i29.min 0
onmne-db-01;onmne-db-01:irqstats.i29.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i29.label 354304-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i29.info Interrupt 29, for device(s): 354304-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.iERR.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iERR.label ERR
onmne-db-01;onmne-db-01:irqstats.iERR.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iERR.min 0
onmne-db-01;onmne-db-01:irqstats.iERR.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i49.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i49.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i49.min 0
onmne-db-01;onmne-db-01:irqstats.i49.info Interrupt 49, for device(s): 395264-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i49.label 395264-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i49.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i0.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i0.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i0.min 0
onmne-db-01;onmne-db-01:irqstats.i0.label 2-edge      timer
onmne-db-01;onmne-db-01:irqstats.i0.info Interrupt 0, for device(s): 2-edge      timer
onmne-db-01;onmne-db-01:irqstats.i0.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i61.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i61.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i61.info Interrupt 61, for device(s): 1572868-edge      ens160-rxtx-4
onmne-db-01;onmne-db-01:irqstats.i61.label 1572868-edge      ens160-rxtx-4
onmne-db-01;onmne-db-01:irqstats.i61.min 0
onmne-db-01;onmne-db-01:irqstats.i61.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iCAL.label Function call interrupts
onmne-db-01;onmne-db-01:irqstats.iCAL.info Interrupt CAL, for device(s): Function call interrupts
onmne-db-01;onmne-db-01:irqstats.iCAL.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iCAL.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iCAL.min 0
onmne-db-01;onmne-db-01:irqstats.iCAL.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i60.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i60.info Interrupt 60, for device(s): 1572867-edge      ens160-rxtx-3
onmne-db-01;onmne-db-01:irqstats.i60.label 1572867-edge      ens160-rxtx-3
onmne-db-01;onmne-db-01:irqstats.i60.min 0
onmne-db-01;onmne-db-01:irqstats.i60.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i60.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iTRM.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iTRM.min 0
onmne-db-01;onmne-db-01:irqstats.iTRM.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iTRM.info Interrupt TRM, for device(s): Thermal event interrupts
onmne-db-01;onmne-db-01:irqstats.iTRM.label Thermal event interrupts
onmne-db-01;onmne-db-01:irqstats.iTRM.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iSPU.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iSPU.min 0
onmne-db-01;onmne-db-01:irqstats.iSPU.info Interrupt SPU, for device(s): Spurious interrupts
onmne-db-01;onmne-db-01:irqstats.iSPU.label Spurious interrupts
onmne-db-01;onmne-db-01:irqstats.iSPU.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iSPU.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iNMI.label Non-maskable interrupts
onmne-db-01;onmne-db-01:irqstats.iNMI.info Interrupt NMI, for device(s): Non-maskable interrupts
onmne-db-01;onmne-db-01:irqstats.iNMI.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iNMI.min 0
onmne-db-01;onmne-db-01:irqstats.iNMI.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iNMI.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i26.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i26.min 0
onmne-db-01;onmne-db-01:irqstats.i26.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i26.info Interrupt 26, for device(s): 348160-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i26.label 348160-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i26.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iPIW.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iPIW.info Interrupt PIW, for device(s): Posted-interrupt wakeup event
onmne-db-01;onmne-db-01:irqstats.iPIW.label Posted-interrupt wakeup event
onmne-db-01;onmne-db-01:irqstats.iPIW.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iPIW.min 0
onmne-db-01;onmne-db-01:irqstats.iPIW.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i28.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i28.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i28.info Interrupt 28, for device(s): 352256-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i28.label 352256-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i28.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i28.min 0
onmne-db-01;onmne-db-01:irqstats.i27.label 350208-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i27.info Interrupt 27, for device(s): 350208-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i27.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i27.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i27.min 0
onmne-db-01;onmne-db-01:irqstats.i27.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i64.info Interrupt 64, for device(s): 1572871-edge      ens160-rxtx-7
onmne-db-01;onmne-db-01:irqstats.i64.label 1572871-edge      ens160-rxtx-7
onmne-db-01;onmne-db-01:irqstats.i64.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i64.min 0
onmne-db-01;onmne-db-01:irqstats.i64.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i64.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i47.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i47.min 0
onmne-db-01;onmne-db-01:irqstats.i47.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i47.label 391168-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i47.info Interrupt 47, for device(s): 391168-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i47.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i42.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i42.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i42.label 380928-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i42.info Interrupt 42, for device(s): 380928-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i42.min 0
onmne-db-01;onmne-db-01:irqstats.i42.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i48.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i48.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i48.info Interrupt 48, for device(s): 393216-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i48.label 393216-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i48.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i48.min 0
onmne-db-01;onmne-db-01:irqstats.i15.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i15.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i15.min 0
onmne-db-01;onmne-db-01:irqstats.i15.label 15-edge      ata_piix
onmne-db-01;onmne-db-01:irqstats.i15.info Interrupt 15, for device(s): 15-edge      ata_piix
onmne-db-01;onmne-db-01:irqstats.i15.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i53.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i53.info Interrupt 53, for device(s): 403456-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i53.label 403456-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i53.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i53.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i53.min 0
onmne-db-01;onmne-db-01:irqstats.i33.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i33.label 362496-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i33.info Interrupt 33, for device(s): 362496-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i33.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i33.min 0
onmne-db-01;onmne-db-01:irqstats.i33.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iPMI.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iPMI.info Interrupt PMI, for device(s): Performance monitoring interrupts
onmne-db-01;onmne-db-01:irqstats.iPMI.label Performance monitoring interrupts
onmne-db-01;onmne-db-01:irqstats.iPMI.min 0
onmne-db-01;onmne-db-01:irqstats.iPMI.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iPMI.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i46.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i46.info Interrupt 46, for device(s): 389120-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i46.label 389120-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i46.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i46.min 0
onmne-db-01;onmne-db-01:irqstats.i46.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iMIS.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iMIS.min 0
onmne-db-01;onmne-db-01:irqstats.iMIS.label MIS
onmne-db-01;onmne-db-01:irqstats.iMIS.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iMIS.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iMCP.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iMCP.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iMCP.min 0
onmne-db-01;onmne-db-01:irqstats.iMCP.info Interrupt MCP, for device(s): Machine check polls
onmne-db-01;onmne-db-01:irqstats.iMCP.label Machine check polls
onmne-db-01;onmne-db-01:irqstats.iMCP.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i34.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i34.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i34.info Interrupt 34, for device(s): 364544-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i34.label 364544-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i34.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i34.min 0
onmne-db-01;onmne-db-01:irqstats.i54.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i54.label 405504-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i54.info Interrupt 54, for device(s): 405504-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i54.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i54.min 0
onmne-db-01;onmne-db-01:irqstats.i54.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i63.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i63.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i63.label 1572870-edge      ens160-rxtx-6
onmne-db-01;onmne-db-01:irqstats.i63.info Interrupt 63, for device(s): 1572870-edge      ens160-rxtx-6
onmne-db-01;onmne-db-01:irqstats.i63.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i63.min 0
onmne-db-01;onmne-db-01:irqstats.i8.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i8.min 0
onmne-db-01;onmne-db-01:irqstats.i8.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i8.label 8-edge      rtc0
onmne-db-01;onmne-db-01:irqstats.i8.info Interrupt 8, for device(s): 8-edge      rtc0
onmne-db-01;onmne-db-01:irqstats.i8.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i65.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i65.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i65.min 0
onmne-db-01;onmne-db-01:irqstats.i65.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i65.info Interrupt 65, for device(s): 1572872-edge      ens160-event-8
onmne-db-01;onmne-db-01:irqstats.i65.label 1572872-edge      ens160-event-8
onmne-db-01;onmne-db-01:irqstats.iNPI.info Interrupt NPI, for device(s): Nested posted-interrupt event
onmne-db-01;onmne-db-01:irqstats.iNPI.label Nested posted-interrupt event
onmne-db-01;onmne-db-01:irqstats.iNPI.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iNPI.min 0
onmne-db-01;onmne-db-01:irqstats.iNPI.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iNPI.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i14.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i14.info Interrupt 14, for device(s): 14-edge      ata_piix
onmne-db-01;onmne-db-01:irqstats.i14.label 14-edge      ata_piix
onmne-db-01;onmne-db-01:irqstats.i14.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i14.min 0
onmne-db-01;onmne-db-01:irqstats.i14.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i51.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i51.label 399360-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i51.info Interrupt 51, for device(s): 399360-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i51.min 0
onmne-db-01;onmne-db-01:irqstats.i51.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i51.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i31.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i31.min 0
onmne-db-01;onmne-db-01:irqstats.i31.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i31.label 358400-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i31.info Interrupt 31, for device(s): 358400-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i31.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i50.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i50.label 397312-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i50.info Interrupt 50, for device(s): 397312-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i50.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i50.min 0
onmne-db-01;onmne-db-01:irqstats.i50.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i30.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i30.label 356352-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i30.info Interrupt 30, for device(s): 356352-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i30.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i30.min 0
onmne-db-01;onmne-db-01:irqstats.i30.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iMCE.min 0
onmne-db-01;onmne-db-01:irqstats.iMCE.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iMCE.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iMCE.label Machine check exceptions
onmne-db-01;onmne-db-01:irqstats.iMCE.info Interrupt MCE, for device(s): Machine check exceptions
onmne-db-01;onmne-db-01:irqstats.iMCE.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i56.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i56.info Interrupt 56, for device(s): 1064960-edge      ahci[0000:02:01.0]
onmne-db-01;onmne-db-01:irqstats.i56.label 1064960-edge      ahci[0000:02:01.0]
onmne-db-01;onmne-db-01:irqstats.i56.min 0
onmne-db-01;onmne-db-01:irqstats.i56.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i56.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i36.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i36.min 0
onmne-db-01;onmne-db-01:irqstats.i36.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i36.label 368640-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i36.info Interrupt 36, for device(s): 368640-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i36.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i43.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i43.min 0
onmne-db-01;onmne-db-01:irqstats.i43.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i43.label 382976-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i43.info Interrupt 43, for device(s): 382976-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i43.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i32.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i32.label 360448-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i32.info Interrupt 32, for device(s): 360448-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i32.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i32.min 0
onmne-db-01;onmne-db-01:irqstats.i32.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i52.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i52.min 0
onmne-db-01;onmne-db-01:irqstats.i52.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i52.label 401408-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i52.info Interrupt 52, for device(s): 401408-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i52.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iTHR.min 0
onmne-db-01;onmne-db-01:irqstats.iTHR.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iTHR.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iTHR.label Threshold APIC interrupts
onmne-db-01;onmne-db-01:irqstats.iTHR.info Interrupt THR, for device(s): Threshold APIC interrupts
onmne-db-01;onmne-db-01:irqstats.iTHR.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i58.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i58.min 0
onmne-db-01;onmne-db-01:irqstats.i58.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i58.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i58.label 1572865-edge      ens160-rxtx-1
onmne-db-01;onmne-db-01:irqstats.i58.info Interrupt 58, for device(s): 1572865-edge      ens160-rxtx-1
onmne-db-01;onmne-db-01:irqstats.i38.info Interrupt 38, for device(s): 372736-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i38.label 372736-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i38.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i38.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i38.min 0
onmne-db-01;onmne-db-01:irqstats.i38.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i57.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i57.min 0
onmne-db-01;onmne-db-01:irqstats.i57.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i57.info Interrupt 57, for device(s): 1572864-edge      ens160-rxtx-0
onmne-db-01;onmne-db-01:irqstats.i57.label 1572864-edge      ens160-rxtx-0
onmne-db-01;onmne-db-01:irqstats.i57.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i37.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i37.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i37.min 0
onmne-db-01;onmne-db-01:irqstats.i37.label 370688-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i37.info Interrupt 37, for device(s): 370688-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i37.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i12.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i12.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i12.min 0
onmne-db-01;onmne-db-01:irqstats.i12.label 12-edge      i8042
onmne-db-01;onmne-db-01:irqstats.i12.info Interrupt 12, for device(s): 12-edge      i8042
onmne-db-01;onmne-db-01:irqstats.i12.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i17.min 0
onmne-db-01;onmne-db-01:irqstats.i17.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i17.info Interrupt 17, for device(s): 17-fasteoi   ioc0
onmne-db-01;onmne-db-01:irqstats.i17.label 17-fasteoi   ioc0
onmne-db-01;onmne-db-01:irqstats.i17.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i17.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iIWI.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iIWI.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iIWI.info Interrupt IWI, for device(s): IRQ work interrupts
onmne-db-01;onmne-db-01:irqstats.iIWI.label IRQ work interrupts
onmne-db-01;onmne-db-01:irqstats.iIWI.min 0
onmne-db-01;onmne-db-01:irqstats.iIWI.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i16.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i16.min 0
onmne-db-01;onmne-db-01:irqstats.i16.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i16.info Interrupt 16, for device(s): 16-fasteoi   vmwgfx
onmne-db-01;onmne-db-01:irqstats.i16.label 16-fasteoi   vmwgfx
onmne-db-01;onmne-db-01:irqstats.i16.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i45.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i45.min 0
onmne-db-01;onmne-db-01:irqstats.i45.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i45.info Interrupt 45, for device(s): 387072-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i45.label 387072-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i45.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i25.info Interrupt 25, for device(s): 346112-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i25.label 346112-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i25.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i25.min 0
onmne-db-01;onmne-db-01:irqstats.i25.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i25.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i9.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i9.min 0
onmne-db-01;onmne-db-01:irqstats.i9.label 9-fasteoi   acpi
onmne-db-01;onmne-db-01:irqstats.i9.info Interrupt 9, for device(s): 9-fasteoi   acpi
onmne-db-01;onmne-db-01:irqstats.i9.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i9.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i39.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i39.min 0
onmne-db-01;onmne-db-01:irqstats.i39.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i39.label 374784-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i39.info Interrupt 39, for device(s): 374784-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i39.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iDFR.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iDFR.label Deferred Error APIC interrupts
onmne-db-01;onmne-db-01:irqstats.iDFR.info Interrupt DFR, for device(s): Deferred Error APIC interrupts
onmne-db-01;onmne-db-01:irqstats.iDFR.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iDFR.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iDFR.min 0
onmne-db-01;onmne-db-01:irqstats.i59.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i59.min 0
onmne-db-01;onmne-db-01:irqstats.i59.info Interrupt 59, for device(s): 1572866-edge      ens160-rxtx-2
onmne-db-01;onmne-db-01:irqstats.i59.label 1572866-edge      ens160-rxtx-2
onmne-db-01;onmne-db-01:irqstats.i59.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i59.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iPIN.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iPIN.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iPIN.label Posted-interrupt notification event
onmne-db-01;onmne-db-01:irqstats.iPIN.info Interrupt PIN, for device(s): Posted-interrupt notification event
onmne-db-01;onmne-db-01:irqstats.iPIN.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iPIN.min 0
onmne-db-01;onmne-db-01:irqstats.i1.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i1.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i1.info Interrupt 1, for device(s): 1-edge      i8042
onmne-db-01;onmne-db-01:irqstats.i1.label 1-edge      i8042
onmne-db-01;onmne-db-01:irqstats.i1.min 0
onmne-db-01;onmne-db-01:irqstats.i1.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iRTR.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iRTR.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iRTR.min 0
onmne-db-01;onmne-db-01:irqstats.iRTR.label APIC ICR read retries
onmne-db-01;onmne-db-01:irqstats.iRTR.info Interrupt RTR, for device(s): APIC ICR read retries
onmne-db-01;onmne-db-01:irqstats.iRTR.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i40.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i40.label 376832-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i40.info Interrupt 40, for device(s): 376832-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i40.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i40.min 0
onmne-db-01;onmne-db-01:irqstats.i40.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i41.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i41.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i41.min 0
onmne-db-01;onmne-db-01:irqstats.i41.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i41.info Interrupt 41, for device(s): 378880-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i41.label 378880-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i44.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i44.info Interrupt 44, for device(s): 385024-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i44.label 385024-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i44.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i44.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i44.min 0
onmne-db-01;onmne-db-01:irqstats.iRES.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iRES.min 0
onmne-db-01;onmne-db-01:irqstats.iRES.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iRES.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iRES.label Rescheduling interrupts
onmne-db-01;onmne-db-01:irqstats.iRES.info Interrupt RES, for device(s): Rescheduling interrupts
onmne-db-01;onmne-db-01:irqstats.iLOC.update_rate 300
onmne-db-01;onmne-db-01:irqstats.iLOC.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iLOC.min 0
onmne-db-01;onmne-db-01:irqstats.iLOC.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iLOC.label Local timer interrupts
onmne-db-01;onmne-db-01:irqstats.iLOC.info Interrupt LOC, for device(s): Local timer interrupts
onmne-db-01;onmne-db-01:irqstats.i66.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i66.min 0
onmne-db-01;onmne-db-01:irqstats.i66.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i66.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i66.label 129024-edge      vmw_vmci
onmne-db-01;onmne-db-01:irqstats.i66.info Interrupt 66, for device(s): 129024-edge      vmw_vmci
onmne-db-01;onmne-db-01:irqstats.iTLB.label TLB shootdowns
onmne-db-01;onmne-db-01:irqstats.iTLB.info Interrupt TLB, for device(s): TLB shootdowns
onmne-db-01;onmne-db-01:irqstats.iTLB.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.iTLB.type DERIVE
onmne-db-01;onmne-db-01:irqstats.iTLB.min 0
onmne-db-01;onmne-db-01:irqstats.iTLB.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i62.min 0
onmne-db-01;onmne-db-01:irqstats.i62.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i62.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i62.label 1572869-edge      ens160-rxtx-5
onmne-db-01;onmne-db-01:irqstats.i62.info Interrupt 62, for device(s): 1572869-edge      ens160-rxtx-5
onmne-db-01;onmne-db-01:irqstats.i62.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i24.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i24.info Interrupt 24, for device(s): 344064-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i24.label 344064-edge      PCIe PME, pciehp
onmne-db-01;onmne-db-01:irqstats.i24.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i24.min 0
onmne-db-01;onmne-db-01:irqstats.i24.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i67.update_rate 300
onmne-db-01;onmne-db-01:irqstats.i67.label 129025-edge      vmw_vmci
onmne-db-01;onmne-db-01:irqstats.i67.info Interrupt 67, for device(s): 129025-edge      vmw_vmci
onmne-db-01;onmne-db-01:irqstats.i67.graph_data_size normal
onmne-db-01;onmne-db-01:irqstats.i67.type DERIVE
onmne-db-01;onmne-db-01:irqstats.i67.min 0
onmne-db-01;onmne-db-01:if_veth0b4eccf.graph_order down up down up
onmne-db-01;onmne-db-01:if_veth0b4eccf.graph_title veth0b4eccf traffic
onmne-db-01;onmne-db-01:if_veth0b4eccf.graph_args --base 1000
onmne-db-01;onmne-db-01:if_veth0b4eccf.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_veth0b4eccf.graph_category network
onmne-db-01;onmne-db-01:if_veth0b4eccf.graph_info This graph shows the traffic of the veth0b4eccf network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-01;onmne-db-01:if_veth0b4eccf.up.graph_data_size normal
onmne-db-01;onmne-db-01:if_veth0b4eccf.up.cdef up,8,*
onmne-db-01;onmne-db-01:if_veth0b4eccf.up.info Traffic of the veth0b4eccf interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-01;onmne-db-01:if_veth0b4eccf.up.label bps
onmne-db-01;onmne-db-01:if_veth0b4eccf.up.min 0
onmne-db-01;onmne-db-01:if_veth0b4eccf.up.type DERIVE
onmne-db-01;onmne-db-01:if_veth0b4eccf.up.negative down
onmne-db-01;onmne-db-01:if_veth0b4eccf.up.update_rate 300
onmne-db-01;onmne-db-01:if_veth0b4eccf.down.update_rate 300
onmne-db-01;onmne-db-01:if_veth0b4eccf.down.graph no
onmne-db-01;onmne-db-01:if_veth0b4eccf.down.graph_data_size normal
onmne-db-01;onmne-db-01:if_veth0b4eccf.down.cdef down,8,*
onmne-db-01;onmne-db-01:if_veth0b4eccf.down.label received
onmne-db-01;onmne-db-01:if_veth0b4eccf.down.min 0
onmne-db-01;onmne-db-01:if_veth0b4eccf.down.type DERIVE
onmne-db-01;onmne-db-01:cpu.graph_title CPU usage
onmne-db-01;onmne-db-01:cpu.graph_order system user nice idle iowait irq softirq system user nice idle iowait irq softirq steal guest
onmne-db-01;onmne-db-01:cpu.graph_args --base 1000 -r --lower-limit 0 --upper-limit 800
onmne-db-01;onmne-db-01:cpu.graph_vlabel %
onmne-db-01;onmne-db-01:cpu.graph_scale no
onmne-db-01;onmne-db-01:cpu.graph_info This graph shows how CPU time is spent.
onmne-db-01;onmne-db-01:cpu.graph_category system
onmne-db-01;onmne-db-01:cpu.graph_period second
onmne-db-01;onmne-db-01:cpu.steal.graph_data_size normal
onmne-db-01;onmne-db-01:cpu.steal.label steal
onmne-db-01;onmne-db-01:cpu.steal.info The time that a virtual CPU had runnable tasks, but the virtual CPU itself was not running
onmne-db-01;onmne-db-01:cpu.steal.type DERIVE
onmne-db-01;onmne-db-01:cpu.steal.min 0
onmne-db-01;onmne-db-01:cpu.steal.update_rate 300
onmne-db-01;onmne-db-01:cpu.steal.draw STACK
onmne-db-01;onmne-db-01:cpu.idle.draw STACK
onmne-db-01;onmne-db-01:cpu.idle.update_rate 300
onmne-db-01;onmne-db-01:cpu.idle.min 0
onmne-db-01;onmne-db-01:cpu.idle.type DERIVE
onmne-db-01;onmne-db-01:cpu.idle.label idle
onmne-db-01;onmne-db-01:cpu.idle.info Idle CPU time
onmne-db-01;onmne-db-01:cpu.idle.graph_data_size normal
onmne-db-01;onmne-db-01:cpu.softirq.draw STACK
onmne-db-01;onmne-db-01:cpu.softirq.update_rate 300
onmne-db-01;onmne-db-01:cpu.softirq.min 0
onmne-db-01;onmne-db-01:cpu.softirq.type DERIVE
onmne-db-01;onmne-db-01:cpu.softirq.graph_data_size normal
onmne-db-01;onmne-db-01:cpu.softirq.label softirq
onmne-db-01;onmne-db-01:cpu.softirq.info CPU time spent handling "batched" interrupts
onmne-db-01;onmne-db-01:cpu.user.graph_data_size normal
onmne-db-01;onmne-db-01:cpu.user.info CPU time spent by normal programs and daemons
onmne-db-01;onmne-db-01:cpu.user.label user
onmne-db-01;onmne-db-01:cpu.user.min 0
onmne-db-01;onmne-db-01:cpu.user.type DERIVE
onmne-db-01;onmne-db-01:cpu.user.update_rate 300
onmne-db-01;onmne-db-01:cpu.user.draw STACK
onmne-db-01;onmne-db-01:cpu.nice.draw STACK
onmne-db-01;onmne-db-01:cpu.nice.update_rate 300
onmne-db-01;onmne-db-01:cpu.nice.info CPU time spent by nice(1)d programs
onmne-db-01;onmne-db-01:cpu.nice.label nice
onmne-db-01;onmne-db-01:cpu.nice.graph_data_size normal
onmne-db-01;onmne-db-01:cpu.nice.type DERIVE
onmne-db-01;onmne-db-01:cpu.nice.min 0
onmne-db-01;onmne-db-01:cpu.iowait.type DERIVE
onmne-db-01;onmne-db-01:cpu.iowait.min 0
onmne-db-01;onmne-db-01:cpu.iowait.label iowait
onmne-db-01;onmne-db-01:cpu.iowait.info CPU time spent waiting for I/O operations to finish when there is nothing else to do.
onmne-db-01;onmne-db-01:cpu.iowait.graph_data_size normal
onmne-db-01;onmne-db-01:cpu.iowait.update_rate 300
onmne-db-01;onmne-db-01:cpu.iowait.draw STACK
onmne-db-01;onmne-db-01:cpu.guest.update_rate 300
onmne-db-01;onmne-db-01:cpu.guest.draw STACK
onmne-db-01;onmne-db-01:cpu.guest.type DERIVE
onmne-db-01;onmne-db-01:cpu.guest.min 0
onmne-db-01;onmne-db-01:cpu.guest.label guest
onmne-db-01;onmne-db-01:cpu.guest.info The time spent running a virtual CPU for guest operating systems under the control of the Linux kernel.
onmne-db-01;onmne-db-01:cpu.guest.graph_data_size normal
onmne-db-01;onmne-db-01:cpu.system.type DERIVE
onmne-db-01;onmne-db-01:cpu.system.min 0
onmne-db-01;onmne-db-01:cpu.system.graph_data_size normal
onmne-db-01;onmne-db-01:cpu.system.label system
onmne-db-01;onmne-db-01:cpu.system.info CPU time spent by the kernel in system activities
onmne-db-01;onmne-db-01:cpu.system.update_rate 300
onmne-db-01;onmne-db-01:cpu.system.draw AREA
onmne-db-01;onmne-db-01:cpu.irq.draw STACK
onmne-db-01;onmne-db-01:cpu.irq.update_rate 300
onmne-db-01;onmne-db-01:cpu.irq.info CPU time spent handling interrupts
onmne-db-01;onmne-db-01:cpu.irq.label irq
onmne-db-01;onmne-db-01:cpu.irq.graph_data_size normal
onmne-db-01;onmne-db-01:cpu.irq.min 0
onmne-db-01;onmne-db-01:cpu.irq.type DERIVE
onmne-db-01;onmne-db-01:memory.graph_args --base 1024 -l 0 --upper-limit 33676906496
onmne-db-01;onmne-db-01:memory.graph_vlabel Bytes
onmne-db-01;onmne-db-01:memory.graph_title Memory usage
onmne-db-01;onmne-db-01:memory.graph_category system
onmne-db-01;onmne-db-01:memory.graph_info This graph shows what the machine uses memory for.
onmne-db-01;onmne-db-01:memory.graph_order apps page_tables swap_cache slab cached buffers free swap apps buffers swap cached free slab swap_cache page_tables vmalloc_used committed mapped active inactive
onmne-db-01;onmne-db-01:memory.committed.label committed
onmne-db-01;onmne-db-01:memory.committed.info The amount of memory allocated to programs. Overcommitting is normal, but may indicate memory leaks.
onmne-db-01;onmne-db-01:memory.committed.graph_data_size normal
onmne-db-01;onmne-db-01:memory.committed.draw LINE2
onmne-db-01;onmne-db-01:memory.committed.update_rate 300
onmne-db-01;onmne-db-01:memory.swap.graph_data_size normal
onmne-db-01;onmne-db-01:memory.swap.label swap
onmne-db-01;onmne-db-01:memory.swap.info Swap space used.
onmne-db-01;onmne-db-01:memory.swap.draw STACK
onmne-db-01;onmne-db-01:memory.swap.update_rate 300
onmne-db-01;onmne-db-01:memory.active.draw LINE2
onmne-db-01;onmne-db-01:memory.active.update_rate 300
onmne-db-01;onmne-db-01:memory.active.graph_data_size normal
onmne-db-01;onmne-db-01:memory.active.label active
onmne-db-01;onmne-db-01:memory.active.info Memory recently used. Not reclaimed unless absolutely necessary.
onmne-db-01;onmne-db-01:memory.mapped.label mapped
onmne-db-01;onmne-db-01:memory.mapped.info All mmap()ed pages.
onmne-db-01;onmne-db-01:memory.mapped.graph_data_size normal
onmne-db-01;onmne-db-01:memory.mapped.update_rate 300
onmne-db-01;onmne-db-01:memory.mapped.draw LINE2
onmne-db-01;onmne-db-01:memory.inactive.info Memory not currently used.
onmne-db-01;onmne-db-01:memory.inactive.label inactive
onmne-db-01;onmne-db-01:memory.inactive.graph_data_size normal
onmne-db-01;onmne-db-01:memory.inactive.update_rate 300
onmne-db-01;onmne-db-01:memory.inactive.draw LINE2
onmne-db-01;onmne-db-01:memory.swap_cache.update_rate 300
onmne-db-01;onmne-db-01:memory.swap_cache.draw STACK
onmne-db-01;onmne-db-01:memory.swap_cache.graph_data_size normal
onmne-db-01;onmne-db-01:memory.swap_cache.label swap_cache
onmne-db-01;onmne-db-01:memory.swap_cache.info A piece of memory that keeps track of pages that have been fetched from swap but not yet been modified.
onmne-db-01;onmne-db-01:memory.page_tables.update_rate 300
onmne-db-01;onmne-db-01:memory.page_tables.draw STACK
onmne-db-01;onmne-db-01:memory.page_tables.graph_data_size normal
onmne-db-01;onmne-db-01:memory.page_tables.info Memory used to map between virtual and physical memory addresses.
onmne-db-01;onmne-db-01:memory.page_tables.label page_tables
onmne-db-01;onmne-db-01:memory.apps.graph_data_size normal
onmne-db-01;onmne-db-01:memory.apps.info Memory used by user-space applications.
onmne-db-01;onmne-db-01:memory.apps.label apps
onmne-db-01;onmne-db-01:memory.apps.draw AREA
onmne-db-01;onmne-db-01:memory.apps.update_rate 300
onmne-db-01;onmne-db-01:memory.buffers.draw STACK
onmne-db-01;onmne-db-01:memory.buffers.update_rate 300
onmne-db-01;onmne-db-01:memory.buffers.label buffers
onmne-db-01;onmne-db-01:memory.buffers.info Block device (e.g. harddisk) cache. Also where "dirty" blocks are stored until written.
onmne-db-01;onmne-db-01:memory.buffers.graph_data_size normal
onmne-db-01;onmne-db-01:memory.vmalloc_used.graph_data_size normal
onmne-db-01;onmne-db-01:memory.vmalloc_used.info 'VMalloc' (kernel) memory used
onmne-db-01;onmne-db-01:memory.vmalloc_used.label vmalloc_used
onmne-db-01;onmne-db-01:memory.vmalloc_used.draw LINE2
onmne-db-01;onmne-db-01:memory.vmalloc_used.update_rate 300
onmne-db-01;onmne-db-01:memory.cached.graph_data_size normal
onmne-db-01;onmne-db-01:memory.cached.label cache
onmne-db-01;onmne-db-01:memory.cached.info Parked file data (file content) cache.
onmne-db-01;onmne-db-01:memory.cached.draw STACK
onmne-db-01;onmne-db-01:memory.cached.update_rate 300
onmne-db-01;onmne-db-01:memory.free.label unused
onmne-db-01;onmne-db-01:memory.free.info Wasted memory. Memory that is not used for anything at all.
onmne-db-01;onmne-db-01:memory.free.graph_data_size normal
onmne-db-01;onmne-db-01:memory.free.update_rate 300
onmne-db-01;onmne-db-01:memory.free.draw STACK
onmne-db-01;onmne-db-01:memory.slab.draw STACK
onmne-db-01;onmne-db-01:memory.slab.update_rate 300
onmne-db-01;onmne-db-01:memory.slab.label slab_cache
onmne-db-01;onmne-db-01:memory.slab.info Memory used by the kernel (major users  are caches like inode, dentry, etc).
onmne-db-01;onmne-db-01:memory.slab.graph_data_size normal
onmne-db-01;onmne-db-01:forks.graph_title Fork rate
onmne-db-01;onmne-db-01:forks.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:forks.graph_vlabel forks / ${graph_period}
onmne-db-01;onmne-db-01:forks.graph_category processes
onmne-db-01;onmne-db-01:forks.graph_info This graph shows the number of forks (new processes started) per second.
onmne-db-01;onmne-db-01:forks.graph_order forks
onmne-db-01;onmne-db-01:forks.forks.graph_data_size normal
onmne-db-01;onmne-db-01:forks.forks.info The number of forks per second.
onmne-db-01;onmne-db-01:forks.forks.label forks
onmne-db-01;onmne-db-01:forks.forks.min 0
onmne-db-01;onmne-db-01:forks.forks.type DERIVE
onmne-db-01;onmne-db-01:forks.forks.max 100000
onmne-db-01;onmne-db-01:forks.forks.update_rate 300
onmne-db-01;onmne-db-01:entropy.graph_title Available entropy
onmne-db-01;onmne-db-01:entropy.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:entropy.graph_vlabel entropy (bytes)
onmne-db-01;onmne-db-01:entropy.graph_scale no
onmne-db-01;onmne-db-01:entropy.graph_category system
onmne-db-01;onmne-db-01:entropy.graph_info This graph shows the amount of entropy available in the system.
onmne-db-01;onmne-db-01:entropy.graph_order entropy
onmne-db-01;onmne-db-01:entropy.entropy.update_rate 300
onmne-db-01;onmne-db-01:entropy.entropy.graph_data_size normal
onmne-db-01;onmne-db-01:entropy.entropy.info The number of random bytes available. This is typically used by cryptographic applications.
onmne-db-01;onmne-db-01:entropy.entropy.label entropy
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.graph_title veth0b4eccf errors
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.graph_args --base 1000
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.graph_category network
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth0b4eccf network interface.
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.rxdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.rxdrop.label drops
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.rxdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.rxdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.rxdrop.graph no
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.trans.type COUNTER
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.trans.negative rcvd
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.trans.label errors
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.trans.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.trans.update_rate 300
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.trans.warning 1
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.collisions.update_rate 300
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.collisions.type COUNTER
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.collisions.label collisions
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.collisions.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.txdrop.negative rxdrop
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.txdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.txdrop.label drops
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.txdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.txdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.rcvd.graph no
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.rcvd.warning 1
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.rcvd.update_rate 300
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.rcvd.label errors
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.rcvd.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_veth0b4eccf.rcvd.type COUNTER
onmne-db-01;onmne-db-01:if_br_159aada718b7.graph_order down up down up
onmne-db-01;onmne-db-01:if_br_159aada718b7.graph_title br-159aada718b7 traffic
onmne-db-01;onmne-db-01:if_br_159aada718b7.graph_args --base 1000
onmne-db-01;onmne-db-01:if_br_159aada718b7.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_br_159aada718b7.graph_category network
onmne-db-01;onmne-db-01:if_br_159aada718b7.graph_info This graph shows the traffic of the br-159aada718b7 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-01;onmne-db-01:if_br_159aada718b7.up.info Traffic of the br-159aada718b7 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-01;onmne-db-01:if_br_159aada718b7.up.label bps
onmne-db-01;onmne-db-01:if_br_159aada718b7.up.cdef up,8,*
onmne-db-01;onmne-db-01:if_br_159aada718b7.up.graph_data_size normal
onmne-db-01;onmne-db-01:if_br_159aada718b7.up.type DERIVE
onmne-db-01;onmne-db-01:if_br_159aada718b7.up.min 0
onmne-db-01;onmne-db-01:if_br_159aada718b7.up.negative down
onmne-db-01;onmne-db-01:if_br_159aada718b7.up.update_rate 300
onmne-db-01;onmne-db-01:if_br_159aada718b7.down.graph no
onmne-db-01;onmne-db-01:if_br_159aada718b7.down.update_rate 300
onmne-db-01;onmne-db-01:if_br_159aada718b7.down.label received
onmne-db-01;onmne-db-01:if_br_159aada718b7.down.cdef down,8,*
onmne-db-01;onmne-db-01:if_br_159aada718b7.down.graph_data_size normal
onmne-db-01;onmne-db-01:if_br_159aada718b7.down.min 0
onmne-db-01;onmne-db-01:if_br_159aada718b7.down.type DERIVE
onmne-db-01;onmne-db-01:swap.graph_title Swap in/out
onmne-db-01;onmne-db-01:swap.graph_args -l 0 --base 1000
onmne-db-01;onmne-db-01:swap.graph_vlabel pages per ${graph_period} in (-) / out (+)
onmne-db-01;onmne-db-01:swap.graph_category system
onmne-db-01;onmne-db-01:swap.graph_order swap_in swap_out
onmne-db-01;onmne-db-01:swap.swap_out.max 100000
onmne-db-01;onmne-db-01:swap.swap_out.update_rate 300
onmne-db-01;onmne-db-01:swap.swap_out.graph_data_size normal
onmne-db-01;onmne-db-01:swap.swap_out.label swap
onmne-db-01;onmne-db-01:swap.swap_out.type DERIVE
onmne-db-01;onmne-db-01:swap.swap_out.negative swap_in
onmne-db-01;onmne-db-01:swap.swap_out.min 0
onmne-db-01;onmne-db-01:swap.swap_in.max 100000
onmne-db-01;onmne-db-01:swap.swap_in.graph no
onmne-db-01;onmne-db-01:swap.swap_in.update_rate 300
onmne-db-01;onmne-db-01:swap.swap_in.type DERIVE
onmne-db-01;onmne-db-01:swap.swap_in.min 0
onmne-db-01;onmne-db-01:swap.swap_in.graph_data_size normal
onmne-db-01;onmne-db-01:swap.swap_in.label swap
onmne-db-01;onmne-db-01:if_err_vethf5bf414.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-01;onmne-db-01:if_err_vethf5bf414.graph_title vethf5bf414 errors
onmne-db-01;onmne-db-01:if_err_vethf5bf414.graph_args --base 1000
onmne-db-01;onmne-db-01:if_err_vethf5bf414.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_err_vethf5bf414.graph_category network
onmne-db-01;onmne-db-01:if_err_vethf5bf414.graph_info This graph shows the amount of errors, packet drops, and collisions on the vethf5bf414 network interface.
onmne-db-01;onmne-db-01:if_err_vethf5bf414.txdrop.negative rxdrop
onmne-db-01;onmne-db-01:if_err_vethf5bf414.txdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_vethf5bf414.txdrop.label drops
onmne-db-01;onmne-db-01:if_err_vethf5bf414.txdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_vethf5bf414.txdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_vethf5bf414.rcvd.update_rate 300
onmne-db-01;onmne-db-01:if_err_vethf5bf414.rcvd.warning 1
onmne-db-01;onmne-db-01:if_err_vethf5bf414.rcvd.graph no
onmne-db-01;onmne-db-01:if_err_vethf5bf414.rcvd.label errors
onmne-db-01;onmne-db-01:if_err_vethf5bf414.rcvd.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_vethf5bf414.rcvd.type COUNTER
onmne-db-01;onmne-db-01:if_err_vethf5bf414.rxdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_vethf5bf414.rxdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_vethf5bf414.rxdrop.label drops
onmne-db-01;onmne-db-01:if_err_vethf5bf414.rxdrop.graph no
onmne-db-01;onmne-db-01:if_err_vethf5bf414.rxdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_vethf5bf414.trans.warning 1
onmne-db-01;onmne-db-01:if_err_vethf5bf414.trans.update_rate 300
onmne-db-01;onmne-db-01:if_err_vethf5bf414.trans.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_vethf5bf414.trans.label errors
onmne-db-01;onmne-db-01:if_err_vethf5bf414.trans.negative rcvd
onmne-db-01;onmne-db-01:if_err_vethf5bf414.trans.type COUNTER
onmne-db-01;onmne-db-01:if_err_vethf5bf414.collisions.type COUNTER
onmne-db-01;onmne-db-01:if_err_vethf5bf414.collisions.update_rate 300
onmne-db-01;onmne-db-01:if_err_vethf5bf414.collisions.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_vethf5bf414.collisions.label collisions
onmne-db-01;onmne-db-01:open_files.graph_title File table usage
onmne-db-01;onmne-db-01:open_files.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:open_files.graph_vlabel number of open files
onmne-db-01;onmne-db-01:open_files.graph_category system
onmne-db-01;onmne-db-01:open_files.graph_info This graph monitors the Linux open files table.
onmne-db-01;onmne-db-01:open_files.graph_order used max
onmne-db-01;onmne-db-01:open_files.used.info The number of currently open files.
onmne-db-01;onmne-db-01:open_files.used.label open files
onmne-db-01;onmne-db-01:open_files.used.graph_data_size normal
onmne-db-01;onmne-db-01:open_files.used.critical 9038904596117680128
onmne-db-01;onmne-db-01:open_files.used.warning 8485502273906394112
onmne-db-01;onmne-db-01:open_files.used.update_rate 300
onmne-db-01;onmne-db-01:open_files.max.update_rate 300
onmne-db-01;onmne-db-01:open_files.max.graph_data_size normal
onmne-db-01;onmne-db-01:open_files.max.info The maximum supported number of open files. Tune by modifying /proc/sys/fs/file-max.
onmne-db-01;onmne-db-01:open_files.max.label max open files
onmne-db-01;onmne-db-01:if_err_docker0.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-01;onmne-db-01:if_err_docker0.graph_title docker0 errors
onmne-db-01;onmne-db-01:if_err_docker0.graph_args --base 1000
onmne-db-01;onmne-db-01:if_err_docker0.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_err_docker0.graph_category network
onmne-db-01;onmne-db-01:if_err_docker0.graph_info This graph shows the amount of errors, packet drops, and collisions on the docker0 network interface.
onmne-db-01;onmne-db-01:if_err_docker0.collisions.type COUNTER
onmne-db-01;onmne-db-01:if_err_docker0.collisions.update_rate 300
onmne-db-01;onmne-db-01:if_err_docker0.collisions.label collisions
onmne-db-01;onmne-db-01:if_err_docker0.collisions.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_docker0.rxdrop.label drops
onmne-db-01;onmne-db-01:if_err_docker0.rxdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_docker0.rxdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_docker0.rxdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_docker0.rxdrop.graph no
onmne-db-01;onmne-db-01:if_err_docker0.trans.label errors
onmne-db-01;onmne-db-01:if_err_docker0.trans.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_docker0.trans.type COUNTER
onmne-db-01;onmne-db-01:if_err_docker0.trans.negative rcvd
onmne-db-01;onmne-db-01:if_err_docker0.trans.update_rate 300
onmne-db-01;onmne-db-01:if_err_docker0.trans.warning 1
onmne-db-01;onmne-db-01:if_err_docker0.rcvd.warning 1
onmne-db-01;onmne-db-01:if_err_docker0.rcvd.update_rate 300
onmne-db-01;onmne-db-01:if_err_docker0.rcvd.graph no
onmne-db-01;onmne-db-01:if_err_docker0.rcvd.type COUNTER
onmne-db-01;onmne-db-01:if_err_docker0.rcvd.label errors
onmne-db-01;onmne-db-01:if_err_docker0.rcvd.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_docker0.txdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_docker0.txdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_docker0.txdrop.negative rxdrop
onmne-db-01;onmne-db-01:if_err_docker0.txdrop.label drops
onmne-db-01;onmne-db-01:if_err_docker0.txdrop.graph_data_size normal
onmne-db-01;onmne-db-01:interrupts.graph_title Interrupts and context switches
onmne-db-01;onmne-db-01:interrupts.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:interrupts.graph_vlabel interrupts & ctx switches / ${graph_period}
onmne-db-01;onmne-db-01:interrupts.graph_category system
onmne-db-01;onmne-db-01:interrupts.graph_info This graph shows the number of interrupts and context switches on the system. These are typically high on a busy system.
onmne-db-01;onmne-db-01:interrupts.graph_order intr ctx
onmne-db-01;onmne-db-01:interrupts.intr.graph_data_size normal
onmne-db-01;onmne-db-01:interrupts.intr.info Interrupts are events that alter sequence of instructions executed by a processor. They can come from either hardware (exceptions, NMI, IRQ) or software.
onmne-db-01;onmne-db-01:interrupts.intr.label interrupts
onmne-db-01;onmne-db-01:interrupts.intr.type DERIVE
onmne-db-01;onmne-db-01:interrupts.intr.min 0
onmne-db-01;onmne-db-01:interrupts.intr.max 100000
onmne-db-01;onmne-db-01:interrupts.intr.update_rate 300
onmne-db-01;onmne-db-01:interrupts.ctx.min 0
onmne-db-01;onmne-db-01:interrupts.ctx.type DERIVE
onmne-db-01;onmne-db-01:interrupts.ctx.label context switches
onmne-db-01;onmne-db-01:interrupts.ctx.info A context switch occurs when a multitasking operatings system suspends the currently running process, and starts executing another.
onmne-db-01;onmne-db-01:interrupts.ctx.graph_data_size normal
onmne-db-01;onmne-db-01:interrupts.ctx.update_rate 300
onmne-db-01;onmne-db-01:interrupts.ctx.max 100000
onmne-db-01;onmne-db-01:df.graph_title Disk usage in percent
onmne-db-01;onmne-db-01:df.graph_args --upper-limit 100 -l 0
onmne-db-01;onmne-db-01:df.graph_vlabel %
onmne-db-01;onmne-db-01:df.graph_scale no
onmne-db-01;onmne-db-01:df.graph_category disk
onmne-db-01;onmne-db-01:df.graph_order overlay _dev _sys_fs_cgroup shm _dev_mapper_ubuntu_vL _rootfs_dev_shm _rootfs_run _rootfs_run_lock _dev_sda1
onmne-db-01;onmne-db-01:df._sys_fs_cgroup.warning 92
onmne-db-01;onmne-db-01:df._sys_fs_cgroup.update_rate 300
onmne-db-01;onmne-db-01:df._sys_fs_cgroup.critical 98
onmne-db-01;onmne-db-01:df._sys_fs_cgroup.graph_data_size normal
onmne-db-01;onmne-db-01:df._sys_fs_cgroup.label /sys/fs/cgroup
onmne-db-01;onmne-db-01:df._rootfs_run_lock.graph_data_size normal
onmne-db-01;onmne-db-01:df._rootfs_run_lock.label /rootfs/run/lock
onmne-db-01;onmne-db-01:df._rootfs_run_lock.critical 98
onmne-db-01;onmne-db-01:df._rootfs_run_lock.warning 92
onmne-db-01;onmne-db-01:df._rootfs_run_lock.update_rate 300
onmne-db-01;onmne-db-01:df.shm.critical 98
onmne-db-01;onmne-db-01:df.shm.warning 92
onmne-db-01;onmne-db-01:df.shm.update_rate 300
onmne-db-01;onmne-db-01:df.shm.label /dev/shm
onmne-db-01;onmne-db-01:df.shm.graph_data_size normal
onmne-db-01;onmne-db-01:df._dev_mapper_ubuntu_vL.graph_data_size normal
onmne-db-01;onmne-db-01:df._dev_mapper_ubuntu_vL.label /rootfs
onmne-db-01;onmne-db-01:df._dev_mapper_ubuntu_vL.update_rate 300
onmne-db-01;onmne-db-01:df._dev_mapper_ubuntu_vL.warning 92
onmne-db-01;onmne-db-01:df._dev_mapper_ubuntu_vL.critical 98
onmne-db-01;onmne-db-01:df._dev_sda1.graph_data_size normal
onmne-db-01;onmne-db-01:df._dev_sda1.label /rootfs/boot
onmne-db-01;onmne-db-01:df._dev_sda1.critical 98
onmne-db-01;onmne-db-01:df._dev_sda1.warning 92
onmne-db-01;onmne-db-01:df._dev_sda1.update_rate 300
onmne-db-01;onmne-db-01:df.overlay.critical 98
onmne-db-01;onmne-db-01:df.overlay.update_rate 300
onmne-db-01;onmne-db-01:df.overlay.warning 92
onmne-db-01;onmne-db-01:df.overlay.label /
onmne-db-01;onmne-db-01:df.overlay.graph_data_size normal
onmne-db-01;onmne-db-01:df._rootfs_run.critical 98
onmne-db-01;onmne-db-01:df._rootfs_run.update_rate 300
onmne-db-01;onmne-db-01:df._rootfs_run.warning 92
onmne-db-01;onmne-db-01:df._rootfs_run.graph_data_size normal
onmne-db-01;onmne-db-01:df._rootfs_run.label /rootfs/run
onmne-db-01;onmne-db-01:df._rootfs_dev_shm.graph_data_size normal
onmne-db-01;onmne-db-01:df._rootfs_dev_shm.label /rootfs/dev/shm
onmne-db-01;onmne-db-01:df._rootfs_dev_shm.warning 92
onmne-db-01;onmne-db-01:df._rootfs_dev_shm.update_rate 300
onmne-db-01;onmne-db-01:df._rootfs_dev_shm.critical 98
onmne-db-01;onmne-db-01:df._dev.graph_data_size normal
onmne-db-01;onmne-db-01:df._dev.label /dev
onmne-db-01;onmne-db-01:df._dev.update_rate 300
onmne-db-01;onmne-db-01:df._dev.warning 92
onmne-db-01;onmne-db-01:df._dev.critical 98
onmne-db-01;onmne-db-01:df_inode.graph_title Inode usage in percent
onmne-db-01;onmne-db-01:df_inode.graph_args --upper-limit 100 -l 0
onmne-db-01;onmne-db-01:df_inode.graph_vlabel %
onmne-db-01;onmne-db-01:df_inode.graph_scale no
onmne-db-01;onmne-db-01:df_inode.graph_category disk
onmne-db-01;onmne-db-01:df_inode.graph_order overlay _dev _sys_fs_cgroup shm _dev_mapper_ubuntu_vL _rootfs_dev _rootfs_dev_shm _rootfs_run _rootfs_run_lock _dev_sda1
onmne-db-01;onmne-db-01:df_inode._dev_mapper_ubuntu_vL.graph_data_size normal
onmne-db-01;onmne-db-01:df_inode._dev_mapper_ubuntu_vL.label /rootfs
onmne-db-01;onmne-db-01:df_inode._dev_mapper_ubuntu_vL.critical 98
onmne-db-01;onmne-db-01:df_inode._dev_mapper_ubuntu_vL.update_rate 300
onmne-db-01;onmne-db-01:df_inode._dev_mapper_ubuntu_vL.warning 92
onmne-db-01;onmne-db-01:df_inode._rootfs_dev.label /rootfs/dev
onmne-db-01;onmne-db-01:df_inode._rootfs_dev.graph_data_size normal
onmne-db-01;onmne-db-01:df_inode._rootfs_dev.update_rate 300
onmne-db-01;onmne-db-01:df_inode._rootfs_dev.warning 92
onmne-db-01;onmne-db-01:df_inode._rootfs_dev.critical 98
onmne-db-01;onmne-db-01:df_inode.overlay.label /
onmne-db-01;onmne-db-01:df_inode.overlay.graph_data_size normal
onmne-db-01;onmne-db-01:df_inode.overlay.update_rate 300
onmne-db-01;onmne-db-01:df_inode.overlay.warning 92
onmne-db-01;onmne-db-01:df_inode.overlay.critical 98
onmne-db-01;onmne-db-01:df_inode._dev_sda1.warning 92
onmne-db-01;onmne-db-01:df_inode._dev_sda1.update_rate 300
onmne-db-01;onmne-db-01:df_inode._dev_sda1.critical 98
onmne-db-01;onmne-db-01:df_inode._dev_sda1.graph_data_size normal
onmne-db-01;onmne-db-01:df_inode._dev_sda1.label /rootfs/boot
onmne-db-01;onmne-db-01:df_inode._rootfs_run.label /rootfs/run
onmne-db-01;onmne-db-01:df_inode._rootfs_run.graph_data_size normal
onmne-db-01;onmne-db-01:df_inode._rootfs_run.critical 98
onmne-db-01;onmne-db-01:df_inode._rootfs_run.update_rate 300
onmne-db-01;onmne-db-01:df_inode._rootfs_run.warning 92
onmne-db-01;onmne-db-01:df_inode._dev.label /dev
onmne-db-01;onmne-db-01:df_inode._dev.graph_data_size normal
onmne-db-01;onmne-db-01:df_inode._dev.update_rate 300
onmne-db-01;onmne-db-01:df_inode._dev.warning 92
onmne-db-01;onmne-db-01:df_inode._dev.critical 98
onmne-db-01;onmne-db-01:df_inode._rootfs_dev_shm.critical 98
onmne-db-01;onmne-db-01:df_inode._rootfs_dev_shm.warning 92
onmne-db-01;onmne-db-01:df_inode._rootfs_dev_shm.update_rate 300
onmne-db-01;onmne-db-01:df_inode._rootfs_dev_shm.label /rootfs/dev/shm
onmne-db-01;onmne-db-01:df_inode._rootfs_dev_shm.graph_data_size normal
onmne-db-01;onmne-db-01:df_inode._sys_fs_cgroup.label /sys/fs/cgroup
onmne-db-01;onmne-db-01:df_inode._sys_fs_cgroup.graph_data_size normal
onmne-db-01;onmne-db-01:df_inode._sys_fs_cgroup.warning 92
onmne-db-01;onmne-db-01:df_inode._sys_fs_cgroup.update_rate 300
onmne-db-01;onmne-db-01:df_inode._sys_fs_cgroup.critical 98
onmne-db-01;onmne-db-01:df_inode._rootfs_run_lock.critical 98
onmne-db-01;onmne-db-01:df_inode._rootfs_run_lock.update_rate 300
onmne-db-01;onmne-db-01:df_inode._rootfs_run_lock.warning 92
onmne-db-01;onmne-db-01:df_inode._rootfs_run_lock.label /rootfs/run/lock
onmne-db-01;onmne-db-01:df_inode._rootfs_run_lock.graph_data_size normal
onmne-db-01;onmne-db-01:df_inode.shm.critical 98
onmne-db-01;onmne-db-01:df_inode.shm.update_rate 300
onmne-db-01;onmne-db-01:df_inode.shm.warning 92
onmne-db-01;onmne-db-01:df_inode.shm.graph_data_size normal
onmne-db-01;onmne-db-01:df_inode.shm.label /dev/shm
onmne-db-01;onmne-db-01:open_inodes.graph_title Inode table usage
onmne-db-01;onmne-db-01:open_inodes.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:open_inodes.graph_vlabel number of open inodes
onmne-db-01;onmne-db-01:open_inodes.graph_category system
onmne-db-01;onmne-db-01:open_inodes.graph_info This graph monitors the Linux open inode table.
onmne-db-01;onmne-db-01:open_inodes.graph_order used max
onmne-db-01;onmne-db-01:open_inodes.max.update_rate 300
onmne-db-01;onmne-db-01:open_inodes.max.info The size of the system inode table. This is dynamically adjusted by the kernel.
onmne-db-01;onmne-db-01:open_inodes.max.label inode table size
onmne-db-01;onmne-db-01:open_inodes.max.graph_data_size normal
onmne-db-01;onmne-db-01:open_inodes.used.update_rate 300
onmne-db-01;onmne-db-01:open_inodes.used.graph_data_size normal
onmne-db-01;onmne-db-01:open_inodes.used.info The number of currently open inodes.
onmne-db-01;onmne-db-01:open_inodes.used.label open inodes
onmne-db-01;onmne-db-01:if_err_vethb8bc272.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-01;onmne-db-01:if_err_vethb8bc272.graph_title vethb8bc272 errors
onmne-db-01;onmne-db-01:if_err_vethb8bc272.graph_args --base 1000
onmne-db-01;onmne-db-01:if_err_vethb8bc272.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_err_vethb8bc272.graph_category network
onmne-db-01;onmne-db-01:if_err_vethb8bc272.graph_info This graph shows the amount of errors, packet drops, and collisions on the vethb8bc272 network interface.
onmne-db-01;onmne-db-01:if_err_vethb8bc272.txdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_vethb8bc272.txdrop.label drops
onmne-db-01;onmne-db-01:if_err_vethb8bc272.txdrop.negative rxdrop
onmne-db-01;onmne-db-01:if_err_vethb8bc272.txdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_vethb8bc272.txdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_vethb8bc272.rcvd.label errors
onmne-db-01;onmne-db-01:if_err_vethb8bc272.rcvd.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_vethb8bc272.rcvd.type COUNTER
onmne-db-01;onmne-db-01:if_err_vethb8bc272.rcvd.warning 1
onmne-db-01;onmne-db-01:if_err_vethb8bc272.rcvd.update_rate 300
onmne-db-01;onmne-db-01:if_err_vethb8bc272.rcvd.graph no
onmne-db-01;onmne-db-01:if_err_vethb8bc272.rxdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_vethb8bc272.rxdrop.graph no
onmne-db-01;onmne-db-01:if_err_vethb8bc272.rxdrop.label drops
onmne-db-01;onmne-db-01:if_err_vethb8bc272.rxdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_vethb8bc272.rxdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_vethb8bc272.trans.update_rate 300
onmne-db-01;onmne-db-01:if_err_vethb8bc272.trans.warning 1
onmne-db-01;onmne-db-01:if_err_vethb8bc272.trans.negative rcvd
onmne-db-01;onmne-db-01:if_err_vethb8bc272.trans.type COUNTER
onmne-db-01;onmne-db-01:if_err_vethb8bc272.trans.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_vethb8bc272.trans.label errors
onmne-db-01;onmne-db-01:if_err_vethb8bc272.collisions.update_rate 300
onmne-db-01;onmne-db-01:if_err_vethb8bc272.collisions.type COUNTER
onmne-db-01;onmne-db-01:if_err_vethb8bc272.collisions.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_vethb8bc272.collisions.label collisions
onmne-db-01;onmne-db-01:users.graph_title Logged in users
onmne-db-01;onmne-db-01:users.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:users.graph_vlabel Users
onmne-db-01;onmne-db-01:users.graph_scale no
onmne-db-01;onmne-db-01:users.graph_category system
onmne-db-01;onmne-db-01:users.graph_printf %3.0lf
onmne-db-01;onmne-db-01:users.graph_order tty pty pts X other
onmne-db-01;onmne-db-01:users.pts.graph_data_size normal
onmne-db-01;onmne-db-01:users.pts.label pts
onmne-db-01;onmne-db-01:users.pts.draw AREASTACK
onmne-db-01;onmne-db-01:users.pts.colour 00FFFF
onmne-db-01;onmne-db-01:users.pts.update_rate 300
onmne-db-01;onmne-db-01:users.other.colour FF0000
onmne-db-01;onmne-db-01:users.other.update_rate 300
onmne-db-01;onmne-db-01:users.other.graph_data_size normal
onmne-db-01;onmne-db-01:users.other.label Other users
onmne-db-01;onmne-db-01:users.other.info Users logged in by indeterminate method
onmne-db-01;onmne-db-01:users.pty.draw AREASTACK
onmne-db-01;onmne-db-01:users.pty.update_rate 300
onmne-db-01;onmne-db-01:users.pty.colour 0000FF
onmne-db-01;onmne-db-01:users.pty.label pty
onmne-db-01;onmne-db-01:users.pty.graph_data_size normal
onmne-db-01;onmne-db-01:users.X.update_rate 300
onmne-db-01;onmne-db-01:users.X.colour 000000
onmne-db-01;onmne-db-01:users.X.draw AREASTACK
onmne-db-01;onmne-db-01:users.X.info Users logged in on an X display
onmne-db-01;onmne-db-01:users.X.label X displays
onmne-db-01;onmne-db-01:users.X.graph_data_size normal
onmne-db-01;onmne-db-01:users.tty.label tty
onmne-db-01;onmne-db-01:users.tty.graph_data_size normal
onmne-db-01;onmne-db-01:users.tty.draw AREASTACK
onmne-db-01;onmne-db-01:users.tty.update_rate 300
onmne-db-01;onmne-db-01:users.tty.colour 00FF00
onmne-db-01;onmne-db-01:processes.graph_title Processes
onmne-db-01;onmne-db-01:processes.graph_info This graph shows the number of processes
onmne-db-01;onmne-db-01:processes.graph_category processes
onmne-db-01;onmne-db-01:processes.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:processes.graph_vlabel Number of processes
onmne-db-01;onmne-db-01:processes.graph_order sleeping stopped zombie dead paging uninterruptible runnable processes dead paging sleeping uninterruptible zombie stopped runnable processes
onmne-db-01;onmne-db-01:processes.processes.label total
onmne-db-01;onmne-db-01:processes.processes.info The total number of processes.
onmne-db-01;onmne-db-01:processes.processes.graph_data_size normal
onmne-db-01;onmne-db-01:processes.processes.update_rate 300
onmne-db-01;onmne-db-01:processes.processes.colour c0c0c0
onmne-db-01;onmne-db-01:processes.processes.draw LINE1
onmne-db-01;onmne-db-01:processes.dead.info The number of dead processes.
onmne-db-01;onmne-db-01:processes.dead.label dead
onmne-db-01;onmne-db-01:processes.dead.graph_data_size normal
onmne-db-01;onmne-db-01:processes.dead.update_rate 300
onmne-db-01;onmne-db-01:processes.dead.colour ff0000
onmne-db-01;onmne-db-01:processes.dead.draw STACK
onmne-db-01;onmne-db-01:processes.stopped.update_rate 300
onmne-db-01;onmne-db-01:processes.stopped.colour cc0000
onmne-db-01;onmne-db-01:processes.stopped.draw STACK
onmne-db-01;onmne-db-01:processes.stopped.info The number of stopped or traced processes.
onmne-db-01;onmne-db-01:processes.stopped.label stopped
onmne-db-01;onmne-db-01:processes.stopped.graph_data_size normal
onmne-db-01;onmne-db-01:processes.paging.label paging
onmne-db-01;onmne-db-01:processes.paging.info The number of paging processes (<2.6 kernels only).
onmne-db-01;onmne-db-01:processes.paging.graph_data_size normal
onmne-db-01;onmne-db-01:processes.paging.update_rate 300
onmne-db-01;onmne-db-01:processes.paging.colour 00aaaa
onmne-db-01;onmne-db-01:processes.paging.draw STACK
onmne-db-01;onmne-db-01:processes.runnable.label runnable
onmne-db-01;onmne-db-01:processes.runnable.info The number of runnable processes (on the run queue).
onmne-db-01;onmne-db-01:processes.runnable.graph_data_size normal
onmne-db-01;onmne-db-01:processes.runnable.update_rate 300
onmne-db-01;onmne-db-01:processes.runnable.colour 22ff22
onmne-db-01;onmne-db-01:processes.runnable.draw STACK
onmne-db-01;onmne-db-01:processes.uninterruptible.graph_data_size normal
onmne-db-01;onmne-db-01:processes.uninterruptible.label uninterruptible
onmne-db-01;onmne-db-01:processes.uninterruptible.info The number of uninterruptible processes (usually IO).
onmne-db-01;onmne-db-01:processes.uninterruptible.draw STACK
onmne-db-01;onmne-db-01:processes.uninterruptible.colour ffa500
onmne-db-01;onmne-db-01:processes.uninterruptible.update_rate 300
onmne-db-01;onmne-db-01:processes.zombie.update_rate 300
onmne-db-01;onmne-db-01:processes.zombie.colour 990000
onmne-db-01;onmne-db-01:processes.zombie.draw STACK
onmne-db-01;onmne-db-01:processes.zombie.label zombie
onmne-db-01;onmne-db-01:processes.zombie.info The number of defunct (zombie) processes (process terminated and parent not waiting).
onmne-db-01;onmne-db-01:processes.zombie.graph_data_size normal
onmne-db-01;onmne-db-01:processes.sleeping.colour 0022ff
onmne-db-01;onmne-db-01:processes.sleeping.update_rate 300
onmne-db-01;onmne-db-01:processes.sleeping.draw AREA
onmne-db-01;onmne-db-01:processes.sleeping.graph_data_size normal
onmne-db-01;onmne-db-01:processes.sleeping.label sleeping
onmne-db-01;onmne-db-01:processes.sleeping.info The number of sleeping processes.
onmne-db-01;onmne-db-01:threads.graph_title Number of threads
onmne-db-01;onmne-db-01:threads.graph_vlabel number of threads
onmne-db-01;onmne-db-01:threads.graph_category processes
onmne-db-01;onmne-db-01:threads.graph_info This graph shows the number of threads.
onmne-db-01;onmne-db-01:threads.graph_order threads
onmne-db-01;onmne-db-01:threads.threads.graph_data_size normal
onmne-db-01;onmne-db-01:threads.threads.info The current number of threads.
onmne-db-01;onmne-db-01:threads.threads.label threads
onmne-db-01;onmne-db-01:threads.threads.update_rate 300
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.graph_title br-e7900838fff1 errors
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.graph_args --base 1000
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.graph_category network
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.graph_info This graph shows the amount of errors, packet drops, and collisions on the br-e7900838fff1 network interface.
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.collisions.update_rate 300
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.collisions.type COUNTER
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.collisions.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.collisions.label collisions
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.rxdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.rxdrop.label drops
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.rxdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.rxdrop.graph no
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.rxdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.trans.warning 1
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.trans.update_rate 300
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.trans.label errors
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.trans.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.trans.negative rcvd
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.trans.type COUNTER
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.rcvd.label errors
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.rcvd.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.rcvd.type COUNTER
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.rcvd.warning 1
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.rcvd.update_rate 300
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.rcvd.graph no
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.txdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.txdrop.negative rxdrop
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.txdrop.label drops
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.txdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_br_e7900838fff1.txdrop.update_rate 300
onmne-db-01;onmne-db-01:if_docker0.graph_order down up down up
onmne-db-01;onmne-db-01:if_docker0.graph_title docker0 traffic
onmne-db-01;onmne-db-01:if_docker0.graph_args --base 1000
onmne-db-01;onmne-db-01:if_docker0.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_docker0.graph_category network
onmne-db-01;onmne-db-01:if_docker0.graph_info This graph shows the traffic of the docker0 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-01;onmne-db-01:if_docker0.down.graph no
onmne-db-01;onmne-db-01:if_docker0.down.update_rate 300
onmne-db-01;onmne-db-01:if_docker0.down.min 0
onmne-db-01;onmne-db-01:if_docker0.down.type DERIVE
onmne-db-01;onmne-db-01:if_docker0.down.cdef down,8,*
onmne-db-01;onmne-db-01:if_docker0.down.graph_data_size normal
onmne-db-01;onmne-db-01:if_docker0.down.label received
onmne-db-01;onmne-db-01:if_docker0.up.graph_data_size normal
onmne-db-01;onmne-db-01:if_docker0.up.cdef up,8,*
onmne-db-01;onmne-db-01:if_docker0.up.info Traffic of the docker0 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-01;onmne-db-01:if_docker0.up.label bps
onmne-db-01;onmne-db-01:if_docker0.up.min 0
onmne-db-01;onmne-db-01:if_docker0.up.type DERIVE
onmne-db-01;onmne-db-01:if_docker0.up.negative down
onmne-db-01;onmne-db-01:if_docker0.up.update_rate 300
onmne-db-01;onmne-db-01:munin_stats.graph_title Munin processing time
onmne-db-01;onmne-db-01:munin_stats.graph_info This graph shows the run time of the four different processes making up a munin-master run.  Munin-master is run from cron every 5 minutes and we want each of the programmes in munin-master to complete before the next instance starts.  Especially munin-update and munin-graph are time consuming and their run time bears watching. If munin-update uses too long time to run please see the munin-update graph to determine which host is slowing it down.  If munin-graph is running too slow you need to get clever (email the munin-users mailing list) unless you can buy a faster computer with better disks to run munin on.
onmne-db-01;onmne-db-01:munin_stats.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:munin_stats.graph_scale yes
onmne-db-01;onmne-db-01:munin_stats.graph_vlabel seconds
onmne-db-01;onmne-db-01:munin_stats.graph_category munin
onmne-db-01;onmne-db-01:munin_stats.graph_order update graph html limits
onmne-db-01;onmne-db-01:munin_stats.graph.label munin graph
onmne-db-01;onmne-db-01:munin_stats.graph.graph_data_size normal
onmne-db-01;onmne-db-01:munin_stats.graph.critical 285
onmne-db-01;onmne-db-01:munin_stats.graph.draw AREASTACK
onmne-db-01;onmne-db-01:munin_stats.graph.warning 240
onmne-db-01;onmne-db-01:munin_stats.graph.update_rate 300
onmne-db-01;onmne-db-01:munin_stats.update.label munin update
onmne-db-01;onmne-db-01:munin_stats.update.graph_data_size normal
onmne-db-01;onmne-db-01:munin_stats.update.critical 285
onmne-db-01;onmne-db-01:munin_stats.update.draw AREASTACK
onmne-db-01;onmne-db-01:munin_stats.update.warning 240
onmne-db-01;onmne-db-01:munin_stats.update.update_rate 300
onmne-db-01;onmne-db-01:munin_stats.html.graph_data_size normal
onmne-db-01;onmne-db-01:munin_stats.html.label munin html
onmne-db-01;onmne-db-01:munin_stats.html.update_rate 300
onmne-db-01;onmne-db-01:munin_stats.html.draw AREASTACK
onmne-db-01;onmne-db-01:munin_stats.limits.draw AREASTACK
onmne-db-01;onmne-db-01:munin_stats.limits.update_rate 300
onmne-db-01;onmne-db-01:munin_stats.limits.label munin limits
onmne-db-01;onmne-db-01:munin_stats.limits.graph_data_size normal
onmne-db-01;onmne-db-01:proc_pri.graph_title Processes priority
onmne-db-01;onmne-db-01:proc_pri.graph_order low high locked high low locked
onmne-db-01;onmne-db-01:proc_pri.graph_category processes
onmne-db-01;onmne-db-01:proc_pri.graph_info This graph shows number of processes at each priority
onmne-db-01;onmne-db-01:proc_pri.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:proc_pri.graph_vlabel Number of processes
onmne-db-01;onmne-db-01:proc_pri.low.update_rate 300
onmne-db-01;onmne-db-01:proc_pri.low.draw AREA
onmne-db-01;onmne-db-01:proc_pri.low.graph_data_size normal
onmne-db-01;onmne-db-01:proc_pri.low.info The number of low-priority processes (tasks)
onmne-db-01;onmne-db-01:proc_pri.low.label low priority
onmne-db-01;onmne-db-01:proc_pri.high.label high priority
onmne-db-01;onmne-db-01:proc_pri.high.info The number of high-priority processes (tasks)
onmne-db-01;onmne-db-01:proc_pri.high.graph_data_size normal
onmne-db-01;onmne-db-01:proc_pri.high.draw STACK
onmne-db-01;onmne-db-01:proc_pri.high.update_rate 300
onmne-db-01;onmne-db-01:proc_pri.locked.info The number of processes that have pages locked into memory (for real-time and custom IO)
onmne-db-01;onmne-db-01:proc_pri.locked.label locked in memory
onmne-db-01;onmne-db-01:proc_pri.locked.graph_data_size normal
onmne-db-01;onmne-db-01:proc_pri.locked.update_rate 300
onmne-db-01;onmne-db-01:proc_pri.locked.draw STACK
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.graph_title br-159aada718b7 errors
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.graph_args --base 1000
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.graph_category network
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.graph_info This graph shows the amount of errors, packet drops, and collisions on the br-159aada718b7 network interface.
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.trans.update_rate 300
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.trans.warning 1
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.trans.label errors
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.trans.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.trans.negative rcvd
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.trans.type COUNTER
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.rxdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.rxdrop.label drops
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.rxdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.rxdrop.graph no
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.rxdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.collisions.update_rate 300
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.collisions.type COUNTER
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.collisions.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.collisions.label collisions
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.txdrop.update_rate 300
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.txdrop.graph_data_size normal
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.txdrop.label drops
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.txdrop.negative rxdrop
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.txdrop.type COUNTER
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.rcvd.update_rate 300
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.rcvd.warning 1
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.rcvd.graph no
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.rcvd.type COUNTER
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.rcvd.label errors
onmne-db-01;onmne-db-01:if_err_br_159aada718b7.rcvd.graph_data_size normal
onmne-db-01;onmne-db-01:uptime.graph_title Uptime
onmne-db-01;onmne-db-01:uptime.graph_args --base 1000 -l 0
onmne-db-01;onmne-db-01:uptime.graph_scale no
onmne-db-01;onmne-db-01:uptime.graph_vlabel uptime in days
onmne-db-01;onmne-db-01:uptime.graph_category system
onmne-db-01;onmne-db-01:uptime.graph_order uptime
onmne-db-01;onmne-db-01:uptime.uptime.update_rate 300
onmne-db-01;onmne-db-01:uptime.uptime.draw AREA
onmne-db-01;onmne-db-01:uptime.uptime.label uptime
onmne-db-01;onmne-db-01:uptime.uptime.graph_data_size normal
onmne-db-01;onmne-db-01:if_br_e7900838fff1.graph_order down up down up
onmne-db-01;onmne-db-01:if_br_e7900838fff1.graph_title br-e7900838fff1 traffic
onmne-db-01;onmne-db-01:if_br_e7900838fff1.graph_args --base 1000
onmne-db-01;onmne-db-01:if_br_e7900838fff1.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-01;onmne-db-01:if_br_e7900838fff1.graph_category network
onmne-db-01;onmne-db-01:if_br_e7900838fff1.graph_info This graph shows the traffic of the br-e7900838fff1 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-01;onmne-db-01:if_br_e7900838fff1.down.label received
onmne-db-01;onmne-db-01:if_br_e7900838fff1.down.cdef down,8,*
onmne-db-01;onmne-db-01:if_br_e7900838fff1.down.graph_data_size normal
onmne-db-01;onmne-db-01:if_br_e7900838fff1.down.type DERIVE
onmne-db-01;onmne-db-01:if_br_e7900838fff1.down.min 0
onmne-db-01;onmne-db-01:if_br_e7900838fff1.down.update_rate 300
onmne-db-01;onmne-db-01:if_br_e7900838fff1.down.graph no
onmne-db-01;onmne-db-01:if_br_e7900838fff1.up.update_rate 300
onmne-db-01;onmne-db-01:if_br_e7900838fff1.up.min 0
onmne-db-01;onmne-db-01:if_br_e7900838fff1.up.type DERIVE
onmne-db-01;onmne-db-01:if_br_e7900838fff1.up.negative down
onmne-db-01;onmne-db-01:if_br_e7900838fff1.up.graph_data_size normal
onmne-db-01;onmne-db-01:if_br_e7900838fff1.up.cdef up,8,*
onmne-db-01;onmne-db-01:if_br_e7900838fff1.up.info Traffic of the br-e7900838fff1 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-01;onmne-db-01:if_br_e7900838fff1.up.label bps
onmne-fr-01;localhost:diskstats_iops.loop7.graph_title IOs for /dev/loop7
onmne-fr-01;localhost:diskstats_iops.loop7.graph_args --base 1000
onmne-fr-01;localhost:diskstats_iops.loop7.graph_vlabel Units read (-) / write (+)
onmne-fr-01;localhost:diskstats_iops.loop7.graph_category disk
onmne-fr-01;localhost:diskstats_iops.loop7.graph_info This graph shows the number of IO operations pr second and the average size of these requests.  Lots of small requests should result in in lower throughput (separate graph) and higher service time (separate graph).  Please note that starting with munin-node 2.0 the divisor for K is 1000 instead of 1024 which it was prior to 2.0 beta 3.  This is because the base for this graph is 1000 not 1024.
onmne-fr-01;localhost:diskstats_iops.loop7.graph_order rdio wrio avgrdrqsz avgwrrqsz
onmne-fr-01;localhost:diskstats_iops.loop7.avgwrrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop7.avgwrrqsz.label Req Size (KB)
onmne-fr-01;localhost:diskstats_iops.loop7.avgwrrqsz.info Average Request Size in kilobytes (1000 based)
onmne-fr-01;localhost:diskstats_iops.loop7.avgwrrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop7.avgwrrqsz.negative avgrdrqsz
onmne-fr-01;localhost:diskstats_iops.loop7.avgwrrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop7.avgwrrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop7.avgwrrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop7.avgrdrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop7.avgrdrqsz.graph no
onmne-fr-01;localhost:diskstats_iops.loop7.avgrdrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop7.avgrdrqsz.label dummy
onmne-fr-01;localhost:diskstats_iops.loop7.avgrdrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop7.avgrdrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop7.avgrdrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop7.rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop7.rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop7.rdio.label dummy
onmne-fr-01;localhost:diskstats_iops.loop7.rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop7.rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop7.rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop7.rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop7.wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop7.wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop7.wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop7.wrio.label IO/sec
onmne-fr-01;localhost:diskstats_iops.loop7.wrio.negative rdio
onmne-fr-01;localhost:diskstats_iops.loop7.wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop7.wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop1.graph_title IOs for /dev/loop1
onmne-fr-01;localhost:diskstats_iops.loop1.graph_args --base 1000
onmne-fr-01;localhost:diskstats_iops.loop1.graph_vlabel Units read (-) / write (+)
onmne-fr-01;localhost:diskstats_iops.loop1.graph_category disk
onmne-fr-01;localhost:diskstats_iops.loop1.graph_info This graph shows the number of IO operations pr second and the average size of these requests.  Lots of small requests should result in in lower throughput (separate graph) and higher service time (separate graph).  Please note that starting with munin-node 2.0 the divisor for K is 1000 instead of 1024 which it was prior to 2.0 beta 3.  This is because the base for this graph is 1000 not 1024.
onmne-fr-01;localhost:diskstats_iops.loop1.graph_order rdio wrio avgrdrqsz avgwrrqsz
onmne-fr-01;localhost:diskstats_iops.loop1.wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop1.wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop1.wrio.negative rdio
onmne-fr-01;localhost:diskstats_iops.loop1.wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop1.wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop1.wrio.label IO/sec
onmne-fr-01;localhost:diskstats_iops.loop1.wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop1.rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop1.rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop1.rdio.label dummy
onmne-fr-01;localhost:diskstats_iops.loop1.rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop1.rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop1.rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop1.rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop1.avgrdrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop1.avgrdrqsz.graph no
onmne-fr-01;localhost:diskstats_iops.loop1.avgrdrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop1.avgrdrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop1.avgrdrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop1.avgrdrqsz.label dummy
onmne-fr-01;localhost:diskstats_iops.loop1.avgrdrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop1.avgwrrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop1.avgwrrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop1.avgwrrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop1.avgwrrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop1.avgwrrqsz.negative avgrdrqsz
onmne-fr-01;localhost:diskstats_iops.loop1.avgwrrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop1.avgwrrqsz.info Average Request Size in kilobytes (1000 based)
onmne-fr-01;localhost:diskstats_iops.loop1.avgwrrqsz.label Req Size (KB)
onmne-fr-01;localhost:uptime.graph_title Uptime
onmne-fr-01;localhost:uptime.graph_args --base 1000 -l 0
onmne-fr-01;localhost:uptime.graph_scale no
onmne-fr-01;localhost:uptime.graph_vlabel uptime in days
onmne-fr-01;localhost:uptime.graph_category system
onmne-fr-01;localhost:uptime.graph_order uptime
onmne-fr-01;localhost:uptime.uptime.update_rate 300
onmne-fr-01;localhost:uptime.uptime.draw AREA
onmne-fr-01;localhost:uptime.uptime.label uptime
onmne-fr-01;localhost:uptime.uptime.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop3.graph_title Average latency for /dev/loop3
onmne-fr-01;localhost:diskstats_latency.loop3.graph_args --base 1000 --logarithmic
onmne-fr-01;localhost:diskstats_latency.loop3.graph_vlabel seconds
onmne-fr-01;localhost:diskstats_latency.loop3.graph_category disk
onmne-fr-01;localhost:diskstats_latency.loop3.graph_info This graph shows average waiting time/latency for different categories of disk operations.   The times that include the queue times indicate how busy your system is.  If the waiting time hits 1 second then your I/O system is 100% busy.
onmne-fr-01;localhost:diskstats_latency.loop3.graph_order svctm avgwait avgrdwait avgwrwait
onmne-fr-01;localhost:diskstats_latency.loop3.avgrdwait.label Read IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop3.avgrdwait.info Average wait time for a read I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop3.avgrdwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop3.avgrdwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop3.avgrdwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop3.avgrdwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop3.avgrdwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop3.avgrdwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop3.avgwrwait.info Average wait time for a write I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop3.avgwrwait.label Write IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop3.avgwrwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop3.avgwrwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop3.avgwrwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop3.avgwrwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop3.avgwrwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop3.avgwrwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop3.avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop3.avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop3.avgwait.label IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop3.avgwait.info Average wait time for an I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop3.avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop3.avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop3.avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop3.svctm.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop3.svctm.min 0
onmne-fr-01;localhost:diskstats_latency.loop3.svctm.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop3.svctm.info Average time an I/O takes on the block device not including any queue times, just the round trip time for the disk request.
onmne-fr-01;localhost:diskstats_latency.loop3.svctm.label Device IO time
onmne-fr-01;localhost:diskstats_latency.loop3.svctm.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop3.svctm.update_rate 300
onmne-fr-01;localhost:threads.graph_title Number of threads
onmne-fr-01;localhost:threads.graph_vlabel number of threads
onmne-fr-01;localhost:threads.graph_category processes
onmne-fr-01;localhost:threads.graph_info This graph shows the number of threads.
onmne-fr-01;localhost:threads.graph_order threads
onmne-fr-01;localhost:threads.threads.graph_data_size normal
onmne-fr-01;localhost:threads.threads.label threads
onmne-fr-01;localhost:threads.threads.info The current number of threads.
onmne-fr-01;localhost:threads.threads.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop5.graph_title Disk throughput for /dev/loop5
onmne-fr-01;localhost:diskstats_throughput.loop5.graph_args --base 1024
onmne-fr-01;localhost:diskstats_throughput.loop5.graph_vlabel Pr ${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_throughput.loop5.graph_category disk
onmne-fr-01;localhost:diskstats_throughput.loop5.graph_info This graph shows disk throughput in bytes pr ${graph_period}.  The graph base is 1024 so KB is for Kibi bytes and so on.
onmne-fr-01;localhost:diskstats_throughput.loop5.graph_order rdbytes wrbytes
onmne-fr-01;localhost:diskstats_throughput.loop5.rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop5.rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop5.rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop5.rdbytes.label invisible
onmne-fr-01;localhost:diskstats_throughput.loop5.rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop5.rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop5.rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop5.wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop5.wrbytes.label Bytes
onmne-fr-01;localhost:diskstats_throughput.loop5.wrbytes.negative rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop5.wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop5.wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop5.wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop5.wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.dm_0.graph_title Disk utilization for /dev/dm-0
onmne-fr-01;localhost:diskstats_utilization.dm_0.graph_args --base 1000 --lower-limit 0 --upper-limit 100 --rigid
onmne-fr-01;localhost:diskstats_utilization.dm_0.graph_vlabel % busy
onmne-fr-01;localhost:diskstats_utilization.dm_0.graph_category disk
onmne-fr-01;localhost:diskstats_utilization.dm_0.graph_scale no
onmne-fr-01;localhost:diskstats_utilization.dm_0.graph_order util
onmne-fr-01;localhost:diskstats_utilization.dm_0.util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.dm_0.util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.dm_0.util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.dm_0.util.info Utilization of the device in percent. If the time spent for I/O is close to 1000msec for a given second, the device is nearly 100% saturated.
onmne-fr-01;localhost:diskstats_utilization.dm_0.util.label Utilization
onmne-fr-01;localhost:diskstats_utilization.dm_0.util.min 0
onmne-fr-01;localhost:diskstats_utilization.dm_0.util.type GAUGE
onmne-fr-01;localhost:df.graph_title Disk usage in percent
onmne-fr-01;localhost:df.graph_args --upper-limit 100 -l 0
onmne-fr-01;localhost:df.graph_vlabel %
onmne-fr-01;localhost:df.graph_scale no
onmne-fr-01;localhost:df.graph_category disk
onmne-fr-01;localhost:df.graph_order overlay _dev _sys_fs_cgroup shm _dev_mapper_ubuntu_vL
onmne-fr-01;localhost:df._dev.label /dev
onmne-fr-01;localhost:df._dev.graph_data_size normal
onmne-fr-01;localhost:df._dev.critical 98
onmne-fr-01;localhost:df._dev.warning 92
onmne-fr-01;localhost:df._dev.update_rate 300
onmne-fr-01;localhost:df.overlay.warning 92
onmne-fr-01;localhost:df.overlay.update_rate 300
onmne-fr-01;localhost:df.overlay.critical 98
onmne-fr-01;localhost:df.overlay.label /
onmne-fr-01;localhost:df.overlay.graph_data_size normal
onmne-fr-01;localhost:df._dev_mapper_ubuntu_vL.label /etc/hosts
onmne-fr-01;localhost:df._dev_mapper_ubuntu_vL.graph_data_size normal
onmne-fr-01;localhost:df._dev_mapper_ubuntu_vL.critical 98
onmne-fr-01;localhost:df._dev_mapper_ubuntu_vL.warning 92
onmne-fr-01;localhost:df._dev_mapper_ubuntu_vL.update_rate 300
onmne-fr-01;localhost:df.shm.update_rate 300
onmne-fr-01;localhost:df.shm.warning 92
onmne-fr-01;localhost:df.shm.critical 98
onmne-fr-01;localhost:df.shm.label /dev/shm
onmne-fr-01;localhost:df.shm.graph_data_size normal
onmne-fr-01;localhost:df._sys_fs_cgroup.critical 98
onmne-fr-01;localhost:df._sys_fs_cgroup.update_rate 300
onmne-fr-01;localhost:df._sys_fs_cgroup.warning 92
onmne-fr-01;localhost:df._sys_fs_cgroup.label /sys/fs/cgroup
onmne-fr-01;localhost:df._sys_fs_cgroup.graph_data_size normal
onmne-fr-01;localhost:df_inode.graph_title Inode usage in percent
onmne-fr-01;localhost:df_inode.graph_args --upper-limit 100 -l 0
onmne-fr-01;localhost:df_inode.graph_vlabel %
onmne-fr-01;localhost:df_inode.graph_scale no
onmne-fr-01;localhost:df_inode.graph_category disk
onmne-fr-01;localhost:df_inode.graph_order overlay _dev _sys_fs_cgroup shm _dev_mapper_ubuntu_vL
onmne-fr-01;localhost:df_inode.shm.graph_data_size normal
onmne-fr-01;localhost:df_inode.shm.label /dev/shm
onmne-fr-01;localhost:df_inode.shm.update_rate 300
onmne-fr-01;localhost:df_inode.shm.warning 92
onmne-fr-01;localhost:df_inode.shm.critical 98
onmne-fr-01;localhost:df_inode._sys_fs_cgroup.graph_data_size normal
onmne-fr-01;localhost:df_inode._sys_fs_cgroup.label /sys/fs/cgroup
onmne-fr-01;localhost:df_inode._sys_fs_cgroup.critical 98
onmne-fr-01;localhost:df_inode._sys_fs_cgroup.warning 92
onmne-fr-01;localhost:df_inode._sys_fs_cgroup.update_rate 300
onmne-fr-01;localhost:df_inode._dev.label /dev
onmne-fr-01;localhost:df_inode._dev.graph_data_size normal
onmne-fr-01;localhost:df_inode._dev.update_rate 300
onmne-fr-01;localhost:df_inode._dev.warning 92
onmne-fr-01;localhost:df_inode._dev.critical 98
onmne-fr-01;localhost:df_inode._dev_mapper_ubuntu_vL.critical 98
onmne-fr-01;localhost:df_inode._dev_mapper_ubuntu_vL.warning 92
onmne-fr-01;localhost:df_inode._dev_mapper_ubuntu_vL.update_rate 300
onmne-fr-01;localhost:df_inode._dev_mapper_ubuntu_vL.label /etc/hosts
onmne-fr-01;localhost:df_inode._dev_mapper_ubuntu_vL.graph_data_size normal
onmne-fr-01;localhost:df_inode.overlay.critical 98
onmne-fr-01;localhost:df_inode.overlay.update_rate 300
onmne-fr-01;localhost:df_inode.overlay.warning 92
onmne-fr-01;localhost:df_inode.overlay.graph_data_size normal
onmne-fr-01;localhost:df_inode.overlay.label /
onmne-fr-01;localhost:interrupts.graph_title Interrupts and context switches
onmne-fr-01;localhost:interrupts.graph_args --base 1000 -l 0
onmne-fr-01;localhost:interrupts.graph_vlabel interrupts & ctx switches / ${graph_period}
onmne-fr-01;localhost:interrupts.graph_category system
onmne-fr-01;localhost:interrupts.graph_info This graph shows the number of interrupts and context switches on the system. These are typically high on a busy system.
onmne-fr-01;localhost:interrupts.graph_order intr ctx
onmne-fr-01;localhost:interrupts.ctx.update_rate 300
onmne-fr-01;localhost:interrupts.ctx.min 0
onmne-fr-01;localhost:interrupts.ctx.type DERIVE
onmne-fr-01;localhost:interrupts.ctx.label context switches
onmne-fr-01;localhost:interrupts.ctx.info A context switch occurs when a multitasking operatings system suspends the currently running process, and starts executing another.
onmne-fr-01;localhost:interrupts.ctx.graph_data_size normal
onmne-fr-01;localhost:interrupts.intr.update_rate 300
onmne-fr-01;localhost:interrupts.intr.min 0
onmne-fr-01;localhost:interrupts.intr.type DERIVE
onmne-fr-01;localhost:interrupts.intr.label interrupts
onmne-fr-01;localhost:interrupts.intr.info Interrupts are events that alter sequence of instructions executed by a processor. They can come from either hardware (exceptions, NMI, IRQ) or software.
onmne-fr-01;localhost:interrupts.intr.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop6.graph_title IOs for /dev/loop6
onmne-fr-01;localhost:diskstats_iops.loop6.graph_args --base 1000
onmne-fr-01;localhost:diskstats_iops.loop6.graph_vlabel Units read (-) / write (+)
onmne-fr-01;localhost:diskstats_iops.loop6.graph_category disk
onmne-fr-01;localhost:diskstats_iops.loop6.graph_info This graph shows the number of IO operations pr second and the average size of these requests.  Lots of small requests should result in in lower throughput (separate graph) and higher service time (separate graph).  Please note that starting with munin-node 2.0 the divisor for K is 1000 instead of 1024 which it was prior to 2.0 beta 3.  This is because the base for this graph is 1000 not 1024.
onmne-fr-01;localhost:diskstats_iops.loop6.graph_order rdio wrio avgrdrqsz avgwrrqsz
onmne-fr-01;localhost:diskstats_iops.loop6.rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop6.rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop6.rdio.label dummy
onmne-fr-01;localhost:diskstats_iops.loop6.rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop6.rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop6.rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop6.rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop6.wrio.negative rdio
onmne-fr-01;localhost:diskstats_iops.loop6.wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop6.wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop6.wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop6.wrio.label IO/sec
onmne-fr-01;localhost:diskstats_iops.loop6.wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop6.wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop6.avgrdrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop6.avgrdrqsz.graph no
onmne-fr-01;localhost:diskstats_iops.loop6.avgrdrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop6.avgrdrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop6.avgrdrqsz.label dummy
onmne-fr-01;localhost:diskstats_iops.loop6.avgrdrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop6.avgrdrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop6.avgwrrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop6.avgwrrqsz.negative avgrdrqsz
onmne-fr-01;localhost:diskstats_iops.loop6.avgwrrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop6.avgwrrqsz.label Req Size (KB)
onmne-fr-01;localhost:diskstats_iops.loop6.avgwrrqsz.info Average Request Size in kilobytes (1000 based)
onmne-fr-01;localhost:diskstats_iops.loop6.avgwrrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop6.avgwrrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop6.avgwrrqsz.update_rate 300
onmne-fr-01;localhost:open_inodes.graph_title Inode table usage
onmne-fr-01;localhost:open_inodes.graph_args --base 1000 -l 0
onmne-fr-01;localhost:open_inodes.graph_vlabel number of open inodes
onmne-fr-01;localhost:open_inodes.graph_category system
onmne-fr-01;localhost:open_inodes.graph_info This graph monitors the Linux open inode table.
onmne-fr-01;localhost:open_inodes.graph_order used max
onmne-fr-01;localhost:open_inodes.used.update_rate 300
onmne-fr-01;localhost:open_inodes.used.graph_data_size normal
onmne-fr-01;localhost:open_inodes.used.info The number of currently open inodes.
onmne-fr-01;localhost:open_inodes.used.label open inodes
onmne-fr-01;localhost:open_inodes.max.graph_data_size normal
onmne-fr-01;localhost:open_inodes.max.info The size of the system inode table. This is dynamically adjusted by the kernel.
onmne-fr-01;localhost:open_inodes.max.label inode table size
onmne-fr-01;localhost:open_inodes.max.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop2.graph_title Disk throughput for /dev/loop2
onmne-fr-01;localhost:diskstats_throughput.loop2.graph_args --base 1024
onmne-fr-01;localhost:diskstats_throughput.loop2.graph_vlabel Pr ${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_throughput.loop2.graph_category disk
onmne-fr-01;localhost:diskstats_throughput.loop2.graph_info This graph shows disk throughput in bytes pr ${graph_period}.  The graph base is 1024 so KB is for Kibi bytes and so on.
onmne-fr-01;localhost:diskstats_throughput.loop2.graph_order rdbytes wrbytes
onmne-fr-01;localhost:diskstats_throughput.loop2.wrbytes.label Bytes
onmne-fr-01;localhost:diskstats_throughput.loop2.wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop2.wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop2.wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop2.wrbytes.negative rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop2.wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop2.wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop2.rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop2.rdbytes.label invisible
onmne-fr-01;localhost:diskstats_throughput.loop2.rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop2.rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop2.rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop2.rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop2.rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop0.graph_title Average latency for /dev/loop0
onmne-fr-01;localhost:diskstats_latency.loop0.graph_args --base 1000 --logarithmic
onmne-fr-01;localhost:diskstats_latency.loop0.graph_vlabel seconds
onmne-fr-01;localhost:diskstats_latency.loop0.graph_category disk
onmne-fr-01;localhost:diskstats_latency.loop0.graph_info This graph shows average waiting time/latency for different categories of disk operations.   The times that include the queue times indicate how busy your system is.  If the waiting time hits 1 second then your I/O system is 100% busy.
onmne-fr-01;localhost:diskstats_latency.loop0.graph_order svctm avgwait avgrdwait avgwrwait
onmne-fr-01;localhost:diskstats_latency.loop0.avgrdwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop0.avgrdwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop0.avgrdwait.label Read IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop0.avgrdwait.info Average wait time for a read I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop0.avgrdwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop0.avgrdwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop0.avgrdwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop0.avgrdwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop0.avgwrwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop0.avgwrwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop0.avgwrwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop0.avgwrwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop0.avgwrwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop0.avgwrwait.label Write IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop0.avgwrwait.info Average wait time for a write I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop0.avgwrwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop0.svctm.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop0.svctm.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop0.svctm.label Device IO time
onmne-fr-01;localhost:diskstats_latency.loop0.svctm.info Average time an I/O takes on the block device not including any queue times, just the round trip time for the disk request.
onmne-fr-01;localhost:diskstats_latency.loop0.svctm.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop0.svctm.min 0
onmne-fr-01;localhost:diskstats_latency.loop0.svctm.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop0.avgwait.info Average wait time for an I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop0.avgwait.label IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop0.avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop0.avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop0.avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop0.avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop0.avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop3.graph_title Disk utilization for /dev/loop3
onmne-fr-01;localhost:diskstats_utilization.loop3.graph_args --base 1000 --lower-limit 0 --upper-limit 100 --rigid
onmne-fr-01;localhost:diskstats_utilization.loop3.graph_vlabel % busy
onmne-fr-01;localhost:diskstats_utilization.loop3.graph_category disk
onmne-fr-01;localhost:diskstats_utilization.loop3.graph_scale no
onmne-fr-01;localhost:diskstats_utilization.loop3.graph_order util
onmne-fr-01;localhost:diskstats_utilization.loop3.util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop3.util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop3.util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop3.util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop3.util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop3.util.label Utilization
onmne-fr-01;localhost:diskstats_utilization.loop3.util.info Utilization of the device in percent. If the time spent for I/O is close to 1000msec for a given second, the device is nearly 100% saturated.
onmne-fr-01;localhost:diskstats_utilization.loop4.graph_title Disk utilization for /dev/loop4
onmne-fr-01;localhost:diskstats_utilization.loop4.graph_args --base 1000 --lower-limit 0 --upper-limit 100 --rigid
onmne-fr-01;localhost:diskstats_utilization.loop4.graph_vlabel % busy
onmne-fr-01;localhost:diskstats_utilization.loop4.graph_category disk
onmne-fr-01;localhost:diskstats_utilization.loop4.graph_scale no
onmne-fr-01;localhost:diskstats_utilization.loop4.graph_order util
onmne-fr-01;localhost:diskstats_utilization.loop4.util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop4.util.label Utilization
onmne-fr-01;localhost:diskstats_utilization.loop4.util.info Utilization of the device in percent. If the time spent for I/O is close to 1000msec for a given second, the device is nearly 100% saturated.
onmne-fr-01;localhost:diskstats_utilization.loop4.util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop4.util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop4.util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop4.util.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop2.graph_title Average latency for /dev/loop2
onmne-fr-01;localhost:diskstats_latency.loop2.graph_args --base 1000 --logarithmic
onmne-fr-01;localhost:diskstats_latency.loop2.graph_vlabel seconds
onmne-fr-01;localhost:diskstats_latency.loop2.graph_category disk
onmne-fr-01;localhost:diskstats_latency.loop2.graph_info This graph shows average waiting time/latency for different categories of disk operations.   The times that include the queue times indicate how busy your system is.  If the waiting time hits 1 second then your I/O system is 100% busy.
onmne-fr-01;localhost:diskstats_latency.loop2.graph_order svctm avgwait avgrdwait avgwrwait
onmne-fr-01;localhost:diskstats_latency.loop2.avgrdwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop2.avgrdwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop2.avgrdwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop2.avgrdwait.info Average wait time for a read I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop2.avgrdwait.label Read IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop2.avgrdwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop2.avgrdwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop2.avgrdwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop2.svctm.label Device IO time
onmne-fr-01;localhost:diskstats_latency.loop2.svctm.info Average time an I/O takes on the block device not including any queue times, just the round trip time for the disk request.
onmne-fr-01;localhost:diskstats_latency.loop2.svctm.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop2.svctm.min 0
onmne-fr-01;localhost:diskstats_latency.loop2.svctm.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop2.svctm.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop2.svctm.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop2.avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop2.avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop2.avgwait.info Average wait time for an I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop2.avgwait.label IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop2.avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop2.avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop2.avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop2.avgwrwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop2.avgwrwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop2.avgwrwait.info Average wait time for a write I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop2.avgwrwait.label Write IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop2.avgwrwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop2.avgwrwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop2.avgwrwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop2.avgwrwait.warning 0:3
onmne-fr-01;localhost:diskstats_throughput.loop3.graph_title Disk throughput for /dev/loop3
onmne-fr-01;localhost:diskstats_throughput.loop3.graph_args --base 1024
onmne-fr-01;localhost:diskstats_throughput.loop3.graph_vlabel Pr ${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_throughput.loop3.graph_category disk
onmne-fr-01;localhost:diskstats_throughput.loop3.graph_info This graph shows disk throughput in bytes pr ${graph_period}.  The graph base is 1024 so KB is for Kibi bytes and so on.
onmne-fr-01;localhost:diskstats_throughput.loop3.graph_order rdbytes wrbytes
onmne-fr-01;localhost:diskstats_throughput.loop3.wrbytes.label Bytes
onmne-fr-01;localhost:diskstats_throughput.loop3.wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop3.wrbytes.negative rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop3.wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop3.wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop3.wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop3.wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop3.rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop3.rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop3.rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop3.rdbytes.label invisible
onmne-fr-01;localhost:diskstats_throughput.loop3.rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop3.rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop3.rdbytes.min 0
onmne-fr-01;localhost:diskstats_latency.graph_title Disk latency per device
onmne-fr-01;localhost:diskstats_latency.graph_args --base 1000
onmne-fr-01;localhost:diskstats_latency.graph_vlabel Average IO Wait (seconds)
onmne-fr-01;localhost:diskstats_latency.graph_category disk
onmne-fr-01;localhost:diskstats_latency.graph_width 400
onmne-fr-01;localhost:diskstats_latency.graph_order loop0_avgwait loop1_avgwait loop2_avgwait loop3_avgwait loop4_avgwait loop5_avgwait loop6_avgwait sda_avgwait dm_0_avgwait
onmne-fr-01;localhost:diskstats_latency.loop3_avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop3_avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop3_avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop3_avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop3_avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop3_avgwait.label loop3
onmne-fr-01;localhost:diskstats_latency.loop3_avgwait.info Average wait time for an I/O request
onmne-fr-01;localhost:diskstats_latency.loop0_avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop0_avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop0_avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop0_avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop0_avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop0_avgwait.info Average wait time for an I/O request
onmne-fr-01;localhost:diskstats_latency.loop0_avgwait.label loop0
onmne-fr-01;localhost:diskstats_latency.loop6_avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop6_avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop6_avgwait.label loop6
onmne-fr-01;localhost:diskstats_latency.loop6_avgwait.info Average wait time for an I/O request
onmne-fr-01;localhost:diskstats_latency.loop6_avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop6_avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop6_avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop4_avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop4_avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop4_avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop4_avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop4_avgwait.info Average wait time for an I/O request
onmne-fr-01;localhost:diskstats_latency.loop4_avgwait.label loop4
onmne-fr-01;localhost:diskstats_latency.loop4_avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop5_avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop5_avgwait.label loop5
onmne-fr-01;localhost:diskstats_latency.loop5_avgwait.info Average wait time for an I/O request
onmne-fr-01;localhost:diskstats_latency.loop5_avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop5_avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop5_avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop5_avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.dm_0_avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.dm_0_avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.dm_0_avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.dm_0_avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.dm_0_avgwait.info Average wait time for an I/O request
onmne-fr-01;localhost:diskstats_latency.dm_0_avgwait.label dm-0
onmne-fr-01;localhost:diskstats_latency.dm_0_avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop2_avgwait.label loop2
onmne-fr-01;localhost:diskstats_latency.loop2_avgwait.info Average wait time for an I/O request
onmne-fr-01;localhost:diskstats_latency.loop2_avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop2_avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop2_avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop2_avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop2_avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop1_avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop1_avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop1_avgwait.info Average wait time for an I/O request
onmne-fr-01;localhost:diskstats_latency.loop1_avgwait.label loop1
onmne-fr-01;localhost:diskstats_latency.loop1_avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop1_avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop1_avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.sda_avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.sda_avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.sda_avgwait.info Average wait time for an I/O request
onmne-fr-01;localhost:diskstats_latency.sda_avgwait.label sda
onmne-fr-01;localhost:diskstats_latency.sda_avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.sda_avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.sda_avgwait.min 0
onmne-fr-01;localhost:diskstats_throughput.sda.graph_title Disk throughput for /dev/sda
onmne-fr-01;localhost:diskstats_throughput.sda.graph_args --base 1024
onmne-fr-01;localhost:diskstats_throughput.sda.graph_vlabel Pr ${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_throughput.sda.graph_category disk
onmne-fr-01;localhost:diskstats_throughput.sda.graph_info This graph shows disk throughput in bytes pr ${graph_period}.  The graph base is 1024 so KB is for Kibi bytes and so on.
onmne-fr-01;localhost:diskstats_throughput.sda.graph_order rdbytes wrbytes
onmne-fr-01;localhost:diskstats_throughput.sda.wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.sda.wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.sda.wrbytes.negative rdbytes
onmne-fr-01;localhost:diskstats_throughput.sda.wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.sda.wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.sda.wrbytes.label Bytes
onmne-fr-01;localhost:diskstats_throughput.sda.wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.sda.rdbytes.label invisible
onmne-fr-01;localhost:diskstats_throughput.sda.rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.sda.rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.sda.rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.sda.rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.sda.rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.sda.rdbytes.update_rate 300
onmne-fr-01;localhost:forks.graph_title Fork rate
onmne-fr-01;localhost:forks.graph_args --base 1000 -l 0
onmne-fr-01;localhost:forks.graph_vlabel forks / ${graph_period}
onmne-fr-01;localhost:forks.graph_category processes
onmne-fr-01;localhost:forks.graph_info This graph shows the number of forks (new processes started) per second.
onmne-fr-01;localhost:forks.graph_order forks
onmne-fr-01;localhost:forks.forks.update_rate 300
onmne-fr-01;localhost:forks.forks.max 100000
onmne-fr-01;localhost:forks.forks.info The number of forks per second.
onmne-fr-01;localhost:forks.forks.label forks
onmne-fr-01;localhost:forks.forks.graph_data_size normal
onmne-fr-01;localhost:forks.forks.type DERIVE
onmne-fr-01;localhost:forks.forks.min 0
onmne-fr-01;localhost:diskstats_iops.sda.graph_title IOs for /dev/sda
onmne-fr-01;localhost:diskstats_iops.sda.graph_args --base 1000
onmne-fr-01;localhost:diskstats_iops.sda.graph_vlabel Units read (-) / write (+)
onmne-fr-01;localhost:diskstats_iops.sda.graph_category disk
onmne-fr-01;localhost:diskstats_iops.sda.graph_info This graph shows the number of IO operations pr second and the average size of these requests.  Lots of small requests should result in in lower throughput (separate graph) and higher service time (separate graph).  Please note that starting with munin-node 2.0 the divisor for K is 1000 instead of 1024 which it was prior to 2.0 beta 3.  This is because the base for this graph is 1000 not 1024.
onmne-fr-01;localhost:diskstats_iops.sda.graph_order rdio wrio avgrdrqsz avgwrrqsz
onmne-fr-01;localhost:diskstats_iops.sda.avgrdrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.sda.avgrdrqsz.graph no
onmne-fr-01;localhost:diskstats_iops.sda.avgrdrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.sda.avgrdrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.sda.avgrdrqsz.label dummy
onmne-fr-01;localhost:diskstats_iops.sda.avgrdrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.sda.avgrdrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.sda.wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.sda.wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.sda.wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.sda.wrio.label IO/sec
onmne-fr-01;localhost:diskstats_iops.sda.wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.sda.wrio.negative rdio
onmne-fr-01;localhost:diskstats_iops.sda.wrio.min 0
onmne-fr-01;localhost:diskstats_iops.sda.rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.sda.rdio.label dummy
onmne-fr-01;localhost:diskstats_iops.sda.rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.sda.rdio.min 0
onmne-fr-01;localhost:diskstats_iops.sda.rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.sda.rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.sda.rdio.graph no
onmne-fr-01;localhost:diskstats_iops.sda.avgwrrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.sda.avgwrrqsz.negative avgrdrqsz
onmne-fr-01;localhost:diskstats_iops.sda.avgwrrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.sda.avgwrrqsz.label Req Size (KB)
onmne-fr-01;localhost:diskstats_iops.sda.avgwrrqsz.info Average Request Size in kilobytes (1000 based)
onmne-fr-01;localhost:diskstats_iops.sda.avgwrrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.sda.avgwrrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.sda.avgwrrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop4.graph_title IOs for /dev/loop4
onmne-fr-01;localhost:diskstats_iops.loop4.graph_args --base 1000
onmne-fr-01;localhost:diskstats_iops.loop4.graph_vlabel Units read (-) / write (+)
onmne-fr-01;localhost:diskstats_iops.loop4.graph_category disk
onmne-fr-01;localhost:diskstats_iops.loop4.graph_info This graph shows the number of IO operations pr second and the average size of these requests.  Lots of small requests should result in in lower throughput (separate graph) and higher service time (separate graph).  Please note that starting with munin-node 2.0 the divisor for K is 1000 instead of 1024 which it was prior to 2.0 beta 3.  This is because the base for this graph is 1000 not 1024.
onmne-fr-01;localhost:diskstats_iops.loop4.graph_order rdio wrio avgrdrqsz avgwrrqsz
onmne-fr-01;localhost:diskstats_iops.loop4.avgwrrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop4.avgwrrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop4.avgwrrqsz.negative avgrdrqsz
onmne-fr-01;localhost:diskstats_iops.loop4.avgwrrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop4.avgwrrqsz.info Average Request Size in kilobytes (1000 based)
onmne-fr-01;localhost:diskstats_iops.loop4.avgwrrqsz.label Req Size (KB)
onmne-fr-01;localhost:diskstats_iops.loop4.avgwrrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop4.avgwrrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop4.wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop4.wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop4.wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop4.wrio.label IO/sec
onmne-fr-01;localhost:diskstats_iops.loop4.wrio.negative rdio
onmne-fr-01;localhost:diskstats_iops.loop4.wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop4.wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop4.rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop4.rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop4.rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop4.rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop4.rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop4.rdio.label dummy
onmne-fr-01;localhost:diskstats_iops.loop4.rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop4.avgrdrqsz.label dummy
onmne-fr-01;localhost:diskstats_iops.loop4.avgrdrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop4.avgrdrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop4.avgrdrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop4.avgrdrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop4.avgrdrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop4.avgrdrqsz.graph no
onmne-fr-01;localhost:memory.graph_args --base 1024 -l 0 --upper-limit 16790654976
onmne-fr-01;localhost:memory.graph_vlabel Bytes
onmne-fr-01;localhost:memory.graph_title Memory usage
onmne-fr-01;localhost:memory.graph_category system
onmne-fr-01;localhost:memory.graph_info This graph shows what the machine uses memory for.
onmne-fr-01;localhost:memory.graph_order apps page_tables per_cpu swap_cache slab shmem cached buffers free swap apps buffers swap cached free shmem slab swap_cache page_tables per_cpu vmalloc_used committed mapped active inactive
onmne-fr-01;localhost:memory.buffers.label buffers
onmne-fr-01;localhost:memory.buffers.info Block device (e.g. harddisk) cache. Also where "dirty" blocks are stored until written.
onmne-fr-01;localhost:memory.buffers.graph_data_size normal
onmne-fr-01;localhost:memory.buffers.update_rate 300
onmne-fr-01;localhost:memory.buffers.colour COLOUR5
onmne-fr-01;localhost:memory.buffers.draw STACK
onmne-fr-01;localhost:memory.apps.colour COLOUR0
onmne-fr-01;localhost:memory.apps.update_rate 300
onmne-fr-01;localhost:memory.apps.draw AREA
onmne-fr-01;localhost:memory.apps.graph_data_size normal
onmne-fr-01;localhost:memory.apps.label apps
onmne-fr-01;localhost:memory.apps.info Memory used by user-space applications.
onmne-fr-01;localhost:memory.vmalloc_used.colour COLOUR8
onmne-fr-01;localhost:memory.vmalloc_used.update_rate 300
onmne-fr-01;localhost:memory.vmalloc_used.draw LINE2
onmne-fr-01;localhost:memory.vmalloc_used.graph_data_size normal
onmne-fr-01;localhost:memory.vmalloc_used.label vmalloc_used
onmne-fr-01;localhost:memory.vmalloc_used.info 'VMalloc' (kernel) memory used
onmne-fr-01;localhost:memory.cached.colour COLOUR4
onmne-fr-01;localhost:memory.cached.update_rate 300
onmne-fr-01;localhost:memory.cached.draw STACK
onmne-fr-01;localhost:memory.cached.graph_data_size normal
onmne-fr-01;localhost:memory.cached.info Parked file data (file content) cache.
onmne-fr-01;localhost:memory.cached.label cache
onmne-fr-01;localhost:memory.inactive.colour COLOUR15
onmne-fr-01;localhost:memory.inactive.update_rate 300
onmne-fr-01;localhost:memory.inactive.draw LINE2
onmne-fr-01;localhost:memory.inactive.graph_data_size normal
onmne-fr-01;localhost:memory.inactive.label inactive
onmne-fr-01;localhost:memory.inactive.info Memory not currently used.
onmne-fr-01;localhost:memory.swap_cache.draw STACK
onmne-fr-01;localhost:memory.swap_cache.update_rate 300
onmne-fr-01;localhost:memory.swap_cache.colour COLOUR2
onmne-fr-01;localhost:memory.swap_cache.info A piece of memory that keeps track of pages that have been fetched from swap but not yet been modified.
onmne-fr-01;localhost:memory.swap_cache.label swap_cache
onmne-fr-01;localhost:memory.swap_cache.graph_data_size normal
onmne-fr-01;localhost:memory.page_tables.draw STACK
onmne-fr-01;localhost:memory.page_tables.update_rate 300
onmne-fr-01;localhost:memory.page_tables.colour COLOUR1
onmne-fr-01;localhost:memory.page_tables.label page_tables
onmne-fr-01;localhost:memory.page_tables.info Memory used to map between virtual and physical memory addresses.
onmne-fr-01;localhost:memory.page_tables.graph_data_size normal
onmne-fr-01;localhost:memory.slab.draw STACK
onmne-fr-01;localhost:memory.slab.colour COLOUR3
onmne-fr-01;localhost:memory.slab.update_rate 300
onmne-fr-01;localhost:memory.slab.graph_data_size normal
onmne-fr-01;localhost:memory.slab.label slab_cache
onmne-fr-01;localhost:memory.slab.info Memory used by the kernel (major users  are caches like inode, dentry, etc).
onmne-fr-01;localhost:memory.per_cpu.label per_cpu
onmne-fr-01;localhost:memory.per_cpu.info Per CPU allocations
onmne-fr-01;localhost:memory.per_cpu.graph_data_size normal
onmne-fr-01;localhost:memory.per_cpu.update_rate 300
onmne-fr-01;localhost:memory.per_cpu.colour COLOUR20
onmne-fr-01;localhost:memory.per_cpu.draw STACK
onmne-fr-01;localhost:memory.free.label unused
onmne-fr-01;localhost:memory.free.info Wasted memory. Memory that is not used for anything at all.
onmne-fr-01;localhost:memory.free.graph_data_size normal
onmne-fr-01;localhost:memory.free.update_rate 300
onmne-fr-01;localhost:memory.free.colour COLOUR6
onmne-fr-01;localhost:memory.free.draw STACK
onmne-fr-01;localhost:memory.shmem.colour COLOUR9
onmne-fr-01;localhost:memory.shmem.update_rate 300
onmne-fr-01;localhost:memory.shmem.draw STACK
onmne-fr-01;localhost:memory.shmem.graph_data_size normal
onmne-fr-01;localhost:memory.shmem.info Shared Memory (SYSV SHM segments, tmpfs).
onmne-fr-01;localhost:memory.shmem.label shmem
onmne-fr-01;localhost:memory.committed.draw LINE2
onmne-fr-01;localhost:memory.committed.update_rate 300
onmne-fr-01;localhost:memory.committed.colour COLOUR10
onmne-fr-01;localhost:memory.committed.info The amount of memory allocated to programs. Overcommitting is normal, but may indicate memory leaks.
onmne-fr-01;localhost:memory.committed.label committed
onmne-fr-01;localhost:memory.committed.graph_data_size normal
onmne-fr-01;localhost:memory.mapped.graph_data_size normal
onmne-fr-01;localhost:memory.mapped.info All mmap()ed pages.
onmne-fr-01;localhost:memory.mapped.label mapped
onmne-fr-01;localhost:memory.mapped.colour COLOUR11
onmne-fr-01;localhost:memory.mapped.update_rate 300
onmne-fr-01;localhost:memory.mapped.draw LINE2
onmne-fr-01;localhost:memory.swap.graph_data_size normal
onmne-fr-01;localhost:memory.swap.label swap
onmne-fr-01;localhost:memory.swap.info Swap space used.
onmne-fr-01;localhost:memory.swap.draw STACK
onmne-fr-01;localhost:memory.swap.colour COLOUR7
onmne-fr-01;localhost:memory.swap.update_rate 300
onmne-fr-01;localhost:memory.active.draw LINE2
onmne-fr-01;localhost:memory.active.colour COLOUR12
onmne-fr-01;localhost:memory.active.update_rate 300
onmne-fr-01;localhost:memory.active.graph_data_size normal
onmne-fr-01;localhost:memory.active.info Memory recently used. Not reclaimed unless absolutely necessary.
onmne-fr-01;localhost:memory.active.label active
onmne-fr-01;localhost:load.graph_title Load average
onmne-fr-01;localhost:load.graph_args --base 1000 -l 0
onmne-fr-01;localhost:load.graph_vlabel load
onmne-fr-01;localhost:load.graph_scale no
onmne-fr-01;localhost:load.graph_category system
onmne-fr-01;localhost:load.graph_info The load average of the machine describes how many processes are in the run-queue (scheduled to run "immediately").
onmne-fr-01;localhost:load.graph_order load
onmne-fr-01;localhost:load.load.update_rate 300
onmne-fr-01;localhost:load.load.info 5 minute load average
onmne-fr-01;localhost:load.load.label load
onmne-fr-01;localhost:load.load.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop1.graph_title Disk throughput for /dev/loop1
onmne-fr-01;localhost:diskstats_throughput.loop1.graph_args --base 1024
onmne-fr-01;localhost:diskstats_throughput.loop1.graph_vlabel Pr ${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_throughput.loop1.graph_category disk
onmne-fr-01;localhost:diskstats_throughput.loop1.graph_info This graph shows disk throughput in bytes pr ${graph_period}.  The graph base is 1024 so KB is for Kibi bytes and so on.
onmne-fr-01;localhost:diskstats_throughput.loop1.graph_order rdbytes wrbytes
onmne-fr-01;localhost:diskstats_throughput.loop1.wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop1.wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop1.wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop1.wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop1.wrbytes.negative rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop1.wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop1.wrbytes.label Bytes
onmne-fr-01;localhost:diskstats_throughput.loop1.rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop1.rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop1.rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop1.rdbytes.label invisible
onmne-fr-01;localhost:diskstats_throughput.loop1.rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop1.rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop1.rdbytes.min 0
onmne-fr-01;localhost:diskstats_latency.sda.graph_title Average latency for /dev/sda
onmne-fr-01;localhost:diskstats_latency.sda.graph_args --base 1000 --logarithmic
onmne-fr-01;localhost:diskstats_latency.sda.graph_vlabel seconds
onmne-fr-01;localhost:diskstats_latency.sda.graph_category disk
onmne-fr-01;localhost:diskstats_latency.sda.graph_info This graph shows average waiting time/latency for different categories of disk operations.   The times that include the queue times indicate how busy your system is.  If the waiting time hits 1 second then your I/O system is 100% busy.
onmne-fr-01;localhost:diskstats_latency.sda.graph_order svctm avgwait avgrdwait avgwrwait
onmne-fr-01;localhost:diskstats_latency.sda.svctm.type GAUGE
onmne-fr-01;localhost:diskstats_latency.sda.svctm.min 0
onmne-fr-01;localhost:diskstats_latency.sda.svctm.label Device IO time
onmne-fr-01;localhost:diskstats_latency.sda.svctm.info Average time an I/O takes on the block device not including any queue times, just the round trip time for the disk request.
onmne-fr-01;localhost:diskstats_latency.sda.svctm.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.sda.svctm.update_rate 300
onmne-fr-01;localhost:diskstats_latency.sda.svctm.draw LINE1
onmne-fr-01;localhost:diskstats_latency.sda.avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.sda.avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.sda.avgwait.label IO Wait time
onmne-fr-01;localhost:diskstats_latency.sda.avgwait.info Average wait time for an I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.sda.avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.sda.avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.sda.avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.sda.avgwrwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.sda.avgwrwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.sda.avgwrwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.sda.avgwrwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.sda.avgwrwait.info Average wait time for a write I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.sda.avgwrwait.label Write IO Wait time
onmne-fr-01;localhost:diskstats_latency.sda.avgwrwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.sda.avgwrwait.min 0
onmne-fr-01;localhost:diskstats_latency.sda.avgrdwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.sda.avgrdwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.sda.avgrdwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.sda.avgrdwait.info Average wait time for a read I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.sda.avgrdwait.label Read IO Wait time
onmne-fr-01;localhost:diskstats_latency.sda.avgrdwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.sda.avgrdwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.sda.avgrdwait.min 0
onmne-fr-01;localhost:if_err_eth0.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-fr-01;localhost:if_err_eth0.graph_title eth0 errors
onmne-fr-01;localhost:if_err_eth0.graph_args --base 1000
onmne-fr-01;localhost:if_err_eth0.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-fr-01;localhost:if_err_eth0.graph_category network
onmne-fr-01;localhost:if_err_eth0.graph_info This graph shows the amount of errors, packet drops, and collisions on the eth0 network interface.
onmne-fr-01;localhost:if_err_eth0.rcvd.graph no
onmne-fr-01;localhost:if_err_eth0.rcvd.warning 1
onmne-fr-01;localhost:if_err_eth0.rcvd.update_rate 300
onmne-fr-01;localhost:if_err_eth0.rcvd.graph_data_size normal
onmne-fr-01;localhost:if_err_eth0.rcvd.label errors
onmne-fr-01;localhost:if_err_eth0.rcvd.type COUNTER
onmne-fr-01;localhost:if_err_eth0.txdrop.update_rate 300
onmne-fr-01;localhost:if_err_eth0.txdrop.graph_data_size normal
onmne-fr-01;localhost:if_err_eth0.txdrop.label drops
onmne-fr-01;localhost:if_err_eth0.txdrop.negative rxdrop
onmne-fr-01;localhost:if_err_eth0.txdrop.type COUNTER
onmne-fr-01;localhost:if_err_eth0.collisions.graph_data_size normal
onmne-fr-01;localhost:if_err_eth0.collisions.label collisions
onmne-fr-01;localhost:if_err_eth0.collisions.update_rate 300
onmne-fr-01;localhost:if_err_eth0.collisions.type COUNTER
onmne-fr-01;localhost:if_err_eth0.rxdrop.type COUNTER
onmne-fr-01;localhost:if_err_eth0.rxdrop.graph_data_size normal
onmne-fr-01;localhost:if_err_eth0.rxdrop.label drops
onmne-fr-01;localhost:if_err_eth0.rxdrop.graph no
onmne-fr-01;localhost:if_err_eth0.rxdrop.update_rate 300
onmne-fr-01;localhost:if_err_eth0.trans.update_rate 300
onmne-fr-01;localhost:if_err_eth0.trans.warning 1
onmne-fr-01;localhost:if_err_eth0.trans.negative rcvd
onmne-fr-01;localhost:if_err_eth0.trans.type COUNTER
onmne-fr-01;localhost:if_err_eth0.trans.label errors
onmne-fr-01;localhost:if_err_eth0.trans.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop5.graph_title IOs for /dev/loop5
onmne-fr-01;localhost:diskstats_iops.loop5.graph_args --base 1000
onmne-fr-01;localhost:diskstats_iops.loop5.graph_vlabel Units read (-) / write (+)
onmne-fr-01;localhost:diskstats_iops.loop5.graph_category disk
onmne-fr-01;localhost:diskstats_iops.loop5.graph_info This graph shows the number of IO operations pr second and the average size of these requests.  Lots of small requests should result in in lower throughput (separate graph) and higher service time (separate graph).  Please note that starting with munin-node 2.0 the divisor for K is 1000 instead of 1024 which it was prior to 2.0 beta 3.  This is because the base for this graph is 1000 not 1024.
onmne-fr-01;localhost:diskstats_iops.loop5.graph_order rdio wrio avgrdrqsz avgwrrqsz
onmne-fr-01;localhost:diskstats_iops.loop5.avgwrrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop5.avgwrrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop5.avgwrrqsz.negative avgrdrqsz
onmne-fr-01;localhost:diskstats_iops.loop5.avgwrrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop5.avgwrrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop5.avgwrrqsz.label Req Size (KB)
onmne-fr-01;localhost:diskstats_iops.loop5.avgwrrqsz.info Average Request Size in kilobytes (1000 based)
onmne-fr-01;localhost:diskstats_iops.loop5.avgwrrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop5.avgrdrqsz.label dummy
onmne-fr-01;localhost:diskstats_iops.loop5.avgrdrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop5.avgrdrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop5.avgrdrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop5.avgrdrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop5.avgrdrqsz.graph no
onmne-fr-01;localhost:diskstats_iops.loop5.avgrdrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop5.wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop5.wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop5.wrio.label IO/sec
onmne-fr-01;localhost:diskstats_iops.loop5.wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop5.wrio.negative rdio
onmne-fr-01;localhost:diskstats_iops.loop5.wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop5.wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop5.rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop5.rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop5.rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop5.rdio.label dummy
onmne-fr-01;localhost:diskstats_iops.loop5.rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop5.rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop5.rdio.update_rate 300
onmne-fr-01;localhost:munin_stats.graph_title Munin processing time
onmne-fr-01;localhost:munin_stats.graph_info This graph shows the run time of the four different processes making up a munin-master run.  Munin-master is run from cron every 5 minutes and we want each of the programmes in munin-master to complete before the next instance starts.  Especially munin-update and munin-graph are time consuming and their run time bears watching. If munin-update uses too long time to run please see the munin-update graph to determine which host is slowing it down.  If munin-graph is running too slow you need to get clever (email the munin-users mailing list) unless you can buy a faster computer with better disks to run munin on.
onmne-fr-01;localhost:munin_stats.graph_args --base 1000 -l 0
onmne-fr-01;localhost:munin_stats.graph_scale yes
onmne-fr-01;localhost:munin_stats.graph_vlabel seconds
onmne-fr-01;localhost:munin_stats.graph_category munin
onmne-fr-01;localhost:munin_stats.graph_order update graph html limits
onmne-fr-01;localhost:munin_stats.graph.graph_data_size normal
onmne-fr-01;localhost:munin_stats.graph.label munin graph
onmne-fr-01;localhost:munin_stats.graph.warning 240
onmne-fr-01;localhost:munin_stats.graph.update_rate 300
onmne-fr-01;localhost:munin_stats.graph.draw AREASTACK
onmne-fr-01;localhost:munin_stats.graph.critical 285
onmne-fr-01;localhost:munin_stats.update.graph_data_size normal
onmne-fr-01;localhost:munin_stats.update.label munin update
onmne-fr-01;localhost:munin_stats.update.critical 285
onmne-fr-01;localhost:munin_stats.update.warning 240
onmne-fr-01;localhost:munin_stats.update.update_rate 300
onmne-fr-01;localhost:munin_stats.update.draw AREASTACK
onmne-fr-01;localhost:munin_stats.limits.label munin limits
onmne-fr-01;localhost:munin_stats.limits.graph_data_size normal
onmne-fr-01;localhost:munin_stats.limits.update_rate 300
onmne-fr-01;localhost:munin_stats.limits.draw AREASTACK
onmne-fr-01;localhost:munin_stats.html.draw AREASTACK
onmne-fr-01;localhost:munin_stats.html.update_rate 300
onmne-fr-01;localhost:munin_stats.html.label munin html
onmne-fr-01;localhost:munin_stats.html.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop7.graph_title Disk throughput for /dev/loop7
onmne-fr-01;localhost:diskstats_throughput.loop7.graph_args --base 1024
onmne-fr-01;localhost:diskstats_throughput.loop7.graph_vlabel Pr ${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_throughput.loop7.graph_category disk
onmne-fr-01;localhost:diskstats_throughput.loop7.graph_info This graph shows disk throughput in bytes pr ${graph_period}.  The graph base is 1024 so KB is for Kibi bytes and so on.
onmne-fr-01;localhost:diskstats_throughput.loop7.graph_order rdbytes wrbytes
onmne-fr-01;localhost:diskstats_throughput.loop7.wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop7.wrbytes.label Bytes
onmne-fr-01;localhost:diskstats_throughput.loop7.wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop7.wrbytes.negative rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop7.wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop7.wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop7.wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop7.rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop7.rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop7.rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop7.rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop7.rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop7.rdbytes.label invisible
onmne-fr-01;localhost:diskstats_throughput.loop7.rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.graph_title Disk IOs per device
onmne-fr-01;localhost:diskstats_iops.graph_args --base 1000
onmne-fr-01;localhost:diskstats_iops.graph_vlabel IOs/${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_iops.graph_category disk
onmne-fr-01;localhost:diskstats_iops.graph_width 400
onmne-fr-01;localhost:diskstats_iops.graph_order loop0_rdio loop0_wrio loop1_rdio loop1_wrio loop2_rdio loop2_wrio loop3_rdio loop3_wrio loop4_rdio loop4_wrio loop5_rdio loop5_wrio loop6_rdio loop6_wrio loop7_rdio loop7_wrio sda_rdio sda_wrio dm_0_rdio dm_0_wrio
onmne-fr-01;localhost:diskstats_iops.loop1_rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop1_rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop1_rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop1_rdio.label loop1
onmne-fr-01;localhost:diskstats_iops.loop1_rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop1_rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop1_rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop4_wrio.label loop4
onmne-fr-01;localhost:diskstats_iops.loop4_wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop4_wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop4_wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop4_wrio.negative loop4_rdio
onmne-fr-01;localhost:diskstats_iops.loop4_wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop4_wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop6_wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop6_wrio.negative loop6_rdio
onmne-fr-01;localhost:diskstats_iops.loop6_wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop6_wrio.label loop6
onmne-fr-01;localhost:diskstats_iops.loop6_wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop6_wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop6_wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop1_wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop1_wrio.negative loop1_rdio
onmne-fr-01;localhost:diskstats_iops.loop1_wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop1_wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop1_wrio.label loop1
onmne-fr-01;localhost:diskstats_iops.loop1_wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop1_wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop4_rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop4_rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop4_rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop4_rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop4_rdio.label loop4
onmne-fr-01;localhost:diskstats_iops.loop4_rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop4_rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop6_rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop6_rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop6_rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop6_rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop6_rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop6_rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop6_rdio.label loop6
onmne-fr-01;localhost:diskstats_iops.sda_wrio.label sda
onmne-fr-01;localhost:diskstats_iops.sda_wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.sda_wrio.negative sda_rdio
onmne-fr-01;localhost:diskstats_iops.sda_wrio.min 0
onmne-fr-01;localhost:diskstats_iops.sda_wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.sda_wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.sda_wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.dm_0_wrio.negative dm_0_rdio
onmne-fr-01;localhost:diskstats_iops.dm_0_wrio.min 0
onmne-fr-01;localhost:diskstats_iops.dm_0_wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.dm_0_wrio.label dm-0
onmne-fr-01;localhost:diskstats_iops.dm_0_wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.dm_0_wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.dm_0_wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop2_rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop2_rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop2_rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop2_rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop2_rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop2_rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop2_rdio.label loop2
onmne-fr-01;localhost:diskstats_iops.loop7_rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop7_rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop7_rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop7_rdio.label loop7
onmne-fr-01;localhost:diskstats_iops.loop7_rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop7_rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop7_rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop5_rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop5_rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop5_rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop5_rdio.label loop5
onmne-fr-01;localhost:diskstats_iops.loop5_rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop5_rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop5_rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop0_wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop0_wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop0_wrio.label loop0
onmne-fr-01;localhost:diskstats_iops.loop0_wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop0_wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop0_wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop0_wrio.negative loop0_rdio
onmne-fr-01;localhost:diskstats_iops.loop3_wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop3_wrio.label loop3
onmne-fr-01;localhost:diskstats_iops.loop3_wrio.negative loop3_rdio
onmne-fr-01;localhost:diskstats_iops.loop3_wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop3_wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop3_wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop3_wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.dm_0_rdio.label dm-0
onmne-fr-01;localhost:diskstats_iops.dm_0_rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.dm_0_rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.dm_0_rdio.min 0
onmne-fr-01;localhost:diskstats_iops.dm_0_rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.dm_0_rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.dm_0_rdio.graph no
onmne-fr-01;localhost:diskstats_iops.sda_rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.sda_rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.sda_rdio.graph no
onmne-fr-01;localhost:diskstats_iops.sda_rdio.label sda
onmne-fr-01;localhost:diskstats_iops.sda_rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.sda_rdio.min 0
onmne-fr-01;localhost:diskstats_iops.sda_rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop0_rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop0_rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop0_rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop0_rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop0_rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop0_rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop0_rdio.label loop0
onmne-fr-01;localhost:diskstats_iops.loop3_rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop3_rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop3_rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop3_rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop3_rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop3_rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop3_rdio.label loop3
onmne-fr-01;localhost:diskstats_iops.loop7_wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop7_wrio.label loop7
onmne-fr-01;localhost:diskstats_iops.loop7_wrio.negative loop7_rdio
onmne-fr-01;localhost:diskstats_iops.loop7_wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop7_wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop7_wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop7_wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop2_wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop2_wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop2_wrio.label loop2
onmne-fr-01;localhost:diskstats_iops.loop2_wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop2_wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop2_wrio.negative loop2_rdio
onmne-fr-01;localhost:diskstats_iops.loop2_wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop5_wrio.label loop5
onmne-fr-01;localhost:diskstats_iops.loop5_wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop5_wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop5_wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop5_wrio.negative loop5_rdio
onmne-fr-01;localhost:diskstats_iops.loop5_wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop5_wrio.draw LINE1
onmne-fr-01;localhost:processes.graph_title Processes
onmne-fr-01;localhost:processes.graph_info This graph shows the number of processes
onmne-fr-01;localhost:processes.graph_category processes
onmne-fr-01;localhost:processes.graph_args --base 1000 -l 0
onmne-fr-01;localhost:processes.graph_vlabel Number of processes
onmne-fr-01;localhost:processes.graph_order sleeping idle stopped zombie dead paging uninterruptible runnable processes dead paging idle sleeping uninterruptible stopped runnable zombie processes
onmne-fr-01;localhost:processes.paging.colour 00aaaa
onmne-fr-01;localhost:processes.paging.update_rate 300
onmne-fr-01;localhost:processes.paging.draw STACK
onmne-fr-01;localhost:processes.paging.graph_data_size normal
onmne-fr-01;localhost:processes.paging.info The number of paging processes (<2.6 kernels only).
onmne-fr-01;localhost:processes.paging.label paging
onmne-fr-01;localhost:processes.runnable.draw STACK
onmne-fr-01;localhost:processes.runnable.update_rate 300
onmne-fr-01;localhost:processes.runnable.colour 22ff22
onmne-fr-01;localhost:processes.runnable.label runnable
onmne-fr-01;localhost:processes.runnable.info The number of runnable processes (on the run queue).
onmne-fr-01;localhost:processes.runnable.graph_data_size normal
onmne-fr-01;localhost:processes.uninterruptible.info The number of uninterruptible processes (usually IO).
onmne-fr-01;localhost:processes.uninterruptible.label uninterruptible
onmne-fr-01;localhost:processes.uninterruptible.graph_data_size normal
onmne-fr-01;localhost:processes.uninterruptible.update_rate 300
onmne-fr-01;localhost:processes.uninterruptible.colour ffa500
onmne-fr-01;localhost:processes.uninterruptible.draw STACK
onmne-fr-01;localhost:processes.sleeping.update_rate 300
onmne-fr-01;localhost:processes.sleeping.colour 0022ff
onmne-fr-01;localhost:processes.sleeping.draw AREA
onmne-fr-01;localhost:processes.sleeping.info The number of sleeping processes.
onmne-fr-01;localhost:processes.sleeping.label sleeping
onmne-fr-01;localhost:processes.sleeping.graph_data_size normal
onmne-fr-01;localhost:processes.idle.info The number of idle kernel threads (>= 4.2 kernels only).
onmne-fr-01;localhost:processes.idle.label idle
onmne-fr-01;localhost:processes.idle.graph_data_size normal
onmne-fr-01;localhost:processes.idle.draw STACK
onmne-fr-01;localhost:processes.idle.update_rate 300
onmne-fr-01;localhost:processes.idle.colour 4169e1
onmne-fr-01;localhost:processes.zombie.draw STACK
onmne-fr-01;localhost:processes.zombie.colour 990000
onmne-fr-01;localhost:processes.zombie.update_rate 300
onmne-fr-01;localhost:processes.zombie.graph_data_size normal
onmne-fr-01;localhost:processes.zombie.info The number of defunct ('zombie') processes (process terminated and parent not waiting).
onmne-fr-01;localhost:processes.zombie.label zombie
onmne-fr-01;localhost:processes.processes.draw LINE1
onmne-fr-01;localhost:processes.processes.update_rate 300
onmne-fr-01;localhost:processes.processes.colour c0c0c0
onmne-fr-01;localhost:processes.processes.label total
onmne-fr-01;localhost:processes.processes.info The total number of processes.
onmne-fr-01;localhost:processes.processes.graph_data_size normal
onmne-fr-01;localhost:processes.stopped.graph_data_size normal
onmne-fr-01;localhost:processes.stopped.label stopped
onmne-fr-01;localhost:processes.stopped.info The number of stopped or traced processes.
onmne-fr-01;localhost:processes.stopped.colour cc0000
onmne-fr-01;localhost:processes.stopped.update_rate 300
onmne-fr-01;localhost:processes.stopped.draw STACK
onmne-fr-01;localhost:processes.dead.label dead
onmne-fr-01;localhost:processes.dead.info The number of dead processes.
onmne-fr-01;localhost:processes.dead.graph_data_size normal
onmne-fr-01;localhost:processes.dead.update_rate 300
onmne-fr-01;localhost:processes.dead.colour ff0000
onmne-fr-01;localhost:processes.dead.draw STACK
onmne-fr-01;localhost:diskstats_utilization.sda.graph_title Disk utilization for /dev/sda
onmne-fr-01;localhost:diskstats_utilization.sda.graph_args --base 1000 --lower-limit 0 --upper-limit 100 --rigid
onmne-fr-01;localhost:diskstats_utilization.sda.graph_vlabel % busy
onmne-fr-01;localhost:diskstats_utilization.sda.graph_category disk
onmne-fr-01;localhost:diskstats_utilization.sda.graph_scale no
onmne-fr-01;localhost:diskstats_utilization.sda.graph_order util
onmne-fr-01;localhost:diskstats_utilization.sda.util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.sda.util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.sda.util.label Utilization
onmne-fr-01;localhost:diskstats_utilization.sda.util.info Utilization of the device in percent. If the time spent for I/O is close to 1000msec for a given second, the device is nearly 100% saturated.
onmne-fr-01;localhost:diskstats_utilization.sda.util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.sda.util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.sda.util.min 0
onmne-fr-01;localhost:diskstats_iops.loop0.graph_title IOs for /dev/loop0
onmne-fr-01;localhost:diskstats_iops.loop0.graph_args --base 1000
onmne-fr-01;localhost:diskstats_iops.loop0.graph_vlabel Units read (-) / write (+)
onmne-fr-01;localhost:diskstats_iops.loop0.graph_category disk
onmne-fr-01;localhost:diskstats_iops.loop0.graph_info This graph shows the number of IO operations pr second and the average size of these requests.  Lots of small requests should result in in lower throughput (separate graph) and higher service time (separate graph).  Please note that starting with munin-node 2.0 the divisor for K is 1000 instead of 1024 which it was prior to 2.0 beta 3.  This is because the base for this graph is 1000 not 1024.
onmne-fr-01;localhost:diskstats_iops.loop0.graph_order rdio wrio avgrdrqsz avgwrrqsz
onmne-fr-01;localhost:diskstats_iops.loop0.avgwrrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop0.avgwrrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop0.avgwrrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop0.avgwrrqsz.negative avgrdrqsz
onmne-fr-01;localhost:diskstats_iops.loop0.avgwrrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop0.avgwrrqsz.label Req Size (KB)
onmne-fr-01;localhost:diskstats_iops.loop0.avgwrrqsz.info Average Request Size in kilobytes (1000 based)
onmne-fr-01;localhost:diskstats_iops.loop0.avgwrrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop0.avgrdrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop0.avgrdrqsz.label dummy
onmne-fr-01;localhost:diskstats_iops.loop0.avgrdrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop0.avgrdrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop0.avgrdrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop0.avgrdrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop0.avgrdrqsz.graph no
onmne-fr-01;localhost:diskstats_iops.loop0.wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop0.wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop0.wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop0.wrio.label IO/sec
onmne-fr-01;localhost:diskstats_iops.loop0.wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop0.wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop0.wrio.negative rdio
onmne-fr-01;localhost:diskstats_iops.loop0.rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop0.rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop0.rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop0.rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop0.rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop0.rdio.label dummy
onmne-fr-01;localhost:diskstats_iops.loop0.rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.dm_0.graph_title Disk throughput for /dev/dm-0
onmne-fr-01;localhost:diskstats_throughput.dm_0.graph_args --base 1024
onmne-fr-01;localhost:diskstats_throughput.dm_0.graph_vlabel Pr ${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_throughput.dm_0.graph_category disk
onmne-fr-01;localhost:diskstats_throughput.dm_0.graph_info This graph shows disk throughput in bytes pr ${graph_period}.  The graph base is 1024 so KB is for Kibi bytes and so on.
onmne-fr-01;localhost:diskstats_throughput.dm_0.graph_order rdbytes wrbytes
onmne-fr-01;localhost:diskstats_throughput.dm_0.rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.dm_0.rdbytes.label invisible
onmne-fr-01;localhost:diskstats_throughput.dm_0.rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.dm_0.rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.dm_0.rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.dm_0.rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.dm_0.rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.dm_0.wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.dm_0.wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.dm_0.wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.dm_0.wrbytes.negative rdbytes
onmne-fr-01;localhost:diskstats_throughput.dm_0.wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.dm_0.wrbytes.label Bytes
onmne-fr-01;localhost:diskstats_throughput.dm_0.wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.graph_title Utilization per device
onmne-fr-01;localhost:diskstats_utilization.graph_args --base 1000 --lower-limit 0 --upper-limit 100 --rigid
onmne-fr-01;localhost:diskstats_utilization.graph_vlabel % busy
onmne-fr-01;localhost:diskstats_utilization.graph_category disk
onmne-fr-01;localhost:diskstats_utilization.graph_width 400
onmne-fr-01;localhost:diskstats_utilization.graph_scale no
onmne-fr-01;localhost:diskstats_utilization.graph_order loop0_util loop1_util loop2_util loop3_util loop4_util loop5_util loop6_util sda_util dm_0_util
onmne-fr-01;localhost:diskstats_utilization.loop4_util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop4_util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop4_util.label loop4
onmne-fr-01;localhost:diskstats_utilization.loop4_util.info Utilization of the device
onmne-fr-01;localhost:diskstats_utilization.loop4_util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop4_util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop4_util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.dm_0_util.min 0
onmne-fr-01;localhost:diskstats_utilization.dm_0_util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.dm_0_util.info Utilization of the device
onmne-fr-01;localhost:diskstats_utilization.dm_0_util.label dm-0
onmne-fr-01;localhost:diskstats_utilization.dm_0_util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.dm_0_util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.dm_0_util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop6_util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop6_util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop6_util.info Utilization of the device
onmne-fr-01;localhost:diskstats_utilization.loop6_util.label loop6
onmne-fr-01;localhost:diskstats_utilization.loop6_util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop6_util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop6_util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop3_util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop3_util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop3_util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop3_util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop3_util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop3_util.label loop3
onmne-fr-01;localhost:diskstats_utilization.loop3_util.info Utilization of the device
onmne-fr-01;localhost:diskstats_utilization.loop0_util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop0_util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop0_util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop0_util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop0_util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop0_util.label loop0
onmne-fr-01;localhost:diskstats_utilization.loop0_util.info Utilization of the device
onmne-fr-01;localhost:diskstats_utilization.sda_util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.sda_util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.sda_util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.sda_util.label sda
onmne-fr-01;localhost:diskstats_utilization.sda_util.info Utilization of the device
onmne-fr-01;localhost:diskstats_utilization.sda_util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.sda_util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop1_util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop1_util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop1_util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop1_util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop1_util.info Utilization of the device
onmne-fr-01;localhost:diskstats_utilization.loop1_util.label loop1
onmne-fr-01;localhost:diskstats_utilization.loop1_util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop5_util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop5_util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop5_util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop5_util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop5_util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop5_util.label loop5
onmne-fr-01;localhost:diskstats_utilization.loop5_util.info Utilization of the device
onmne-fr-01;localhost:diskstats_utilization.loop2_util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop2_util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop2_util.label loop2
onmne-fr-01;localhost:diskstats_utilization.loop2_util.info Utilization of the device
onmne-fr-01;localhost:diskstats_utilization.loop2_util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop2_util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop2_util.min 0
onmne-fr-01;localhost:diskstats_throughput.graph_title Throughput per device
onmne-fr-01;localhost:diskstats_throughput.graph_args --base 1024
onmne-fr-01;localhost:diskstats_throughput.graph_vlabel Bytes/${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_throughput.graph_category disk
onmne-fr-01;localhost:diskstats_throughput.graph_width 400
onmne-fr-01;localhost:diskstats_throughput.graph_info This graph shows averaged throughput for the given disk in bytes.  Higher throughput is usualy linked with higher service time/latency (separate graph).  The graph base is 1024 yeilding Kibi- and Mebi-bytes.
onmne-fr-01;localhost:diskstats_throughput.graph_order loop0_rdbytes loop0_wrbytes loop1_rdbytes loop1_wrbytes loop2_rdbytes loop2_wrbytes loop3_rdbytes loop3_wrbytes loop4_rdbytes loop4_wrbytes loop5_rdbytes loop5_wrbytes loop6_rdbytes loop6_wrbytes loop7_rdbytes loop7_wrbytes sda_rdbytes sda_wrbytes dm_0_rdbytes dm_0_wrbytes
onmne-fr-01;localhost:diskstats_throughput.loop5_rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop5_rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop5_rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop5_rdbytes.label loop5
onmne-fr-01;localhost:diskstats_throughput.loop5_rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop5_rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop5_rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop2_rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop2_rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop2_rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop2_rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop2_rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop2_rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop2_rdbytes.label loop2
onmne-fr-01;localhost:diskstats_throughput.loop7_rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop7_rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop7_rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop7_rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop7_rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop7_rdbytes.label loop7
onmne-fr-01;localhost:diskstats_throughput.loop7_rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop0_wrbytes.negative loop0_rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop0_wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop0_wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop0_wrbytes.label loop0
onmne-fr-01;localhost:diskstats_throughput.loop0_wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop0_wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop0_wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop3_wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop3_wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop3_wrbytes.negative loop3_rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop3_wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop3_wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop3_wrbytes.label loop3
onmne-fr-01;localhost:diskstats_throughput.loop3_wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.sda_rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.sda_rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.sda_rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.sda_rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.sda_rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.sda_rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.sda_rdbytes.label sda
onmne-fr-01;localhost:diskstats_throughput.dm_0_rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.dm_0_rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.dm_0_rdbytes.label dm-0
onmne-fr-01;localhost:diskstats_throughput.dm_0_rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.dm_0_rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.dm_0_rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.dm_0_rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop0_rdbytes.label loop0
onmne-fr-01;localhost:diskstats_throughput.loop0_rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop0_rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop0_rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop0_rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop0_rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop0_rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop3_rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop3_rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop3_rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop3_rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop3_rdbytes.label loop3
onmne-fr-01;localhost:diskstats_throughput.loop3_rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop3_rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.dm_0_wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.dm_0_wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.dm_0_wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.dm_0_wrbytes.label dm-0
onmne-fr-01;localhost:diskstats_throughput.dm_0_wrbytes.negative dm_0_rdbytes
onmne-fr-01;localhost:diskstats_throughput.dm_0_wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.dm_0_wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop5_wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop5_wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop5_wrbytes.label loop5
onmne-fr-01;localhost:diskstats_throughput.loop5_wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop5_wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop5_wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop5_wrbytes.negative loop5_rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop7_wrbytes.label loop7
onmne-fr-01;localhost:diskstats_throughput.loop7_wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop7_wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop7_wrbytes.negative loop7_rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop7_wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop7_wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop7_wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop2_wrbytes.negative loop2_rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop2_wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop2_wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop2_wrbytes.label loop2
onmne-fr-01;localhost:diskstats_throughput.loop2_wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop2_wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop2_wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop6_wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop6_wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop6_wrbytes.label loop6
onmne-fr-01;localhost:diskstats_throughput.loop6_wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop6_wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop6_wrbytes.negative loop6_rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop6_wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop1_rdbytes.label loop1
onmne-fr-01;localhost:diskstats_throughput.loop1_rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop1_rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop1_rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop1_rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop1_rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop1_rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop4_wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop4_wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop4_wrbytes.negative loop4_rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop4_wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop4_wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop4_wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop4_wrbytes.label loop4
onmne-fr-01;localhost:diskstats_throughput.sda_wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.sda_wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.sda_wrbytes.label sda
onmne-fr-01;localhost:diskstats_throughput.sda_wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.sda_wrbytes.negative sda_rdbytes
onmne-fr-01;localhost:diskstats_throughput.sda_wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.sda_wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop6_rdbytes.label loop6
onmne-fr-01;localhost:diskstats_throughput.loop6_rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop6_rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop6_rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop6_rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop6_rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop6_rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop1_wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop1_wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop1_wrbytes.label loop1
onmne-fr-01;localhost:diskstats_throughput.loop1_wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop1_wrbytes.negative loop1_rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop1_wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop1_wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop4_rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop4_rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop4_rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop4_rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop4_rdbytes.label loop4
onmne-fr-01;localhost:diskstats_throughput.loop4_rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop4_rdbytes.min 0
onmne-fr-01;localhost:diskstats_utilization.loop1.graph_title Disk utilization for /dev/loop1
onmne-fr-01;localhost:diskstats_utilization.loop1.graph_args --base 1000 --lower-limit 0 --upper-limit 100 --rigid
onmne-fr-01;localhost:diskstats_utilization.loop1.graph_vlabel % busy
onmne-fr-01;localhost:diskstats_utilization.loop1.graph_category disk
onmne-fr-01;localhost:diskstats_utilization.loop1.graph_scale no
onmne-fr-01;localhost:diskstats_utilization.loop1.graph_order util
onmne-fr-01;localhost:diskstats_utilization.loop1.util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop1.util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop1.util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop1.util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop1.util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop1.util.info Utilization of the device in percent. If the time spent for I/O is close to 1000msec for a given second, the device is nearly 100% saturated.
onmne-fr-01;localhost:diskstats_utilization.loop1.util.label Utilization
onmne-fr-01;localhost:diskstats_throughput.loop4.graph_title Disk throughput for /dev/loop4
onmne-fr-01;localhost:diskstats_throughput.loop4.graph_args --base 1024
onmne-fr-01;localhost:diskstats_throughput.loop4.graph_vlabel Pr ${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_throughput.loop4.graph_category disk
onmne-fr-01;localhost:diskstats_throughput.loop4.graph_info This graph shows disk throughput in bytes pr ${graph_period}.  The graph base is 1024 so KB is for Kibi bytes and so on.
onmne-fr-01;localhost:diskstats_throughput.loop4.graph_order rdbytes wrbytes
onmne-fr-01;localhost:diskstats_throughput.loop4.rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop4.rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop4.rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop4.rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop4.rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop4.rdbytes.label invisible
onmne-fr-01;localhost:diskstats_throughput.loop4.rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop4.wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop4.wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop4.wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop4.wrbytes.label Bytes
onmne-fr-01;localhost:diskstats_throughput.loop4.wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop4.wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop4.wrbytes.negative rdbytes
onmne-fr-01;localhost:diskstats_latency.loop4.graph_title Average latency for /dev/loop4
onmne-fr-01;localhost:diskstats_latency.loop4.graph_args --base 1000 --logarithmic
onmne-fr-01;localhost:diskstats_latency.loop4.graph_vlabel seconds
onmne-fr-01;localhost:diskstats_latency.loop4.graph_category disk
onmne-fr-01;localhost:diskstats_latency.loop4.graph_info This graph shows average waiting time/latency for different categories of disk operations.   The times that include the queue times indicate how busy your system is.  If the waiting time hits 1 second then your I/O system is 100% busy.
onmne-fr-01;localhost:diskstats_latency.loop4.graph_order svctm avgwait avgrdwait avgwrwait
onmne-fr-01;localhost:diskstats_latency.loop4.avgrdwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop4.avgrdwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop4.avgrdwait.info Average wait time for a read I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop4.avgrdwait.label Read IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop4.avgrdwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop4.avgrdwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop4.avgrdwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop4.avgrdwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop4.avgwrwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop4.avgwrwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop4.avgwrwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop4.avgwrwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop4.avgwrwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop4.avgwrwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop4.avgwrwait.label Write IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop4.avgwrwait.info Average wait time for a write I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop4.svctm.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop4.svctm.label Device IO time
onmne-fr-01;localhost:diskstats_latency.loop4.svctm.info Average time an I/O takes on the block device not including any queue times, just the round trip time for the disk request.
onmne-fr-01;localhost:diskstats_latency.loop4.svctm.min 0
onmne-fr-01;localhost:diskstats_latency.loop4.svctm.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop4.svctm.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop4.svctm.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop4.avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop4.avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop4.avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop4.avgwait.label IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop4.avgwait.info Average wait time for an I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop4.avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop4.avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.dm_0.graph_title Average latency for /dev/dm-0
onmne-fr-01;localhost:diskstats_latency.dm_0.graph_args --base 1000 --logarithmic
onmne-fr-01;localhost:diskstats_latency.dm_0.graph_vlabel seconds
onmne-fr-01;localhost:diskstats_latency.dm_0.graph_category disk
onmne-fr-01;localhost:diskstats_latency.dm_0.graph_info This graph shows average waiting time/latency for different categories of disk operations.   The times that include the queue times indicate how busy your system is.  If the waiting time hits 1 second then your I/O system is 100% busy.
onmne-fr-01;localhost:diskstats_latency.dm_0.graph_order svctm avgwait avgrdwait avgwrwait
onmne-fr-01;localhost:diskstats_latency.dm_0.avgrdwait.min 0
onmne-fr-01;localhost:diskstats_latency.dm_0.avgrdwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.dm_0.avgrdwait.label Read IO Wait time
onmne-fr-01;localhost:diskstats_latency.dm_0.avgrdwait.info Average wait time for a read I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.dm_0.avgrdwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.dm_0.avgrdwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.dm_0.avgrdwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.dm_0.avgrdwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwrwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwrwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwrwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwrwait.min 0
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwrwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwrwait.info Average wait time for a write I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwrwait.label Write IO Wait time
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwrwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwait.label IO Wait time
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwait.info Average wait time for an I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.dm_0.avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.dm_0.svctm.update_rate 300
onmne-fr-01;localhost:diskstats_latency.dm_0.svctm.draw LINE1
onmne-fr-01;localhost:diskstats_latency.dm_0.svctm.label Device IO time
onmne-fr-01;localhost:diskstats_latency.dm_0.svctm.info Average time an I/O takes on the block device not including any queue times, just the round trip time for the disk request.
onmne-fr-01;localhost:diskstats_latency.dm_0.svctm.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.dm_0.svctm.min 0
onmne-fr-01;localhost:diskstats_latency.dm_0.svctm.type GAUGE
onmne-fr-01;localhost:diskstats_iops.dm_0.graph_title IOs for /dev/dm-0
onmne-fr-01;localhost:diskstats_iops.dm_0.graph_args --base 1000
onmne-fr-01;localhost:diskstats_iops.dm_0.graph_vlabel Units read (-) / write (+)
onmne-fr-01;localhost:diskstats_iops.dm_0.graph_category disk
onmne-fr-01;localhost:diskstats_iops.dm_0.graph_info This graph shows the number of IO operations pr second and the average size of these requests.  Lots of small requests should result in in lower throughput (separate graph) and higher service time (separate graph).  Please note that starting with munin-node 2.0 the divisor for K is 1000 instead of 1024 which it was prior to 2.0 beta 3.  This is because the base for this graph is 1000 not 1024.
onmne-fr-01;localhost:diskstats_iops.dm_0.graph_order rdio wrio avgrdrqsz avgwrrqsz
onmne-fr-01;localhost:diskstats_iops.dm_0.avgwrrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.dm_0.avgwrrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.dm_0.avgwrrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.dm_0.avgwrrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.dm_0.avgwrrqsz.negative avgrdrqsz
onmne-fr-01;localhost:diskstats_iops.dm_0.avgwrrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.dm_0.avgwrrqsz.label Req Size (KB)
onmne-fr-01;localhost:diskstats_iops.dm_0.avgwrrqsz.info Average Request Size in kilobytes (1000 based)
onmne-fr-01;localhost:diskstats_iops.dm_0.rdio.min 0
onmne-fr-01;localhost:diskstats_iops.dm_0.rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.dm_0.rdio.label dummy
onmne-fr-01;localhost:diskstats_iops.dm_0.rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.dm_0.rdio.graph no
onmne-fr-01;localhost:diskstats_iops.dm_0.rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.dm_0.rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.dm_0.wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.dm_0.wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.dm_0.wrio.negative rdio
onmne-fr-01;localhost:diskstats_iops.dm_0.wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.dm_0.wrio.min 0
onmne-fr-01;localhost:diskstats_iops.dm_0.wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.dm_0.wrio.label IO/sec
onmne-fr-01;localhost:diskstats_iops.dm_0.avgrdrqsz.label dummy
onmne-fr-01;localhost:diskstats_iops.dm_0.avgrdrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.dm_0.avgrdrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.dm_0.avgrdrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.dm_0.avgrdrqsz.graph no
onmne-fr-01;localhost:diskstats_iops.dm_0.avgrdrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.dm_0.avgrdrqsz.update_rate 300
onmne-fr-01;localhost:if_eth0.graph_order down up down up
onmne-fr-01;localhost:if_eth0.graph_title eth0 traffic
onmne-fr-01;localhost:if_eth0.graph_args --base 1000
onmne-fr-01;localhost:if_eth0.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-fr-01;localhost:if_eth0.graph_category network
onmne-fr-01;localhost:if_eth0.graph_info This graph shows the traffic of the eth0 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-fr-01;localhost:if_eth0.up.min 0
onmne-fr-01;localhost:if_eth0.up.negative down
onmne-fr-01;localhost:if_eth0.up.type DERIVE
onmne-fr-01;localhost:if_eth0.up.label bps
onmne-fr-01;localhost:if_eth0.up.info Traffic of the eth0 interface. Maximum speed is 10000 Mb/s.
onmne-fr-01;localhost:if_eth0.up.cdef up,8,*
onmne-fr-01;localhost:if_eth0.up.graph_data_size normal
onmne-fr-01;localhost:if_eth0.up.max 10000000000
onmne-fr-01;localhost:if_eth0.up.update_rate 300
onmne-fr-01;localhost:if_eth0.down.update_rate 300
onmne-fr-01;localhost:if_eth0.down.max 10000000000
onmne-fr-01;localhost:if_eth0.down.graph no
onmne-fr-01;localhost:if_eth0.down.label received
onmne-fr-01;localhost:if_eth0.down.cdef down,8,*
onmne-fr-01;localhost:if_eth0.down.graph_data_size normal
onmne-fr-01;localhost:if_eth0.down.type DERIVE
onmne-fr-01;localhost:if_eth0.down.min 0
onmne-fr-01;localhost:entropy.graph_title Available entropy
onmne-fr-01;localhost:entropy.graph_args --base 1000 -l 0
onmne-fr-01;localhost:entropy.graph_vlabel entropy (bytes)
onmne-fr-01;localhost:entropy.graph_scale no
onmne-fr-01;localhost:entropy.graph_category system
onmne-fr-01;localhost:entropy.graph_info This graph shows the amount of entropy available in the system.
onmne-fr-01;localhost:entropy.graph_order entropy
onmne-fr-01;localhost:entropy.entropy.update_rate 300
onmne-fr-01;localhost:entropy.entropy.label entropy
onmne-fr-01;localhost:entropy.entropy.info The number of random bytes available. This is typically used by cryptographic applications.
onmne-fr-01;localhost:entropy.entropy.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop5.graph_title Disk utilization for /dev/loop5
onmne-fr-01;localhost:diskstats_utilization.loop5.graph_args --base 1000 --lower-limit 0 --upper-limit 100 --rigid
onmne-fr-01;localhost:diskstats_utilization.loop5.graph_vlabel % busy
onmne-fr-01;localhost:diskstats_utilization.loop5.graph_category disk
onmne-fr-01;localhost:diskstats_utilization.loop5.graph_scale no
onmne-fr-01;localhost:diskstats_utilization.loop5.graph_order util
onmne-fr-01;localhost:diskstats_utilization.loop5.util.label Utilization
onmne-fr-01;localhost:diskstats_utilization.loop5.util.info Utilization of the device in percent. If the time spent for I/O is close to 1000msec for a given second, the device is nearly 100% saturated.
onmne-fr-01;localhost:diskstats_utilization.loop5.util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop5.util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop5.util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop5.util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop5.util.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop0.graph_title Disk throughput for /dev/loop0
onmne-fr-01;localhost:diskstats_throughput.loop0.graph_args --base 1024
onmne-fr-01;localhost:diskstats_throughput.loop0.graph_vlabel Pr ${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_throughput.loop0.graph_category disk
onmne-fr-01;localhost:diskstats_throughput.loop0.graph_info This graph shows disk throughput in bytes pr ${graph_period}.  The graph base is 1024 so KB is for Kibi bytes and so on.
onmne-fr-01;localhost:diskstats_throughput.loop0.graph_order rdbytes wrbytes
onmne-fr-01;localhost:diskstats_throughput.loop0.rdbytes.label invisible
onmne-fr-01;localhost:diskstats_throughput.loop0.rdbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop0.rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop0.rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop0.rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop0.rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop0.rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop0.wrbytes.label Bytes
onmne-fr-01;localhost:diskstats_throughput.loop0.wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop0.wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop0.wrbytes.negative rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop0.wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop0.wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop0.wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop1.graph_title Average latency for /dev/loop1
onmne-fr-01;localhost:diskstats_latency.loop1.graph_args --base 1000 --logarithmic
onmne-fr-01;localhost:diskstats_latency.loop1.graph_vlabel seconds
onmne-fr-01;localhost:diskstats_latency.loop1.graph_category disk
onmne-fr-01;localhost:diskstats_latency.loop1.graph_info This graph shows average waiting time/latency for different categories of disk operations.   The times that include the queue times indicate how busy your system is.  If the waiting time hits 1 second then your I/O system is 100% busy.
onmne-fr-01;localhost:diskstats_latency.loop1.graph_order svctm avgwait avgrdwait avgwrwait
onmne-fr-01;localhost:diskstats_latency.loop1.avgwrwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop1.avgwrwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop1.avgwrwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop1.avgwrwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop1.avgwrwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop1.avgwrwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop1.avgwrwait.label Write IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop1.avgwrwait.info Average wait time for a write I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop1.avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop1.avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop1.avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop1.avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop1.avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop1.avgwait.label IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop1.avgwait.info Average wait time for an I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop1.svctm.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop1.svctm.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop1.svctm.min 0
onmne-fr-01;localhost:diskstats_latency.loop1.svctm.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop1.svctm.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop1.svctm.label Device IO time
onmne-fr-01;localhost:diskstats_latency.loop1.svctm.info Average time an I/O takes on the block device not including any queue times, just the round trip time for the disk request.
onmne-fr-01;localhost:diskstats_latency.loop1.avgrdwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop1.avgrdwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop1.avgrdwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop1.avgrdwait.label Read IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop1.avgrdwait.info Average wait time for a read I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop1.avgrdwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop1.avgrdwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop1.avgrdwait.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop2.graph_title Disk utilization for /dev/loop2
onmne-fr-01;localhost:diskstats_utilization.loop2.graph_args --base 1000 --lower-limit 0 --upper-limit 100 --rigid
onmne-fr-01;localhost:diskstats_utilization.loop2.graph_vlabel % busy
onmne-fr-01;localhost:diskstats_utilization.loop2.graph_category disk
onmne-fr-01;localhost:diskstats_utilization.loop2.graph_scale no
onmne-fr-01;localhost:diskstats_utilization.loop2.graph_order util
onmne-fr-01;localhost:diskstats_utilization.loop2.util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop2.util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop2.util.label Utilization
onmne-fr-01;localhost:diskstats_utilization.loop2.util.info Utilization of the device in percent. If the time spent for I/O is close to 1000msec for a given second, the device is nearly 100% saturated.
onmne-fr-01;localhost:diskstats_utilization.loop2.util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop2.util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop2.util.draw LINE1
onmne-fr-01;localhost:irqstats.graph_title Individual interrupts
onmne-fr-01;localhost:irqstats.graph_args --base 1000 --logarithmic
onmne-fr-01;localhost:irqstats.graph_vlabel interrupts / ${graph_period}
onmne-fr-01;localhost:irqstats.graph_category system
onmne-fr-01;localhost:irqstats.graph_info Shows the number of different IRQs received by the kernel.  High disk or network traffic can cause a high number of interrupts (with good hardware and drivers this will be less so). Sudden high interrupt activity with no associated higher system activity is not normal.
onmne-fr-01;localhost:irqstats.graph_order i0 i1 i8 i9 i12 i14 i15 i16 i17 i24 i25 i26 i27 i28 i29 i30 i31 i32 i33 i34 i35 i36 i37 i38 i39 i40 i41 i42 i43 i44 i45 i46 i47 i48 i49 i50 i51 i52 i53 i54 i55 i56 i57 i58 i59 i60 i61 i62 i63 i64 i65 i66 i67 iNMI iLOC iSPU iPMI iIWI iRTR iRES iCAL iTLB iTRM iTHR iDFR iMCE iMCP iERR iMIS iPIN iNPI iPIW i0 i1 i8 i9 i12 i14 i15 i16 i17 i24 i25 i26 i27 i28 i29 i30 i31 i32 i33 i34 i35 i36 i37 i38 i39 i40 i41 i42 i43 i44 i45 i46 i47 i48 i49 i50 i51 i52 i53 i54 i55 i56 i57 i58 i59 i60 i61 i62 i63 i64 i65 i66 i67 iNMI iLOC iSPU iPMI iIWI iRTR iRES iCAL iTLB iTRM iTHR iDFR iMCE iMCP iERR iMIS iPIN iNPI iPIW
onmne-fr-01;localhost:irqstats.i36.update_rate 300
onmne-fr-01;localhost:irqstats.i36.info Interrupt 36, for device(s): 368640-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i36.label 368640-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i36.graph_data_size normal
onmne-fr-01;localhost:irqstats.i36.type DERIVE
onmne-fr-01;localhost:irqstats.i36.min 0
onmne-fr-01;localhost:irqstats.i56.min 0
onmne-fr-01;localhost:irqstats.i56.type DERIVE
onmne-fr-01;localhost:irqstats.i56.graph_data_size normal
onmne-fr-01;localhost:irqstats.i56.label 1572864-edge      ens160-rxtx-0
onmne-fr-01;localhost:irqstats.i56.info Interrupt 56, for device(s): 1572864-edge      ens160-rxtx-0
onmne-fr-01;localhost:irqstats.i56.update_rate 300
onmne-fr-01;localhost:irqstats.i43.info Interrupt 43, for device(s): 382976-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i43.label 382976-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i43.graph_data_size normal
onmne-fr-01;localhost:irqstats.i43.min 0
onmne-fr-01;localhost:irqstats.i43.type DERIVE
onmne-fr-01;localhost:irqstats.i43.update_rate 300
onmne-fr-01;localhost:irqstats.i58.update_rate 300
onmne-fr-01;localhost:irqstats.i58.min 0
onmne-fr-01;localhost:irqstats.i58.type DERIVE
onmne-fr-01;localhost:irqstats.i58.label 1572866-edge      ens160-rxtx-2
onmne-fr-01;localhost:irqstats.i58.info Interrupt 58, for device(s): 1572866-edge      ens160-rxtx-2
onmne-fr-01;localhost:irqstats.i58.graph_data_size normal
onmne-fr-01;localhost:irqstats.i38.update_rate 300
onmne-fr-01;localhost:irqstats.i38.min 0
onmne-fr-01;localhost:irqstats.i38.type DERIVE
onmne-fr-01;localhost:irqstats.i38.label 372736-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i38.info Interrupt 38, for device(s): 372736-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i38.graph_data_size normal
onmne-fr-01;localhost:irqstats.i52.update_rate 300
onmne-fr-01;localhost:irqstats.i52.min 0
onmne-fr-01;localhost:irqstats.i52.type DERIVE
onmne-fr-01;localhost:irqstats.i52.graph_data_size normal
onmne-fr-01;localhost:irqstats.i52.label 401408-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i52.info Interrupt 52, for device(s): 401408-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i32.type DERIVE
onmne-fr-01;localhost:irqstats.i32.min 0
onmne-fr-01;localhost:irqstats.i32.info Interrupt 32, for device(s): 360448-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i32.label 360448-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i32.graph_data_size normal
onmne-fr-01;localhost:irqstats.i32.update_rate 300
onmne-fr-01;localhost:irqstats.iTHR.update_rate 300
onmne-fr-01;localhost:irqstats.iTHR.label Threshold APIC interrupts
onmne-fr-01;localhost:irqstats.iTHR.info Interrupt THR, for device(s): Threshold APIC interrupts
onmne-fr-01;localhost:irqstats.iTHR.graph_data_size normal
onmne-fr-01;localhost:irqstats.iTHR.min 0
onmne-fr-01;localhost:irqstats.iTHR.type DERIVE
onmne-fr-01;localhost:irqstats.i57.graph_data_size normal
onmne-fr-01;localhost:irqstats.i57.info Interrupt 57, for device(s): 1572865-edge      ens160-rxtx-1
onmne-fr-01;localhost:irqstats.i57.label 1572865-edge      ens160-rxtx-1
onmne-fr-01;localhost:irqstats.i57.min 0
onmne-fr-01;localhost:irqstats.i57.type DERIVE
onmne-fr-01;localhost:irqstats.i57.update_rate 300
onmne-fr-01;localhost:irqstats.i37.graph_data_size normal
onmne-fr-01;localhost:irqstats.i37.label 370688-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i37.info Interrupt 37, for device(s): 370688-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i37.min 0
onmne-fr-01;localhost:irqstats.i37.type DERIVE
onmne-fr-01;localhost:irqstats.i37.update_rate 300
onmne-fr-01;localhost:irqstats.iMCE.label Machine check exceptions
onmne-fr-01;localhost:irqstats.iMCE.info Interrupt MCE, for device(s): Machine check exceptions
onmne-fr-01;localhost:irqstats.iMCE.graph_data_size normal
onmne-fr-01;localhost:irqstats.iMCE.min 0
onmne-fr-01;localhost:irqstats.iMCE.type DERIVE
onmne-fr-01;localhost:irqstats.iMCE.update_rate 300
onmne-fr-01;localhost:irqstats.i25.min 0
onmne-fr-01;localhost:irqstats.i25.type DERIVE
onmne-fr-01;localhost:irqstats.i25.label 346112-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i25.info Interrupt 25, for device(s): 346112-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i25.graph_data_size normal
onmne-fr-01;localhost:irqstats.i25.update_rate 300
onmne-fr-01;localhost:irqstats.i39.update_rate 300
onmne-fr-01;localhost:irqstats.i39.type DERIVE
onmne-fr-01;localhost:irqstats.i39.min 0
onmne-fr-01;localhost:irqstats.i39.graph_data_size normal
onmne-fr-01;localhost:irqstats.i39.info Interrupt 39, for device(s): 374784-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i39.label 374784-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i59.update_rate 300
onmne-fr-01;localhost:irqstats.i59.graph_data_size normal
onmne-fr-01;localhost:irqstats.i59.info Interrupt 59, for device(s): 1572867-edge      ens160-rxtx-3
onmne-fr-01;localhost:irqstats.i59.label 1572867-edge      ens160-rxtx-3
onmne-fr-01;localhost:irqstats.i59.min 0
onmne-fr-01;localhost:irqstats.i59.type DERIVE
onmne-fr-01;localhost:irqstats.iDFR.update_rate 300
onmne-fr-01;localhost:irqstats.iDFR.graph_data_size normal
onmne-fr-01;localhost:irqstats.iDFR.label Deferred Error APIC interrupts
onmne-fr-01;localhost:irqstats.iDFR.info Interrupt DFR, for device(s): Deferred Error APIC interrupts
onmne-fr-01;localhost:irqstats.iDFR.type DERIVE
onmne-fr-01;localhost:irqstats.iDFR.min 0
onmne-fr-01;localhost:irqstats.i9.update_rate 300
onmne-fr-01;localhost:irqstats.i9.type DERIVE
onmne-fr-01;localhost:irqstats.i9.min 0
onmne-fr-01;localhost:irqstats.i9.graph_data_size normal
onmne-fr-01;localhost:irqstats.i9.label 9-fasteoi   acpi
onmne-fr-01;localhost:irqstats.i9.info Interrupt 9, for device(s): 9-fasteoi   acpi
onmne-fr-01;localhost:irqstats.i12.update_rate 300
onmne-fr-01;localhost:irqstats.i12.type DERIVE
onmne-fr-01;localhost:irqstats.i12.min 0
onmne-fr-01;localhost:irqstats.i12.graph_data_size normal
onmne-fr-01;localhost:irqstats.i12.label 12-edge      i8042
onmne-fr-01;localhost:irqstats.i12.info Interrupt 12, for device(s): 12-edge      i8042
onmne-fr-01;localhost:irqstats.i17.type DERIVE
onmne-fr-01;localhost:irqstats.i17.min 0
onmne-fr-01;localhost:irqstats.i17.info Interrupt 17, for device(s): 17-fasteoi   ioc0
onmne-fr-01;localhost:irqstats.i17.label 17-fasteoi   ioc0
onmne-fr-01;localhost:irqstats.i17.graph_data_size normal
onmne-fr-01;localhost:irqstats.i17.update_rate 300
onmne-fr-01;localhost:irqstats.iIWI.update_rate 300
onmne-fr-01;localhost:irqstats.iIWI.min 0
onmne-fr-01;localhost:irqstats.iIWI.type DERIVE
onmne-fr-01;localhost:irqstats.iIWI.label IRQ work interrupts
onmne-fr-01;localhost:irqstats.iIWI.info Interrupt IWI, for device(s): IRQ work interrupts
onmne-fr-01;localhost:irqstats.iIWI.graph_data_size normal
onmne-fr-01;localhost:irqstats.i16.graph_data_size normal
onmne-fr-01;localhost:irqstats.i16.label 16-fasteoi   vmwgfx
onmne-fr-01;localhost:irqstats.i16.info Interrupt 16, for device(s): 16-fasteoi   vmwgfx
onmne-fr-01;localhost:irqstats.i16.type DERIVE
onmne-fr-01;localhost:irqstats.i16.min 0
onmne-fr-01;localhost:irqstats.i16.update_rate 300
onmne-fr-01;localhost:irqstats.i45.min 0
onmne-fr-01;localhost:irqstats.i45.type DERIVE
onmne-fr-01;localhost:irqstats.i45.graph_data_size normal
onmne-fr-01;localhost:irqstats.i45.label 387072-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i45.info Interrupt 45, for device(s): 387072-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i45.update_rate 300
onmne-fr-01;localhost:irqstats.i40.min 0
onmne-fr-01;localhost:irqstats.i40.type DERIVE
onmne-fr-01;localhost:irqstats.i40.graph_data_size normal
onmne-fr-01;localhost:irqstats.i40.info Interrupt 40, for device(s): 376832-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i40.label 376832-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i40.update_rate 300
onmne-fr-01;localhost:irqstats.i41.info Interrupt 41, for device(s): 378880-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i41.label 378880-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i41.graph_data_size normal
onmne-fr-01;localhost:irqstats.i41.type DERIVE
onmne-fr-01;localhost:irqstats.i41.min 0
onmne-fr-01;localhost:irqstats.i41.update_rate 300
onmne-fr-01;localhost:irqstats.iPIN.graph_data_size normal
onmne-fr-01;localhost:irqstats.iPIN.label Posted-interrupt notification event
onmne-fr-01;localhost:irqstats.iPIN.info Interrupt PIN, for device(s): Posted-interrupt notification event
onmne-fr-01;localhost:irqstats.iPIN.type DERIVE
onmne-fr-01;localhost:irqstats.iPIN.min 0
onmne-fr-01;localhost:irqstats.iPIN.update_rate 300
onmne-fr-01;localhost:irqstats.iRTR.update_rate 300
onmne-fr-01;localhost:irqstats.iRTR.type DERIVE
onmne-fr-01;localhost:irqstats.iRTR.min 0
onmne-fr-01;localhost:irqstats.iRTR.label APIC ICR read retries
onmne-fr-01;localhost:irqstats.iRTR.info Interrupt RTR, for device(s): APIC ICR read retries
onmne-fr-01;localhost:irqstats.iRTR.graph_data_size normal
onmne-fr-01;localhost:irqstats.i1.info Interrupt 1, for device(s): 1-edge      i8042
onmne-fr-01;localhost:irqstats.i1.label 1-edge      i8042
onmne-fr-01;localhost:irqstats.i1.graph_data_size normal
onmne-fr-01;localhost:irqstats.i1.type DERIVE
onmne-fr-01;localhost:irqstats.i1.min 0
onmne-fr-01;localhost:irqstats.i1.update_rate 300
onmne-fr-01;localhost:irqstats.i66.update_rate 300
onmne-fr-01;localhost:irqstats.i66.label 129024-edge      vmw_vmci
onmne-fr-01;localhost:irqstats.i66.info Interrupt 66, for device(s): 129024-edge      vmw_vmci
onmne-fr-01;localhost:irqstats.i66.graph_data_size normal
onmne-fr-01;localhost:irqstats.i66.type DERIVE
onmne-fr-01;localhost:irqstats.i66.min 0
onmne-fr-01;localhost:irqstats.i62.label 1572870-edge      ens160-rxtx-6
onmne-fr-01;localhost:irqstats.i62.info Interrupt 62, for device(s): 1572870-edge      ens160-rxtx-6
onmne-fr-01;localhost:irqstats.i62.graph_data_size normal
onmne-fr-01;localhost:irqstats.i62.min 0
onmne-fr-01;localhost:irqstats.i62.type DERIVE
onmne-fr-01;localhost:irqstats.i62.update_rate 300
onmne-fr-01;localhost:irqstats.iTLB.type DERIVE
onmne-fr-01;localhost:irqstats.iTLB.min 0
onmne-fr-01;localhost:irqstats.iTLB.info Interrupt TLB, for device(s): TLB shootdowns
onmne-fr-01;localhost:irqstats.iTLB.label TLB shootdowns
onmne-fr-01;localhost:irqstats.iTLB.graph_data_size normal
onmne-fr-01;localhost:irqstats.iTLB.update_rate 300
onmne-fr-01;localhost:irqstats.i67.min 0
onmne-fr-01;localhost:irqstats.i67.type DERIVE
onmne-fr-01;localhost:irqstats.i67.graph_data_size normal
onmne-fr-01;localhost:irqstats.i67.info Interrupt 67, for device(s): 129025-edge      vmw_vmci
onmne-fr-01;localhost:irqstats.i67.label 129025-edge      vmw_vmci
onmne-fr-01;localhost:irqstats.i67.update_rate 300
onmne-fr-01;localhost:irqstats.i24.label 344064-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i24.info Interrupt 24, for device(s): 344064-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i24.graph_data_size normal
onmne-fr-01;localhost:irqstats.i24.min 0
onmne-fr-01;localhost:irqstats.i24.type DERIVE
onmne-fr-01;localhost:irqstats.i24.update_rate 300
onmne-fr-01;localhost:irqstats.i44.update_rate 300
onmne-fr-01;localhost:irqstats.i44.label 385024-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i44.info Interrupt 44, for device(s): 385024-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i44.graph_data_size normal
onmne-fr-01;localhost:irqstats.i44.min 0
onmne-fr-01;localhost:irqstats.i44.type DERIVE
onmne-fr-01;localhost:irqstats.iLOC.update_rate 300
onmne-fr-01;localhost:irqstats.iLOC.min 0
onmne-fr-01;localhost:irqstats.iLOC.type DERIVE
onmne-fr-01;localhost:irqstats.iLOC.graph_data_size normal
onmne-fr-01;localhost:irqstats.iLOC.label Local timer interrupts
onmne-fr-01;localhost:irqstats.iLOC.info Interrupt LOC, for device(s): Local timer interrupts
onmne-fr-01;localhost:irqstats.iRES.graph_data_size normal
onmne-fr-01;localhost:irqstats.iRES.label Rescheduling interrupts
onmne-fr-01;localhost:irqstats.iRES.info Interrupt RES, for device(s): Rescheduling interrupts
onmne-fr-01;localhost:irqstats.iRES.type DERIVE
onmne-fr-01;localhost:irqstats.iRES.min 0
onmne-fr-01;localhost:irqstats.iRES.update_rate 300
onmne-fr-01;localhost:irqstats.i49.update_rate 300
onmne-fr-01;localhost:irqstats.i49.type DERIVE
onmne-fr-01;localhost:irqstats.i49.min 0
onmne-fr-01;localhost:irqstats.i49.graph_data_size normal
onmne-fr-01;localhost:irqstats.i49.label 395264-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i49.info Interrupt 49, for device(s): 395264-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i0.update_rate 300
onmne-fr-01;localhost:irqstats.i0.type DERIVE
onmne-fr-01;localhost:irqstats.i0.min 0
onmne-fr-01;localhost:irqstats.i0.graph_data_size normal
onmne-fr-01;localhost:irqstats.i0.label 2-edge      timer
onmne-fr-01;localhost:irqstats.i0.info Interrupt 0, for device(s): 2-edge      timer
onmne-fr-01;localhost:irqstats.iERR.min 0
onmne-fr-01;localhost:irqstats.iERR.type DERIVE
onmne-fr-01;localhost:irqstats.iERR.graph_data_size normal
onmne-fr-01;localhost:irqstats.iERR.label ERR
onmne-fr-01;localhost:irqstats.iERR.update_rate 300
onmne-fr-01;localhost:irqstats.iCAL.update_rate 300
onmne-fr-01;localhost:irqstats.iCAL.info Interrupt CAL, for device(s): Function call interrupts
onmne-fr-01;localhost:irqstats.iCAL.label Function call interrupts
onmne-fr-01;localhost:irqstats.iCAL.graph_data_size normal
onmne-fr-01;localhost:irqstats.iCAL.min 0
onmne-fr-01;localhost:irqstats.iCAL.type DERIVE
onmne-fr-01;localhost:irqstats.i61.update_rate 300
onmne-fr-01;localhost:irqstats.i61.type DERIVE
onmne-fr-01;localhost:irqstats.i61.min 0
onmne-fr-01;localhost:irqstats.i61.label 1572869-edge      ens160-rxtx-5
onmne-fr-01;localhost:irqstats.i61.info Interrupt 61, for device(s): 1572869-edge      ens160-rxtx-5
onmne-fr-01;localhost:irqstats.i61.graph_data_size normal
onmne-fr-01;localhost:irqstats.iSPU.info Interrupt SPU, for device(s): Spurious interrupts
onmne-fr-01;localhost:irqstats.iSPU.label Spurious interrupts
onmne-fr-01;localhost:irqstats.iSPU.graph_data_size normal
onmne-fr-01;localhost:irqstats.iSPU.min 0
onmne-fr-01;localhost:irqstats.iSPU.type DERIVE
onmne-fr-01;localhost:irqstats.iSPU.update_rate 300
onmne-fr-01;localhost:irqstats.iTRM.info Interrupt TRM, for device(s): Thermal event interrupts
onmne-fr-01;localhost:irqstats.iTRM.label Thermal event interrupts
onmne-fr-01;localhost:irqstats.iTRM.graph_data_size normal
onmne-fr-01;localhost:irqstats.iTRM.min 0
onmne-fr-01;localhost:irqstats.iTRM.type DERIVE
onmne-fr-01;localhost:irqstats.iTRM.update_rate 300
onmne-fr-01;localhost:irqstats.i60.update_rate 300
onmne-fr-01;localhost:irqstats.i60.graph_data_size normal
onmne-fr-01;localhost:irqstats.i60.info Interrupt 60, for device(s): 1572868-edge      ens160-rxtx-4
onmne-fr-01;localhost:irqstats.i60.label 1572868-edge      ens160-rxtx-4
onmne-fr-01;localhost:irqstats.i60.min 0
onmne-fr-01;localhost:irqstats.i60.type DERIVE
onmne-fr-01;localhost:irqstats.iNMI.update_rate 300
onmne-fr-01;localhost:irqstats.iNMI.min 0
onmne-fr-01;localhost:irqstats.iNMI.type DERIVE
onmne-fr-01;localhost:irqstats.iNMI.graph_data_size normal
onmne-fr-01;localhost:irqstats.iNMI.info Interrupt NMI, for device(s): Non-maskable interrupts
onmne-fr-01;localhost:irqstats.iNMI.label Non-maskable interrupts
onmne-fr-01;localhost:irqstats.i55.label 407552-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i55.info Interrupt 55, for device(s): 407552-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i55.graph_data_size normal
onmne-fr-01;localhost:irqstats.i55.type DERIVE
onmne-fr-01;localhost:irqstats.i55.min 0
onmne-fr-01;localhost:irqstats.i55.update_rate 300
onmne-fr-01;localhost:irqstats.i35.min 0
onmne-fr-01;localhost:irqstats.i35.type DERIVE
onmne-fr-01;localhost:irqstats.i35.graph_data_size normal
onmne-fr-01;localhost:irqstats.i35.info Interrupt 35, for device(s): 366592-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i35.label 366592-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i35.update_rate 300
onmne-fr-01;localhost:irqstats.i29.update_rate 300
onmne-fr-01;localhost:irqstats.i29.graph_data_size normal
onmne-fr-01;localhost:irqstats.i29.info Interrupt 29, for device(s): 354304-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i29.label 354304-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i29.min 0
onmne-fr-01;localhost:irqstats.i29.type DERIVE
onmne-fr-01;localhost:irqstats.i47.type DERIVE
onmne-fr-01;localhost:irqstats.i47.min 0
onmne-fr-01;localhost:irqstats.i47.graph_data_size normal
onmne-fr-01;localhost:irqstats.i47.info Interrupt 47, for device(s): 391168-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i47.label 391168-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i47.update_rate 300
onmne-fr-01;localhost:irqstats.i48.info Interrupt 48, for device(s): 393216-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i48.label 393216-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i48.graph_data_size normal
onmne-fr-01;localhost:irqstats.i48.type DERIVE
onmne-fr-01;localhost:irqstats.i48.min 0
onmne-fr-01;localhost:irqstats.i48.update_rate 300
onmne-fr-01;localhost:irqstats.i42.update_rate 300
onmne-fr-01;localhost:irqstats.i42.min 0
onmne-fr-01;localhost:irqstats.i42.type DERIVE
onmne-fr-01;localhost:irqstats.i42.label 380928-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i42.info Interrupt 42, for device(s): 380928-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i42.graph_data_size normal
onmne-fr-01;localhost:irqstats.i33.type DERIVE
onmne-fr-01;localhost:irqstats.i33.min 0
onmne-fr-01;localhost:irqstats.i33.graph_data_size normal
onmne-fr-01;localhost:irqstats.i33.info Interrupt 33, for device(s): 362496-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i33.label 362496-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i33.update_rate 300
onmne-fr-01;localhost:irqstats.i53.graph_data_size normal
onmne-fr-01;localhost:irqstats.i53.info Interrupt 53, for device(s): 403456-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i53.label 403456-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i53.min 0
onmne-fr-01;localhost:irqstats.i53.type DERIVE
onmne-fr-01;localhost:irqstats.i53.update_rate 300
onmne-fr-01;localhost:irqstats.i15.min 0
onmne-fr-01;localhost:irqstats.i15.type DERIVE
onmne-fr-01;localhost:irqstats.i15.graph_data_size normal
onmne-fr-01;localhost:irqstats.i15.info Interrupt 15, for device(s): 15-edge      ata_piix
onmne-fr-01;localhost:irqstats.i15.label 15-edge      ata_piix
onmne-fr-01;localhost:irqstats.i15.update_rate 300
onmne-fr-01;localhost:irqstats.iPMI.graph_data_size normal
onmne-fr-01;localhost:irqstats.iPMI.info Interrupt PMI, for device(s): Performance monitoring interrupts
onmne-fr-01;localhost:irqstats.iPMI.label Performance monitoring interrupts
onmne-fr-01;localhost:irqstats.iPMI.min 0
onmne-fr-01;localhost:irqstats.iPMI.type DERIVE
onmne-fr-01;localhost:irqstats.iPMI.update_rate 300
onmne-fr-01;localhost:irqstats.iMIS.min 0
onmne-fr-01;localhost:irqstats.iMIS.type DERIVE
onmne-fr-01;localhost:irqstats.iMIS.graph_data_size normal
onmne-fr-01;localhost:irqstats.iMIS.label MIS
onmne-fr-01;localhost:irqstats.iMIS.update_rate 300
onmne-fr-01;localhost:irqstats.i46.info Interrupt 46, for device(s): 389120-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i46.label 389120-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i46.graph_data_size normal
onmne-fr-01;localhost:irqstats.i46.min 0
onmne-fr-01;localhost:irqstats.i46.type DERIVE
onmne-fr-01;localhost:irqstats.i46.update_rate 300
onmne-fr-01;localhost:irqstats.i26.label 348160-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i26.info Interrupt 26, for device(s): 348160-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i26.graph_data_size normal
onmne-fr-01;localhost:irqstats.i26.type DERIVE
onmne-fr-01;localhost:irqstats.i26.min 0
onmne-fr-01;localhost:irqstats.i26.update_rate 300
onmne-fr-01;localhost:irqstats.iPIW.min 0
onmne-fr-01;localhost:irqstats.iPIW.type DERIVE
onmne-fr-01;localhost:irqstats.iPIW.label Posted-interrupt wakeup event
onmne-fr-01;localhost:irqstats.iPIW.info Interrupt PIW, for device(s): Posted-interrupt wakeup event
onmne-fr-01;localhost:irqstats.iPIW.graph_data_size normal
onmne-fr-01;localhost:irqstats.iPIW.update_rate 300
onmne-fr-01;localhost:irqstats.i28.update_rate 300
onmne-fr-01;localhost:irqstats.i28.type DERIVE
onmne-fr-01;localhost:irqstats.i28.min 0
onmne-fr-01;localhost:irqstats.i28.graph_data_size normal
onmne-fr-01;localhost:irqstats.i28.info Interrupt 28, for device(s): 352256-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i28.label 352256-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i64.type DERIVE
onmne-fr-01;localhost:irqstats.i64.min 0
onmne-fr-01;localhost:irqstats.i64.graph_data_size normal
onmne-fr-01;localhost:irqstats.i64.info Interrupt 64, for device(s): 1572872-edge      ens160-event-8
onmne-fr-01;localhost:irqstats.i64.label 1572872-edge      ens160-event-8
onmne-fr-01;localhost:irqstats.i64.update_rate 300
onmne-fr-01;localhost:irqstats.i27.min 0
onmne-fr-01;localhost:irqstats.i27.type DERIVE
onmne-fr-01;localhost:irqstats.i27.label 350208-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i27.info Interrupt 27, for device(s): 350208-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i27.graph_data_size normal
onmne-fr-01;localhost:irqstats.i27.update_rate 300
onmne-fr-01;localhost:irqstats.i63.label 1572871-edge      ens160-rxtx-7
onmne-fr-01;localhost:irqstats.i63.info Interrupt 63, for device(s): 1572871-edge      ens160-rxtx-7
onmne-fr-01;localhost:irqstats.i63.graph_data_size normal
onmne-fr-01;localhost:irqstats.i63.type DERIVE
onmne-fr-01;localhost:irqstats.i63.min 0
onmne-fr-01;localhost:irqstats.i63.update_rate 300
onmne-fr-01;localhost:irqstats.i8.update_rate 300
onmne-fr-01;localhost:irqstats.i8.type DERIVE
onmne-fr-01;localhost:irqstats.i8.min 0
onmne-fr-01;localhost:irqstats.i8.graph_data_size normal
onmne-fr-01;localhost:irqstats.i8.label 8-edge      rtc0
onmne-fr-01;localhost:irqstats.i8.info Interrupt 8, for device(s): 8-edge      rtc0
onmne-fr-01;localhost:irqstats.iMCP.update_rate 300
onmne-fr-01;localhost:irqstats.iMCP.graph_data_size normal
onmne-fr-01;localhost:irqstats.iMCP.label Machine check polls
onmne-fr-01;localhost:irqstats.iMCP.info Interrupt MCP, for device(s): Machine check polls
onmne-fr-01;localhost:irqstats.iMCP.type DERIVE
onmne-fr-01;localhost:irqstats.iMCP.min 0
onmne-fr-01;localhost:irqstats.i54.type DERIVE
onmne-fr-01;localhost:irqstats.i54.min 0
onmne-fr-01;localhost:irqstats.i54.graph_data_size normal
onmne-fr-01;localhost:irqstats.i54.label 405504-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i54.info Interrupt 54, for device(s): 405504-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i54.update_rate 300
onmne-fr-01;localhost:irqstats.i34.update_rate 300
onmne-fr-01;localhost:irqstats.i34.graph_data_size normal
onmne-fr-01;localhost:irqstats.i34.info Interrupt 34, for device(s): 364544-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i34.label 364544-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i34.type DERIVE
onmne-fr-01;localhost:irqstats.i34.min 0
onmne-fr-01;localhost:irqstats.i51.min 0
onmne-fr-01;localhost:irqstats.i51.type DERIVE
onmne-fr-01;localhost:irqstats.i51.label 399360-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i51.info Interrupt 51, for device(s): 399360-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i51.graph_data_size normal
onmne-fr-01;localhost:irqstats.i51.update_rate 300
onmne-fr-01;localhost:irqstats.i31.type DERIVE
onmne-fr-01;localhost:irqstats.i31.min 0
onmne-fr-01;localhost:irqstats.i31.label 358400-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i31.info Interrupt 31, for device(s): 358400-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i31.graph_data_size normal
onmne-fr-01;localhost:irqstats.i31.update_rate 300
onmne-fr-01;localhost:irqstats.i14.label 14-edge      ata_piix
onmne-fr-01;localhost:irqstats.i14.info Interrupt 14, for device(s): 14-edge      ata_piix
onmne-fr-01;localhost:irqstats.i14.graph_data_size normal
onmne-fr-01;localhost:irqstats.i14.min 0
onmne-fr-01;localhost:irqstats.i14.type DERIVE
onmne-fr-01;localhost:irqstats.i14.update_rate 300
onmne-fr-01;localhost:irqstats.i50.update_rate 300
onmne-fr-01;localhost:irqstats.i50.min 0
onmne-fr-01;localhost:irqstats.i50.type DERIVE
onmne-fr-01;localhost:irqstats.i50.label 397312-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i50.info Interrupt 50, for device(s): 397312-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i50.graph_data_size normal
onmne-fr-01;localhost:irqstats.i30.type DERIVE
onmne-fr-01;localhost:irqstats.i30.min 0
onmne-fr-01;localhost:irqstats.i30.label 356352-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i30.info Interrupt 30, for device(s): 356352-edge      PCIe PME, pciehp
onmne-fr-01;localhost:irqstats.i30.graph_data_size normal
onmne-fr-01;localhost:irqstats.i30.update_rate 300
onmne-fr-01;localhost:irqstats.i65.update_rate 300
onmne-fr-01;localhost:irqstats.i65.type DERIVE
onmne-fr-01;localhost:irqstats.i65.min 0
onmne-fr-01;localhost:irqstats.i65.graph_data_size normal
onmne-fr-01;localhost:irqstats.i65.info Interrupt 65, for device(s): 1064960-edge      ahci[0000:02:01.0]
onmne-fr-01;localhost:irqstats.i65.label 1064960-edge      ahci[0000:02:01.0]
onmne-fr-01;localhost:irqstats.iNPI.graph_data_size normal
onmne-fr-01;localhost:irqstats.iNPI.label Nested posted-interrupt event
onmne-fr-01;localhost:irqstats.iNPI.info Interrupt NPI, for device(s): Nested posted-interrupt event
onmne-fr-01;localhost:irqstats.iNPI.type DERIVE
onmne-fr-01;localhost:irqstats.iNPI.min 0
onmne-fr-01;localhost:irqstats.iNPI.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop0.graph_title Disk utilization for /dev/loop0
onmne-fr-01;localhost:diskstats_utilization.loop0.graph_args --base 1000 --lower-limit 0 --upper-limit 100 --rigid
onmne-fr-01;localhost:diskstats_utilization.loop0.graph_vlabel % busy
onmne-fr-01;localhost:diskstats_utilization.loop0.graph_category disk
onmne-fr-01;localhost:diskstats_utilization.loop0.graph_scale no
onmne-fr-01;localhost:diskstats_utilization.loop0.graph_order util
onmne-fr-01;localhost:diskstats_utilization.loop0.util.draw LINE1
onmne-fr-01;localhost:diskstats_utilization.loop0.util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop0.util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop0.util.label Utilization
onmne-fr-01;localhost:diskstats_utilization.loop0.util.info Utilization of the device in percent. If the time spent for I/O is close to 1000msec for a given second, the device is nearly 100% saturated.
onmne-fr-01;localhost:diskstats_utilization.loop0.util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop0.util.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop6.graph_title Average latency for /dev/loop6
onmne-fr-01;localhost:diskstats_latency.loop6.graph_args --base 1000 --logarithmic
onmne-fr-01;localhost:diskstats_latency.loop6.graph_vlabel seconds
onmne-fr-01;localhost:diskstats_latency.loop6.graph_category disk
onmne-fr-01;localhost:diskstats_latency.loop6.graph_info This graph shows average waiting time/latency for different categories of disk operations.   The times that include the queue times indicate how busy your system is.  If the waiting time hits 1 second then your I/O system is 100% busy.
onmne-fr-01;localhost:diskstats_latency.loop6.graph_order svctm avgwait avgrdwait avgwrwait
onmne-fr-01;localhost:diskstats_latency.loop6.avgwrwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop6.avgwrwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop6.avgwrwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop6.avgwrwait.label Write IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop6.avgwrwait.info Average wait time for a write I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop6.avgwrwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop6.avgwrwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop6.avgwrwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop6.avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop6.avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop6.avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop6.avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop6.avgwait.label IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop6.avgwait.info Average wait time for an I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop6.avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop6.svctm.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop6.svctm.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop6.svctm.info Average time an I/O takes on the block device not including any queue times, just the round trip time for the disk request.
onmne-fr-01;localhost:diskstats_latency.loop6.svctm.label Device IO time
onmne-fr-01;localhost:diskstats_latency.loop6.svctm.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop6.svctm.min 0
onmne-fr-01;localhost:diskstats_latency.loop6.svctm.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop6.avgrdwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop6.avgrdwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop6.avgrdwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop6.avgrdwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop6.avgrdwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop6.avgrdwait.info Average wait time for a read I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop6.avgrdwait.label Read IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop6.avgrdwait.graph_data_size normal
onmne-fr-01;localhost:cpu.graph_title CPU usage
onmne-fr-01;localhost:cpu.graph_order system user nice idle iowait irq softirq system user nice idle iowait irq softirq steal guest
onmne-fr-01;localhost:cpu.graph_args --base 1000 -r --lower-limit 0 --upper-limit 800
onmne-fr-01;localhost:cpu.graph_vlabel %
onmne-fr-01;localhost:cpu.graph_scale no
onmne-fr-01;localhost:cpu.graph_info This graph shows how CPU time is spent.
onmne-fr-01;localhost:cpu.graph_category system
onmne-fr-01;localhost:cpu.graph_period second
onmne-fr-01;localhost:cpu.nice.update_rate 300
onmne-fr-01;localhost:cpu.nice.draw STACK
onmne-fr-01;localhost:cpu.nice.type DERIVE
onmne-fr-01;localhost:cpu.nice.min 0
onmne-fr-01;localhost:cpu.nice.graph_data_size normal
onmne-fr-01;localhost:cpu.nice.label nice
onmne-fr-01;localhost:cpu.nice.info CPU time spent by nice(1)d programs
onmne-fr-01;localhost:cpu.system.label system
onmne-fr-01;localhost:cpu.system.info CPU time spent by the kernel in system activities
onmne-fr-01;localhost:cpu.system.graph_data_size normal
onmne-fr-01;localhost:cpu.system.min 0
onmne-fr-01;localhost:cpu.system.type DERIVE
onmne-fr-01;localhost:cpu.system.update_rate 300
onmne-fr-01;localhost:cpu.system.draw AREA
onmne-fr-01;localhost:cpu.iowait.draw STACK
onmne-fr-01;localhost:cpu.iowait.update_rate 300
onmne-fr-01;localhost:cpu.iowait.label iowait
onmne-fr-01;localhost:cpu.iowait.info CPU time spent waiting for I/O operations to finish when there is nothing else to do.
onmne-fr-01;localhost:cpu.iowait.graph_data_size normal
onmne-fr-01;localhost:cpu.iowait.min 0
onmne-fr-01;localhost:cpu.iowait.type DERIVE
onmne-fr-01;localhost:cpu.guest.update_rate 300
onmne-fr-01;localhost:cpu.guest.draw STACK
onmne-fr-01;localhost:cpu.guest.label guest
onmne-fr-01;localhost:cpu.guest.info The time spent running a virtual CPU for guest operating systems under the control of the Linux kernel.
onmne-fr-01;localhost:cpu.guest.graph_data_size normal
onmne-fr-01;localhost:cpu.guest.type DERIVE
onmne-fr-01;localhost:cpu.guest.min 0
onmne-fr-01;localhost:cpu.irq.type DERIVE
onmne-fr-01;localhost:cpu.irq.min 0
onmne-fr-01;localhost:cpu.irq.info CPU time spent handling interrupts
onmne-fr-01;localhost:cpu.irq.label irq
onmne-fr-01;localhost:cpu.irq.graph_data_size normal
onmne-fr-01;localhost:cpu.irq.update_rate 300
onmne-fr-01;localhost:cpu.irq.draw STACK
onmne-fr-01;localhost:cpu.idle.draw STACK
onmne-fr-01;localhost:cpu.idle.update_rate 300
onmne-fr-01;localhost:cpu.idle.min 0
onmne-fr-01;localhost:cpu.idle.type DERIVE
onmne-fr-01;localhost:cpu.idle.graph_data_size normal
onmne-fr-01;localhost:cpu.idle.label idle
onmne-fr-01;localhost:cpu.idle.info Idle CPU time
onmne-fr-01;localhost:cpu.steal.graph_data_size normal
onmne-fr-01;localhost:cpu.steal.info The time that a virtual CPU had runnable tasks, but the virtual CPU itself was not running
onmne-fr-01;localhost:cpu.steal.label steal
onmne-fr-01;localhost:cpu.steal.min 0
onmne-fr-01;localhost:cpu.steal.type DERIVE
onmne-fr-01;localhost:cpu.steal.update_rate 300
onmne-fr-01;localhost:cpu.steal.draw STACK
onmne-fr-01;localhost:cpu.softirq.update_rate 300
onmne-fr-01;localhost:cpu.softirq.draw STACK
onmne-fr-01;localhost:cpu.softirq.graph_data_size normal
onmne-fr-01;localhost:cpu.softirq.label softirq
onmne-fr-01;localhost:cpu.softirq.info CPU time spent handling "batched" interrupts
onmne-fr-01;localhost:cpu.softirq.min 0
onmne-fr-01;localhost:cpu.softirq.type DERIVE
onmne-fr-01;localhost:cpu.user.draw STACK
onmne-fr-01;localhost:cpu.user.update_rate 300
onmne-fr-01;localhost:cpu.user.min 0
onmne-fr-01;localhost:cpu.user.type DERIVE
onmne-fr-01;localhost:cpu.user.graph_data_size normal
onmne-fr-01;localhost:cpu.user.info CPU time spent by normal programs and daemons
onmne-fr-01;localhost:cpu.user.label user
onmne-fr-01;localhost:diskstats_throughput.loop6.graph_title Disk throughput for /dev/loop6
onmne-fr-01;localhost:diskstats_throughput.loop6.graph_args --base 1024
onmne-fr-01;localhost:diskstats_throughput.loop6.graph_vlabel Pr ${graph_period} read (-) / write (+)
onmne-fr-01;localhost:diskstats_throughput.loop6.graph_category disk
onmne-fr-01;localhost:diskstats_throughput.loop6.graph_info This graph shows disk throughput in bytes pr ${graph_period}.  The graph base is 1024 so KB is for Kibi bytes and so on.
onmne-fr-01;localhost:diskstats_throughput.loop6.graph_order rdbytes wrbytes
onmne-fr-01;localhost:diskstats_throughput.loop6.wrbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop6.wrbytes.negative rdbytes
onmne-fr-01;localhost:diskstats_throughput.loop6.wrbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop6.wrbytes.graph_data_size normal
onmne-fr-01;localhost:diskstats_throughput.loop6.wrbytes.label Bytes
onmne-fr-01;localhost:diskstats_throughput.loop6.wrbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop6.wrbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop6.rdbytes.update_rate 300
onmne-fr-01;localhost:diskstats_throughput.loop6.rdbytes.graph no
onmne-fr-01;localhost:diskstats_throughput.loop6.rdbytes.draw LINE1
onmne-fr-01;localhost:diskstats_throughput.loop6.rdbytes.min 0
onmne-fr-01;localhost:diskstats_throughput.loop6.rdbytes.type GAUGE
onmne-fr-01;localhost:diskstats_throughput.loop6.rdbytes.label invisible
onmne-fr-01;localhost:diskstats_throughput.loop6.rdbytes.graph_data_size normal
onmne-fr-01;localhost:vmstat.graph_title VMstat
onmne-fr-01;localhost:vmstat.graph_args --base 1000 -l 0
onmne-fr-01;localhost:vmstat.graph_vlabel process states
onmne-fr-01;localhost:vmstat.graph_category processes
onmne-fr-01;localhost:vmstat.graph_order wait sleep
onmne-fr-01;localhost:vmstat.wait.type GAUGE
onmne-fr-01;localhost:vmstat.wait.graph_data_size normal
onmne-fr-01;localhost:vmstat.wait.label running
onmne-fr-01;localhost:vmstat.wait.update_rate 300
onmne-fr-01;localhost:vmstat.wait.max 500000
onmne-fr-01;localhost:vmstat.sleep.update_rate 300
onmne-fr-01;localhost:vmstat.sleep.max 500000
onmne-fr-01;localhost:vmstat.sleep.type GAUGE
onmne-fr-01;localhost:vmstat.sleep.label I/O sleep
onmne-fr-01;localhost:vmstat.sleep.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop3.graph_title IOs for /dev/loop3
onmne-fr-01;localhost:diskstats_iops.loop3.graph_args --base 1000
onmne-fr-01;localhost:diskstats_iops.loop3.graph_vlabel Units read (-) / write (+)
onmne-fr-01;localhost:diskstats_iops.loop3.graph_category disk
onmne-fr-01;localhost:diskstats_iops.loop3.graph_info This graph shows the number of IO operations pr second and the average size of these requests.  Lots of small requests should result in in lower throughput (separate graph) and higher service time (separate graph).  Please note that starting with munin-node 2.0 the divisor for K is 1000 instead of 1024 which it was prior to 2.0 beta 3.  This is because the base for this graph is 1000 not 1024.
onmne-fr-01;localhost:diskstats_iops.loop3.graph_order rdio wrio avgrdrqsz avgwrrqsz
onmne-fr-01;localhost:diskstats_iops.loop3.rdio.label dummy
onmne-fr-01;localhost:diskstats_iops.loop3.rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop3.rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop3.rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop3.rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop3.rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop3.rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop3.wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop3.wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop3.wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop3.wrio.negative rdio
onmne-fr-01;localhost:diskstats_iops.loop3.wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop3.wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop3.wrio.label IO/sec
onmne-fr-01;localhost:diskstats_iops.loop3.avgrdrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop3.avgrdrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop3.avgrdrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop3.avgrdrqsz.label dummy
onmne-fr-01;localhost:diskstats_iops.loop3.avgrdrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop3.avgrdrqsz.graph no
onmne-fr-01;localhost:diskstats_iops.loop3.avgrdrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop3.avgwrrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop3.avgwrrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop3.avgwrrqsz.info Average Request Size in kilobytes (1000 based)
onmne-fr-01;localhost:diskstats_iops.loop3.avgwrrqsz.label Req Size (KB)
onmne-fr-01;localhost:diskstats_iops.loop3.avgwrrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop3.avgwrrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop3.avgwrrqsz.negative avgrdrqsz
onmne-fr-01;localhost:diskstats_iops.loop3.avgwrrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop5.graph_title Average latency for /dev/loop5
onmne-fr-01;localhost:diskstats_latency.loop5.graph_args --base 1000 --logarithmic
onmne-fr-01;localhost:diskstats_latency.loop5.graph_vlabel seconds
onmne-fr-01;localhost:diskstats_latency.loop5.graph_category disk
onmne-fr-01;localhost:diskstats_latency.loop5.graph_info This graph shows average waiting time/latency for different categories of disk operations.   The times that include the queue times indicate how busy your system is.  If the waiting time hits 1 second then your I/O system is 100% busy.
onmne-fr-01;localhost:diskstats_latency.loop5.graph_order svctm avgwait avgrdwait avgwrwait
onmne-fr-01;localhost:diskstats_latency.loop5.avgwait.label IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop5.avgwait.info Average wait time for an I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop5.avgwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop5.avgwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop5.avgwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop5.avgwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop5.avgwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop5.svctm.label Device IO time
onmne-fr-01;localhost:diskstats_latency.loop5.svctm.info Average time an I/O takes on the block device not including any queue times, just the round trip time for the disk request.
onmne-fr-01;localhost:diskstats_latency.loop5.svctm.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop5.svctm.min 0
onmne-fr-01;localhost:diskstats_latency.loop5.svctm.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop5.svctm.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop5.svctm.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop5.avgwrwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop5.avgwrwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop5.avgwrwait.draw LINE1
onmne-fr-01;localhost:diskstats_latency.loop5.avgwrwait.label Write IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop5.avgwrwait.info Average wait time for a write I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop5.avgwrwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop5.avgwrwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop5.avgwrwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop5.avgrdwait.graph_data_size normal
onmne-fr-01;localhost:diskstats_latency.loop5.avgrdwait.info Average wait time for a read I/O from request start to finish (includes queue times et al)
onmne-fr-01;localhost:diskstats_latency.loop5.avgrdwait.label Read IO Wait time
onmne-fr-01;localhost:diskstats_latency.loop5.avgrdwait.type GAUGE
onmne-fr-01;localhost:diskstats_latency.loop5.avgrdwait.min 0
onmne-fr-01;localhost:diskstats_latency.loop5.avgrdwait.warning 0:3
onmne-fr-01;localhost:diskstats_latency.loop5.avgrdwait.update_rate 300
onmne-fr-01;localhost:diskstats_latency.loop5.avgrdwait.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop2.graph_title IOs for /dev/loop2
onmne-fr-01;localhost:diskstats_iops.loop2.graph_args --base 1000
onmne-fr-01;localhost:diskstats_iops.loop2.graph_vlabel Units read (-) / write (+)
onmne-fr-01;localhost:diskstats_iops.loop2.graph_category disk
onmne-fr-01;localhost:diskstats_iops.loop2.graph_info This graph shows the number of IO operations pr second and the average size of these requests.  Lots of small requests should result in in lower throughput (separate graph) and higher service time (separate graph).  Please note that starting with munin-node 2.0 the divisor for K is 1000 instead of 1024 which it was prior to 2.0 beta 3.  This is because the base for this graph is 1000 not 1024.
onmne-fr-01;localhost:diskstats_iops.loop2.graph_order rdio wrio avgrdrqsz avgwrrqsz
onmne-fr-01;localhost:diskstats_iops.loop2.rdio.label dummy
onmne-fr-01;localhost:diskstats_iops.loop2.rdio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop2.rdio.min 0
onmne-fr-01;localhost:diskstats_iops.loop2.rdio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop2.rdio.graph no
onmne-fr-01;localhost:diskstats_iops.loop2.rdio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop2.rdio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop2.wrio.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop2.wrio.label IO/sec
onmne-fr-01;localhost:diskstats_iops.loop2.wrio.negative rdio
onmne-fr-01;localhost:diskstats_iops.loop2.wrio.min 0
onmne-fr-01;localhost:diskstats_iops.loop2.wrio.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop2.wrio.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop2.wrio.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop2.avgrdrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop2.avgrdrqsz.graph no
onmne-fr-01;localhost:diskstats_iops.loop2.avgrdrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop2.avgrdrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop2.avgrdrqsz.min 0
onmne-fr-01;localhost:diskstats_iops.loop2.avgrdrqsz.label dummy
onmne-fr-01;localhost:diskstats_iops.loop2.avgrdrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop2.avgwrrqsz.update_rate 300
onmne-fr-01;localhost:diskstats_iops.loop2.avgwrrqsz.draw LINE1
onmne-fr-01;localhost:diskstats_iops.loop2.avgwrrqsz.info Average Request Size in kilobytes (1000 based)
onmne-fr-01;localhost:diskstats_iops.loop2.avgwrrqsz.label Req Size (KB)
onmne-fr-01;localhost:diskstats_iops.loop2.avgwrrqsz.graph_data_size normal
onmne-fr-01;localhost:diskstats_iops.loop2.avgwrrqsz.type GAUGE
onmne-fr-01;localhost:diskstats_iops.loop2.avgwrrqsz.negative avgrdrqsz
onmne-fr-01;localhost:diskstats_iops.loop2.avgwrrqsz.min 0
onmne-fr-01;localhost:diskstats_utilization.loop6.graph_title Disk utilization for /dev/loop6
onmne-fr-01;localhost:diskstats_utilization.loop6.graph_args --base 1000 --lower-limit 0 --upper-limit 100 --rigid
onmne-fr-01;localhost:diskstats_utilization.loop6.graph_vlabel % busy
onmne-fr-01;localhost:diskstats_utilization.loop6.graph_category disk
onmne-fr-01;localhost:diskstats_utilization.loop6.graph_scale no
onmne-fr-01;localhost:diskstats_utilization.loop6.graph_order util
onmne-fr-01;localhost:diskstats_utilization.loop6.util.graph_data_size normal
onmne-fr-01;localhost:diskstats_utilization.loop6.util.label Utilization
onmne-fr-01;localhost:diskstats_utilization.loop6.util.info Utilization of the device in percent. If the time spent for I/O is close to 1000msec for a given second, the device is nearly 100% saturated.
onmne-fr-01;localhost:diskstats_utilization.loop6.util.min 0
onmne-fr-01;localhost:diskstats_utilization.loop6.util.type GAUGE
onmne-fr-01;localhost:diskstats_utilization.loop6.util.update_rate 300
onmne-fr-01;localhost:diskstats_utilization.loop6.util.draw LINE1
onmne-fr-01;localhost:fw_packets.graph_title Firewall Throughput
onmne-fr-01;localhost:fw_packets.graph_args --base 1000 -l 0
onmne-fr-01;localhost:fw_packets.graph_vlabel Packets/${graph_period}
onmne-fr-01;localhost:fw_packets.graph_category network
onmne-fr-01;localhost:fw_packets.graph_order received forwarded
onmne-fr-01;localhost:fw_packets.forwarded.label Forwarded
onmne-fr-01;localhost:fw_packets.forwarded.graph_data_size normal
onmne-fr-01;localhost:fw_packets.forwarded.min 0
onmne-fr-01;localhost:fw_packets.forwarded.type DERIVE
onmne-fr-01;localhost:fw_packets.forwarded.draw LINE2
onmne-fr-01;localhost:fw_packets.forwarded.update_rate 300
onmne-fr-01;localhost:fw_packets.received.label Received
onmne-fr-01;localhost:fw_packets.received.graph_data_size normal
onmne-fr-01;localhost:fw_packets.received.min 0
onmne-fr-01;localhost:fw_packets.received.type DERIVE
onmne-fr-01;localhost:fw_packets.received.update_rate 300
onmne-fr-01;localhost:fw_packets.received.draw AREA
onmne-db-02;onmne-db-02:if_veth3aa50f8.graph_order down up down up
onmne-db-02;onmne-db-02:if_veth3aa50f8.graph_title veth3aa50f8 traffic
onmne-db-02;onmne-db-02:if_veth3aa50f8.graph_args --base 1000
onmne-db-02;onmne-db-02:if_veth3aa50f8.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_veth3aa50f8.graph_category network
onmne-db-02;onmne-db-02:if_veth3aa50f8.graph_info This graph shows the traffic of the veth3aa50f8 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-02;onmne-db-02:if_veth3aa50f8.down.type DERIVE
onmne-db-02;onmne-db-02:if_veth3aa50f8.down.min 0
onmne-db-02;onmne-db-02:if_veth3aa50f8.down.cdef down,8,*
onmne-db-02;onmne-db-02:if_veth3aa50f8.down.graph_data_size normal
onmne-db-02;onmne-db-02:if_veth3aa50f8.down.label received
onmne-db-02;onmne-db-02:if_veth3aa50f8.down.update_rate 300
onmne-db-02;onmne-db-02:if_veth3aa50f8.down.graph no
onmne-db-02;onmne-db-02:if_veth3aa50f8.up.min 0
onmne-db-02;onmne-db-02:if_veth3aa50f8.up.type DERIVE
onmne-db-02;onmne-db-02:if_veth3aa50f8.up.negative down
onmne-db-02;onmne-db-02:if_veth3aa50f8.up.info Traffic of the veth3aa50f8 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-02;onmne-db-02:if_veth3aa50f8.up.label bps
onmne-db-02;onmne-db-02:if_veth3aa50f8.up.cdef up,8,*
onmne-db-02;onmne-db-02:if_veth3aa50f8.up.graph_data_size normal
onmne-db-02;onmne-db-02:if_veth3aa50f8.up.update_rate 300
onmne-db-02;onmne-db-02:vmstat.graph_title VMstat
onmne-db-02;onmne-db-02:vmstat.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:vmstat.graph_vlabel process states
onmne-db-02;onmne-db-02:vmstat.graph_category processes
onmne-db-02;onmne-db-02:vmstat.graph_order wait sleep
onmne-db-02;onmne-db-02:vmstat.sleep.type GAUGE
onmne-db-02;onmne-db-02:vmstat.sleep.label I/O sleep
onmne-db-02;onmne-db-02:vmstat.sleep.graph_data_size normal
onmne-db-02;onmne-db-02:vmstat.sleep.update_rate 300
onmne-db-02;onmne-db-02:vmstat.sleep.max 500000
onmne-db-02;onmne-db-02:vmstat.wait.max 500000
onmne-db-02;onmne-db-02:vmstat.wait.update_rate 300
onmne-db-02;onmne-db-02:vmstat.wait.type GAUGE
onmne-db-02;onmne-db-02:vmstat.wait.graph_data_size normal
onmne-db-02;onmne-db-02:vmstat.wait.label running
onmne-db-02;onmne-db-02:if_err_ens160.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-02;onmne-db-02:if_err_ens160.graph_title ens160 errors
onmne-db-02;onmne-db-02:if_err_ens160.graph_args --base 1000
onmne-db-02;onmne-db-02:if_err_ens160.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_err_ens160.graph_category network
onmne-db-02;onmne-db-02:if_err_ens160.graph_info This graph shows the amount of errors, packet drops, and collisions on the ens160 network interface.
onmne-db-02;onmne-db-02:if_err_ens160.trans.type COUNTER
onmne-db-02;onmne-db-02:if_err_ens160.trans.negative rcvd
onmne-db-02;onmne-db-02:if_err_ens160.trans.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_ens160.trans.label errors
onmne-db-02;onmne-db-02:if_err_ens160.trans.update_rate 300
onmne-db-02;onmne-db-02:if_err_ens160.trans.warning 1
onmne-db-02;onmne-db-02:if_err_ens160.rxdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_ens160.rxdrop.graph no
onmne-db-02;onmne-db-02:if_err_ens160.rxdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_ens160.rxdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_ens160.rxdrop.label drops
onmne-db-02;onmne-db-02:if_err_ens160.collisions.type COUNTER
onmne-db-02;onmne-db-02:if_err_ens160.collisions.update_rate 300
onmne-db-02;onmne-db-02:if_err_ens160.collisions.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_ens160.collisions.label collisions
onmne-db-02;onmne-db-02:if_err_ens160.txdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_ens160.txdrop.label drops
onmne-db-02;onmne-db-02:if_err_ens160.txdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_ens160.txdrop.negative rxdrop
onmne-db-02;onmne-db-02:if_err_ens160.txdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_ens160.rcvd.type COUNTER
onmne-db-02;onmne-db-02:if_err_ens160.rcvd.label errors
onmne-db-02;onmne-db-02:if_err_ens160.rcvd.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_ens160.rcvd.graph no
onmne-db-02;onmne-db-02:if_err_ens160.rcvd.update_rate 300
onmne-db-02;onmne-db-02:if_err_ens160.rcvd.warning 1
onmne-db-02;onmne-db-02:fw_packets.graph_title Firewall Throughput
onmne-db-02;onmne-db-02:fw_packets.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:fw_packets.graph_vlabel Packets/${graph_period}
onmne-db-02;onmne-db-02:fw_packets.graph_category network
onmne-db-02;onmne-db-02:fw_packets.graph_order received forwarded
onmne-db-02;onmne-db-02:fw_packets.forwarded.label Forwarded
onmne-db-02;onmne-db-02:fw_packets.forwarded.graph_data_size normal
onmne-db-02;onmne-db-02:fw_packets.forwarded.type DERIVE
onmne-db-02;onmne-db-02:fw_packets.forwarded.min 0
onmne-db-02;onmne-db-02:fw_packets.forwarded.update_rate 300
onmne-db-02;onmne-db-02:fw_packets.forwarded.draw LINE2
onmne-db-02;onmne-db-02:fw_packets.received.min 0
onmne-db-02;onmne-db-02:fw_packets.received.type DERIVE
onmne-db-02;onmne-db-02:fw_packets.received.graph_data_size normal
onmne-db-02;onmne-db-02:fw_packets.received.label Received
onmne-db-02;onmne-db-02:fw_packets.received.draw AREA
onmne-db-02;onmne-db-02:fw_packets.received.update_rate 300
onmne-db-02;onmne-db-02:netstat.graph_title Netstat
onmne-db-02;onmne-db-02:netstat.graph_args --base 1000 --logarithmic
onmne-db-02;onmne-db-02:netstat.graph_vlabel TCP connections
onmne-db-02;onmne-db-02:netstat.graph_category network
onmne-db-02;onmne-db-02:netstat.graph_period second
onmne-db-02;onmne-db-02:netstat.graph_info This graph shows the TCP activity of all the network interfaces combined.
onmne-db-02;onmne-db-02:netstat.graph_order active passive failed resets established
onmne-db-02;onmne-db-02:netstat.resets.max 50000
onmne-db-02;onmne-db-02:netstat.resets.update_rate 300
onmne-db-02;onmne-db-02:netstat.resets.info The number of TCP connection resets.
onmne-db-02;onmne-db-02:netstat.resets.label resets
onmne-db-02;onmne-db-02:netstat.resets.graph_data_size normal
onmne-db-02;onmne-db-02:netstat.resets.min 0
onmne-db-02;onmne-db-02:netstat.resets.type DERIVE
onmne-db-02;onmne-db-02:netstat.failed.min 0
onmne-db-02;onmne-db-02:netstat.failed.type DERIVE
onmne-db-02;onmne-db-02:netstat.failed.graph_data_size normal
onmne-db-02;onmne-db-02:netstat.failed.label failed
onmne-db-02;onmne-db-02:netstat.failed.info The number of failed TCP connection attempts per second.
onmne-db-02;onmne-db-02:netstat.failed.update_rate 300
onmne-db-02;onmne-db-02:netstat.failed.max 50000
onmne-db-02;onmne-db-02:netstat.active.graph_data_size normal
onmne-db-02;onmne-db-02:netstat.active.label active
onmne-db-02;onmne-db-02:netstat.active.info The number of active TCP openings per second.
onmne-db-02;onmne-db-02:netstat.active.min 0
onmne-db-02;onmne-db-02:netstat.active.type DERIVE
onmne-db-02;onmne-db-02:netstat.active.max 50000
onmne-db-02;onmne-db-02:netstat.active.update_rate 300
onmne-db-02;onmne-db-02:netstat.established.update_rate 300
onmne-db-02;onmne-db-02:netstat.established.max 50000
onmne-db-02;onmne-db-02:netstat.established.info The number of currently open connections.
onmne-db-02;onmne-db-02:netstat.established.label established
onmne-db-02;onmne-db-02:netstat.established.graph_data_size normal
onmne-db-02;onmne-db-02:netstat.established.type GAUGE
onmne-db-02;onmne-db-02:netstat.passive.update_rate 300
onmne-db-02;onmne-db-02:netstat.passive.max 50000
onmne-db-02;onmne-db-02:netstat.passive.label passive
onmne-db-02;onmne-db-02:netstat.passive.info The number of passive TCP openings per second.
onmne-db-02;onmne-db-02:netstat.passive.graph_data_size normal
onmne-db-02;onmne-db-02:netstat.passive.type DERIVE
onmne-db-02;onmne-db-02:netstat.passive.min 0
onmne-db-02;onmne-db-02:if_ens160.graph_order down up down up
onmne-db-02;onmne-db-02:if_ens160.graph_title ens160 traffic
onmne-db-02;onmne-db-02:if_ens160.graph_args --base 1000
onmne-db-02;onmne-db-02:if_ens160.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_ens160.graph_category network
onmne-db-02;onmne-db-02:if_ens160.graph_info This graph shows the traffic of the ens160 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-02;onmne-db-02:if_ens160.down.graph no
onmne-db-02;onmne-db-02:if_ens160.down.max 10000000000
onmne-db-02;onmne-db-02:if_ens160.down.update_rate 300
onmne-db-02;onmne-db-02:if_ens160.down.min 0
onmne-db-02;onmne-db-02:if_ens160.down.type DERIVE
onmne-db-02;onmne-db-02:if_ens160.down.label received
onmne-db-02;onmne-db-02:if_ens160.down.cdef down,8,*
onmne-db-02;onmne-db-02:if_ens160.down.graph_data_size normal
onmne-db-02;onmne-db-02:if_ens160.up.update_rate 300
onmne-db-02;onmne-db-02:if_ens160.up.max 10000000000
onmne-db-02;onmne-db-02:if_ens160.up.graph_data_size normal
onmne-db-02;onmne-db-02:if_ens160.up.cdef up,8,*
onmne-db-02;onmne-db-02:if_ens160.up.label bps
onmne-db-02;onmne-db-02:if_ens160.up.info Traffic of the ens160 interface. Maximum speed is 10000 Mb/s.
onmne-db-02;onmne-db-02:if_ens160.up.min 0
onmne-db-02;onmne-db-02:if_ens160.up.negative down
onmne-db-02;onmne-db-02:if_ens160.up.type DERIVE
onmne-db-02;onmne-db-02:memory.graph_args --base 1024 -l 0 --upper-limit 33676906496
onmne-db-02;onmne-db-02:memory.graph_vlabel Bytes
onmne-db-02;onmne-db-02:memory.graph_title Memory usage
onmne-db-02;onmne-db-02:memory.graph_category system
onmne-db-02;onmne-db-02:memory.graph_info This graph shows what the machine uses memory for.
onmne-db-02;onmne-db-02:memory.graph_order apps page_tables swap_cache slab cached buffers free swap apps buffers swap cached free slab swap_cache page_tables vmalloc_used committed mapped active inactive
onmne-db-02;onmne-db-02:memory.slab.update_rate 300
onmne-db-02;onmne-db-02:memory.slab.draw STACK
onmne-db-02;onmne-db-02:memory.slab.graph_data_size normal
onmne-db-02;onmne-db-02:memory.slab.info Memory used by the kernel (major users  are caches like inode, dentry, etc).
onmne-db-02;onmne-db-02:memory.slab.label slab_cache
onmne-db-02;onmne-db-02:memory.free.graph_data_size normal
onmne-db-02;onmne-db-02:memory.free.info Wasted memory. Memory that is not used for anything at all.
onmne-db-02;onmne-db-02:memory.free.label unused
onmne-db-02;onmne-db-02:memory.free.draw STACK
onmne-db-02;onmne-db-02:memory.free.update_rate 300
onmne-db-02;onmne-db-02:memory.vmalloc_used.graph_data_size normal
onmne-db-02;onmne-db-02:memory.vmalloc_used.label vmalloc_used
onmne-db-02;onmne-db-02:memory.vmalloc_used.info 'VMalloc' (kernel) memory used
onmne-db-02;onmne-db-02:memory.vmalloc_used.update_rate 300
onmne-db-02;onmne-db-02:memory.vmalloc_used.draw LINE2
onmne-db-02;onmne-db-02:memory.buffers.label buffers
onmne-db-02;onmne-db-02:memory.buffers.info Block device (e.g. harddisk) cache. Also where "dirty" blocks are stored until written.
onmne-db-02;onmne-db-02:memory.buffers.graph_data_size normal
onmne-db-02;onmne-db-02:memory.buffers.draw STACK
onmne-db-02;onmne-db-02:memory.buffers.update_rate 300
onmne-db-02;onmne-db-02:memory.apps.label apps
onmne-db-02;onmne-db-02:memory.apps.info Memory used by user-space applications.
onmne-db-02;onmne-db-02:memory.apps.graph_data_size normal
onmne-db-02;onmne-db-02:memory.apps.update_rate 300
onmne-db-02;onmne-db-02:memory.apps.draw AREA
onmne-db-02;onmne-db-02:memory.cached.graph_data_size normal
onmne-db-02;onmne-db-02:memory.cached.label cache
onmne-db-02;onmne-db-02:memory.cached.info Parked file data (file content) cache.
onmne-db-02;onmne-db-02:memory.cached.draw STACK
onmne-db-02;onmne-db-02:memory.cached.update_rate 300
onmne-db-02;onmne-db-02:memory.swap_cache.update_rate 300
onmne-db-02;onmne-db-02:memory.swap_cache.draw STACK
onmne-db-02;onmne-db-02:memory.swap_cache.info A piece of memory that keeps track of pages that have been fetched from swap but not yet been modified.
onmne-db-02;onmne-db-02:memory.swap_cache.label swap_cache
onmne-db-02;onmne-db-02:memory.swap_cache.graph_data_size normal
onmne-db-02;onmne-db-02:memory.inactive.info Memory not currently used.
onmne-db-02;onmne-db-02:memory.inactive.label inactive
onmne-db-02;onmne-db-02:memory.inactive.graph_data_size normal
onmne-db-02;onmne-db-02:memory.inactive.update_rate 300
onmne-db-02;onmne-db-02:memory.inactive.draw LINE2
onmne-db-02;onmne-db-02:memory.page_tables.label page_tables
onmne-db-02;onmne-db-02:memory.page_tables.info Memory used to map between virtual and physical memory addresses.
onmne-db-02;onmne-db-02:memory.page_tables.graph_data_size normal
onmne-db-02;onmne-db-02:memory.page_tables.update_rate 300
onmne-db-02;onmne-db-02:memory.page_tables.draw STACK
onmne-db-02;onmne-db-02:memory.mapped.update_rate 300
onmne-db-02;onmne-db-02:memory.mapped.draw LINE2
onmne-db-02;onmne-db-02:memory.mapped.info All mmap()ed pages.
onmne-db-02;onmne-db-02:memory.mapped.label mapped
onmne-db-02;onmne-db-02:memory.mapped.graph_data_size normal
onmne-db-02;onmne-db-02:memory.active.info Memory recently used. Not reclaimed unless absolutely necessary.
onmne-db-02;onmne-db-02:memory.active.label active
onmne-db-02;onmne-db-02:memory.active.graph_data_size normal
onmne-db-02;onmne-db-02:memory.active.draw LINE2
onmne-db-02;onmne-db-02:memory.active.update_rate 300
onmne-db-02;onmne-db-02:memory.swap.label swap
onmne-db-02;onmne-db-02:memory.swap.info Swap space used.
onmne-db-02;onmne-db-02:memory.swap.graph_data_size normal
onmne-db-02;onmne-db-02:memory.swap.draw STACK
onmne-db-02;onmne-db-02:memory.swap.update_rate 300
onmne-db-02;onmne-db-02:memory.committed.draw LINE2
onmne-db-02;onmne-db-02:memory.committed.update_rate 300
onmne-db-02;onmne-db-02:memory.committed.graph_data_size normal
onmne-db-02;onmne-db-02:memory.committed.info The amount of memory allocated to programs. Overcommitting is normal, but may indicate memory leaks.
onmne-db-02;onmne-db-02:memory.committed.label committed
onmne-db-02;onmne-db-02:irqstats.graph_title Individual interrupts
onmne-db-02;onmne-db-02:irqstats.graph_args --base 1000 --logarithmic
onmne-db-02;onmne-db-02:irqstats.graph_vlabel interrupts / ${graph_period}
onmne-db-02;onmne-db-02:irqstats.graph_category system
onmne-db-02;onmne-db-02:irqstats.graph_info Shows the number of different IRQs received by the kernel.  High disk or network traffic can cause a high number of interrupts (with good hardware and drivers this will be less so). Sudden high interrupt activity with no associated higher system activity is not normal.
onmne-db-02;onmne-db-02:irqstats.graph_order i0 i1 i8 i9 i12 i14 i15 i16 i17 i24 i25 i26 i27 i28 i29 i30 i31 i32 i33 i34 i35 i36 i37 i38 i39 i40 i41 i42 i43 i44 i45 i46 i47 i48 i49 i50 i51 i52 i53 i54 i55 i56 i57 i58 i59 i60 i61 i62 i63 i64 i65 i66 i67 iNMI iLOC iSPU iPMI iIWI iRTR iRES iCAL iTLB iTRM iTHR iDFR iMCE iMCP iERR iMIS iPIN iNPI iPIW i0 i1 i8 i9 i12 i14 i15 i16 i17 i24 i25 i26 i27 i28 i29 i30 i31 i32 i33 i34 i35 i36 i37 i38 i39 i40 i41 i42 i43 i44 i45 i46 i47 i48 i49 i50 i51 i52 i53 i54 i55 i56 i57 i58 i59 i60 i61 i62 i63 i64 i65 i66 i67 iNMI iLOC iSPU iPMI iIWI iRTR iRES iCAL iTLB iTRM iTHR iDFR iMCE iMCP iERR iMIS iPIN iNPI iPIW
onmne-db-02;onmne-db-02:irqstats.i63.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i63.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i63.min 0
onmne-db-02;onmne-db-02:irqstats.i63.label 1572871-edge      ens160-rxtx-7
onmne-db-02;onmne-db-02:irqstats.i63.info Interrupt 63, for device(s): 1572871-edge      ens160-rxtx-7
onmne-db-02;onmne-db-02:irqstats.i63.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i8.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i8.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i8.min 0
onmne-db-02;onmne-db-02:irqstats.i8.label 8-edge      rtc0
onmne-db-02;onmne-db-02:irqstats.i8.info Interrupt 8, for device(s): 8-edge      rtc0
onmne-db-02;onmne-db-02:irqstats.i8.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iMCP.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iMCP.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iMCP.label Machine check polls
onmne-db-02;onmne-db-02:irqstats.iMCP.info Interrupt MCP, for device(s): Machine check polls
onmne-db-02;onmne-db-02:irqstats.iMCP.min 0
onmne-db-02;onmne-db-02:irqstats.iMCP.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i54.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i54.label 405504-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i54.info Interrupt 54, for device(s): 405504-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i54.min 0
onmne-db-02;onmne-db-02:irqstats.i54.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i54.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i34.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i34.min 0
onmne-db-02;onmne-db-02:irqstats.i34.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i34.info Interrupt 34, for device(s): 364544-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i34.label 364544-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i34.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i30.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i30.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i30.info Interrupt 30, for device(s): 356352-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i30.label 356352-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i30.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i30.min 0
onmne-db-02;onmne-db-02:irqstats.i50.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i50.label 397312-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i50.info Interrupt 50, for device(s): 397312-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i50.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i50.min 0
onmne-db-02;onmne-db-02:irqstats.i50.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i51.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i51.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i51.label 399360-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i51.info Interrupt 51, for device(s): 399360-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i51.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i51.min 0
onmne-db-02;onmne-db-02:irqstats.i31.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i31.label 358400-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i31.info Interrupt 31, for device(s): 358400-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i31.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i31.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i31.min 0
onmne-db-02;onmne-db-02:irqstats.i14.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i14.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i14.min 0
onmne-db-02;onmne-db-02:irqstats.i14.label 14-edge      ata_piix
onmne-db-02;onmne-db-02:irqstats.i14.info Interrupt 14, for device(s): 14-edge      ata_piix
onmne-db-02;onmne-db-02:irqstats.i14.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i65.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i65.info Interrupt 65, for device(s): 1064960-edge      ahci[0000:02:01.0]
onmne-db-02;onmne-db-02:irqstats.i65.label 1064960-edge      ahci[0000:02:01.0]
onmne-db-02;onmne-db-02:irqstats.i65.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i65.min 0
onmne-db-02;onmne-db-02:irqstats.i65.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iNPI.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iNPI.min 0
onmne-db-02;onmne-db-02:irqstats.iNPI.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iNPI.label Nested posted-interrupt event
onmne-db-02;onmne-db-02:irqstats.iNPI.info Interrupt NPI, for device(s): Nested posted-interrupt event
onmne-db-02;onmne-db-02:irqstats.iNPI.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iSPU.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iSPU.label Spurious interrupts
onmne-db-02;onmne-db-02:irqstats.iSPU.info Interrupt SPU, for device(s): Spurious interrupts
onmne-db-02;onmne-db-02:irqstats.iSPU.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iSPU.min 0
onmne-db-02;onmne-db-02:irqstats.iSPU.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iTRM.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iTRM.min 0
onmne-db-02;onmne-db-02:irqstats.iTRM.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iTRM.info Interrupt TRM, for device(s): Thermal event interrupts
onmne-db-02;onmne-db-02:irqstats.iTRM.label Thermal event interrupts
onmne-db-02;onmne-db-02:irqstats.iTRM.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i60.min 0
onmne-db-02;onmne-db-02:irqstats.i60.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i60.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i60.label 1572868-edge      ens160-rxtx-4
onmne-db-02;onmne-db-02:irqstats.i60.info Interrupt 60, for device(s): 1572868-edge      ens160-rxtx-4
onmne-db-02;onmne-db-02:irqstats.i60.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iNMI.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iNMI.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iNMI.info Interrupt NMI, for device(s): Non-maskable interrupts
onmne-db-02;onmne-db-02:irqstats.iNMI.label Non-maskable interrupts
onmne-db-02;onmne-db-02:irqstats.iNMI.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iNMI.min 0
onmne-db-02;onmne-db-02:irqstats.i49.min 0
onmne-db-02;onmne-db-02:irqstats.i49.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i49.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i49.info Interrupt 49, for device(s): 395264-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i49.label 395264-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i49.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i0.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i0.label 2-edge      timer
onmne-db-02;onmne-db-02:irqstats.i0.info Interrupt 0, for device(s): 2-edge      timer
onmne-db-02;onmne-db-02:irqstats.i0.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i0.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i0.min 0
onmne-db-02;onmne-db-02:irqstats.iERR.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iERR.label ERR
onmne-db-02;onmne-db-02:irqstats.iERR.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iERR.min 0
onmne-db-02;onmne-db-02:irqstats.iERR.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i61.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i61.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i61.info Interrupt 61, for device(s): 1572869-edge      ens160-rxtx-5
onmne-db-02;onmne-db-02:irqstats.i61.label 1572869-edge      ens160-rxtx-5
onmne-db-02;onmne-db-02:irqstats.i61.min 0
onmne-db-02;onmne-db-02:irqstats.i61.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iCAL.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iCAL.min 0
onmne-db-02;onmne-db-02:irqstats.iCAL.info Interrupt CAL, for device(s): Function call interrupts
onmne-db-02;onmne-db-02:irqstats.iCAL.label Function call interrupts
onmne-db-02;onmne-db-02:irqstats.iCAL.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iCAL.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i29.min 0
onmne-db-02;onmne-db-02:irqstats.i29.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i29.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i29.label 354304-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i29.info Interrupt 29, for device(s): 354304-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i29.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i35.min 0
onmne-db-02;onmne-db-02:irqstats.i35.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i35.label 366592-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i35.info Interrupt 35, for device(s): 366592-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i35.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i35.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i55.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i55.info Interrupt 55, for device(s): 407552-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i55.label 407552-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i55.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i55.min 0
onmne-db-02;onmne-db-02:irqstats.i55.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i15.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i15.info Interrupt 15, for device(s): 15-edge      ata_piix
onmne-db-02;onmne-db-02:irqstats.i15.label 15-edge      ata_piix
onmne-db-02;onmne-db-02:irqstats.i15.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i15.min 0
onmne-db-02;onmne-db-02:irqstats.i15.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i53.info Interrupt 53, for device(s): 403456-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i53.label 403456-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i53.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i53.min 0
onmne-db-02;onmne-db-02:irqstats.i53.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i53.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iPMI.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iPMI.min 0
onmne-db-02;onmne-db-02:irqstats.iPMI.label Performance monitoring interrupts
onmne-db-02;onmne-db-02:irqstats.iPMI.info Interrupt PMI, for device(s): Performance monitoring interrupts
onmne-db-02;onmne-db-02:irqstats.iPMI.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iPMI.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i33.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i33.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i33.info Interrupt 33, for device(s): 362496-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i33.label 362496-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i33.min 0
onmne-db-02;onmne-db-02:irqstats.i33.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iMIS.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iMIS.label MIS
onmne-db-02;onmne-db-02:irqstats.iMIS.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iMIS.min 0
onmne-db-02;onmne-db-02:irqstats.iMIS.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i46.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i46.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i46.label 389120-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i46.info Interrupt 46, for device(s): 389120-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i46.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i46.min 0
onmne-db-02;onmne-db-02:irqstats.i47.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i47.min 0
onmne-db-02;onmne-db-02:irqstats.i47.info Interrupt 47, for device(s): 391168-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i47.label 391168-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i47.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i47.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i48.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i48.info Interrupt 48, for device(s): 393216-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i48.label 393216-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i48.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i48.min 0
onmne-db-02;onmne-db-02:irqstats.i48.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i42.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i42.min 0
onmne-db-02;onmne-db-02:irqstats.i42.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i42.label 380928-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i42.info Interrupt 42, for device(s): 380928-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i42.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i28.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i28.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i28.min 0
onmne-db-02;onmne-db-02:irqstats.i28.info Interrupt 28, for device(s): 352256-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i28.label 352256-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i28.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i64.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i64.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i64.label 1572872-edge      ens160-event-8
onmne-db-02;onmne-db-02:irqstats.i64.info Interrupt 64, for device(s): 1572872-edge      ens160-event-8
onmne-db-02;onmne-db-02:irqstats.i64.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i64.min 0
onmne-db-02;onmne-db-02:irqstats.i27.min 0
onmne-db-02;onmne-db-02:irqstats.i27.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i27.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i27.label 350208-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i27.info Interrupt 27, for device(s): 350208-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i27.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i26.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i26.min 0
onmne-db-02;onmne-db-02:irqstats.i26.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i26.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i26.info Interrupt 26, for device(s): 348160-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i26.label 348160-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.iPIW.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iPIW.info Interrupt PIW, for device(s): Posted-interrupt wakeup event
onmne-db-02;onmne-db-02:irqstats.iPIW.label Posted-interrupt wakeup event
onmne-db-02;onmne-db-02:irqstats.iPIW.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iPIW.min 0
onmne-db-02;onmne-db-02:irqstats.iPIW.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i41.label 378880-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i41.info Interrupt 41, for device(s): 378880-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i41.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i41.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i41.min 0
onmne-db-02;onmne-db-02:irqstats.i41.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i40.min 0
onmne-db-02;onmne-db-02:irqstats.i40.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i40.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i40.info Interrupt 40, for device(s): 376832-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i40.label 376832-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i40.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iRTR.label APIC ICR read retries
onmne-db-02;onmne-db-02:irqstats.iRTR.info Interrupt RTR, for device(s): APIC ICR read retries
onmne-db-02;onmne-db-02:irqstats.iRTR.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iRTR.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iRTR.min 0
onmne-db-02;onmne-db-02:irqstats.iRTR.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i1.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i1.info Interrupt 1, for device(s): 1-edge      i8042
onmne-db-02;onmne-db-02:irqstats.i1.label 1-edge      i8042
onmne-db-02;onmne-db-02:irqstats.i1.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i1.min 0
onmne-db-02;onmne-db-02:irqstats.i1.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iPIN.min 0
onmne-db-02;onmne-db-02:irqstats.iPIN.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iPIN.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iPIN.label Posted-interrupt notification event
onmne-db-02;onmne-db-02:irqstats.iPIN.info Interrupt PIN, for device(s): Posted-interrupt notification event
onmne-db-02;onmne-db-02:irqstats.iPIN.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i62.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i62.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i62.label 1572870-edge      ens160-rxtx-6
onmne-db-02;onmne-db-02:irqstats.i62.info Interrupt 62, for device(s): 1572870-edge      ens160-rxtx-6
onmne-db-02;onmne-db-02:irqstats.i62.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i62.min 0
onmne-db-02;onmne-db-02:irqstats.iTLB.label TLB shootdowns
onmne-db-02;onmne-db-02:irqstats.iTLB.info Interrupt TLB, for device(s): TLB shootdowns
onmne-db-02;onmne-db-02:irqstats.iTLB.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iTLB.min 0
onmne-db-02;onmne-db-02:irqstats.iTLB.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iTLB.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i67.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i67.info Interrupt 67, for device(s): 129025-edge      vmw_vmci
onmne-db-02;onmne-db-02:irqstats.i67.label 129025-edge      vmw_vmci
onmne-db-02;onmne-db-02:irqstats.i67.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i67.min 0
onmne-db-02;onmne-db-02:irqstats.i67.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i24.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i24.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i24.info Interrupt 24, for device(s): 344064-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i24.label 344064-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i24.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i24.min 0
onmne-db-02;onmne-db-02:irqstats.i66.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i66.info Interrupt 66, for device(s): 129024-edge      vmw_vmci
onmne-db-02;onmne-db-02:irqstats.i66.label 129024-edge      vmw_vmci
onmne-db-02;onmne-db-02:irqstats.i66.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i66.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i66.min 0
onmne-db-02;onmne-db-02:irqstats.iLOC.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iLOC.info Interrupt LOC, for device(s): Local timer interrupts
onmne-db-02;onmne-db-02:irqstats.iLOC.label Local timer interrupts
onmne-db-02;onmne-db-02:irqstats.iLOC.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iLOC.min 0
onmne-db-02;onmne-db-02:irqstats.iLOC.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iRES.info Interrupt RES, for device(s): Rescheduling interrupts
onmne-db-02;onmne-db-02:irqstats.iRES.label Rescheduling interrupts
onmne-db-02;onmne-db-02:irqstats.iRES.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iRES.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iRES.min 0
onmne-db-02;onmne-db-02:irqstats.iRES.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i44.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i44.label 385024-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i44.info Interrupt 44, for device(s): 385024-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i44.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i44.min 0
onmne-db-02;onmne-db-02:irqstats.i44.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i58.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i58.min 0
onmne-db-02;onmne-db-02:irqstats.i58.label 1572866-edge      ens160-rxtx-2
onmne-db-02;onmne-db-02:irqstats.i58.info Interrupt 58, for device(s): 1572866-edge      ens160-rxtx-2
onmne-db-02;onmne-db-02:irqstats.i58.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i58.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i38.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i38.min 0
onmne-db-02;onmne-db-02:irqstats.i38.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i38.label 372736-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i38.info Interrupt 38, for device(s): 372736-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i38.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i32.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i32.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i32.info Interrupt 32, for device(s): 360448-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i32.label 360448-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i32.min 0
onmne-db-02;onmne-db-02:irqstats.i32.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i52.min 0
onmne-db-02;onmne-db-02:irqstats.i52.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i52.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i52.info Interrupt 52, for device(s): 401408-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i52.label 401408-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i52.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iTHR.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iTHR.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iTHR.min 0
onmne-db-02;onmne-db-02:irqstats.iTHR.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iTHR.label Threshold APIC interrupts
onmne-db-02;onmne-db-02:irqstats.iTHR.info Interrupt THR, for device(s): Threshold APIC interrupts
onmne-db-02;onmne-db-02:irqstats.i37.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i37.min 0
onmne-db-02;onmne-db-02:irqstats.i37.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i37.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i37.info Interrupt 37, for device(s): 370688-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i37.label 370688-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i57.min 0
onmne-db-02;onmne-db-02:irqstats.i57.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i57.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i57.label 1572865-edge      ens160-rxtx-1
onmne-db-02;onmne-db-02:irqstats.i57.info Interrupt 57, for device(s): 1572865-edge      ens160-rxtx-1
onmne-db-02;onmne-db-02:irqstats.i57.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i36.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i36.min 0
onmne-db-02;onmne-db-02:irqstats.i36.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i36.info Interrupt 36, for device(s): 368640-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i36.label 368640-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i36.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i56.label 1572864-edge      ens160-rxtx-0
onmne-db-02;onmne-db-02:irqstats.i56.info Interrupt 56, for device(s): 1572864-edge      ens160-rxtx-0
onmne-db-02;onmne-db-02:irqstats.i56.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i56.min 0
onmne-db-02;onmne-db-02:irqstats.i56.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i56.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i43.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i43.label 382976-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i43.info Interrupt 43, for device(s): 382976-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i43.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i43.min 0
onmne-db-02;onmne-db-02:irqstats.i43.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iMCE.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iMCE.min 0
onmne-db-02;onmne-db-02:irqstats.iMCE.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iMCE.info Interrupt MCE, for device(s): Machine check exceptions
onmne-db-02;onmne-db-02:irqstats.iMCE.label Machine check exceptions
onmne-db-02;onmne-db-02:irqstats.iMCE.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i59.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i59.info Interrupt 59, for device(s): 1572867-edge      ens160-rxtx-3
onmne-db-02;onmne-db-02:irqstats.i59.label 1572867-edge      ens160-rxtx-3
onmne-db-02;onmne-db-02:irqstats.i59.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i59.min 0
onmne-db-02;onmne-db-02:irqstats.i59.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i39.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i39.min 0
onmne-db-02;onmne-db-02:irqstats.i39.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i39.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i39.info Interrupt 39, for device(s): 374784-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i39.label 374784-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.iDFR.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iDFR.min 0
onmne-db-02;onmne-db-02:irqstats.iDFR.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iDFR.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.iDFR.info Interrupt DFR, for device(s): Deferred Error APIC interrupts
onmne-db-02;onmne-db-02:irqstats.iDFR.label Deferred Error APIC interrupts
onmne-db-02;onmne-db-02:irqstats.i9.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i9.label 9-fasteoi   acpi
onmne-db-02;onmne-db-02:irqstats.i9.info Interrupt 9, for device(s): 9-fasteoi   acpi
onmne-db-02;onmne-db-02:irqstats.i9.min 0
onmne-db-02;onmne-db-02:irqstats.i9.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i9.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i25.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i25.min 0
onmne-db-02;onmne-db-02:irqstats.i25.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i25.label 346112-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i25.info Interrupt 25, for device(s): 346112-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i25.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i16.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i16.min 0
onmne-db-02;onmne-db-02:irqstats.i16.info Interrupt 16, for device(s): 16-fasteoi   vmwgfx
onmne-db-02;onmne-db-02:irqstats.i16.label 16-fasteoi   vmwgfx
onmne-db-02;onmne-db-02:irqstats.i16.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i16.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i45.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i45.info Interrupt 45, for device(s): 387072-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i45.label 387072-edge      PCIe PME, pciehp
onmne-db-02;onmne-db-02:irqstats.i45.min 0
onmne-db-02;onmne-db-02:irqstats.i45.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i45.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i12.info Interrupt 12, for device(s): 12-edge      i8042
onmne-db-02;onmne-db-02:irqstats.i12.label 12-edge      i8042
onmne-db-02;onmne-db-02:irqstats.i12.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i12.min 0
onmne-db-02;onmne-db-02:irqstats.i12.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i12.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iIWI.update_rate 300
onmne-db-02;onmne-db-02:irqstats.iIWI.min 0
onmne-db-02;onmne-db-02:irqstats.iIWI.type DERIVE
onmne-db-02;onmne-db-02:irqstats.iIWI.label IRQ work interrupts
onmne-db-02;onmne-db-02:irqstats.iIWI.info Interrupt IWI, for device(s): IRQ work interrupts
onmne-db-02;onmne-db-02:irqstats.iIWI.graph_data_size normal
onmne-db-02;onmne-db-02:irqstats.i17.update_rate 300
onmne-db-02;onmne-db-02:irqstats.i17.type DERIVE
onmne-db-02;onmne-db-02:irqstats.i17.min 0
onmne-db-02;onmne-db-02:irqstats.i17.label 17-fasteoi   ioc0
onmne-db-02;onmne-db-02:irqstats.i17.info Interrupt 17, for device(s): 17-fasteoi   ioc0
onmne-db-02;onmne-db-02:irqstats.i17.graph_data_size normal
onmne-db-02;onmne-db-02:load.graph_title Load average
onmne-db-02;onmne-db-02:load.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:load.graph_vlabel load
onmne-db-02;onmne-db-02:load.graph_scale no
onmne-db-02;onmne-db-02:load.graph_category system
onmne-db-02;onmne-db-02:load.graph_info The load average of the machine describes how many processes are in the run-queue (scheduled to run "immediately").
onmne-db-02;onmne-db-02:load.graph_order load
onmne-db-02;onmne-db-02:load.load.info 5 minute load average
onmne-db-02;onmne-db-02:load.load.label load
onmne-db-02;onmne-db-02:load.load.graph_data_size normal
onmne-db-02;onmne-db-02:load.load.update_rate 300
onmne-db-02;onmne-db-02:cpu.graph_title CPU usage
onmne-db-02;onmne-db-02:cpu.graph_order system user nice idle iowait irq softirq system user nice idle iowait irq softirq steal guest
onmne-db-02;onmne-db-02:cpu.graph_args --base 1000 -r --lower-limit 0 --upper-limit 800
onmne-db-02;onmne-db-02:cpu.graph_vlabel %
onmne-db-02;onmne-db-02:cpu.graph_scale no
onmne-db-02;onmne-db-02:cpu.graph_info This graph shows how CPU time is spent.
onmne-db-02;onmne-db-02:cpu.graph_category system
onmne-db-02;onmne-db-02:cpu.graph_period second
onmne-db-02;onmne-db-02:cpu.user.draw STACK
onmne-db-02;onmne-db-02:cpu.user.update_rate 300
onmne-db-02;onmne-db-02:cpu.user.type DERIVE
onmne-db-02;onmne-db-02:cpu.user.min 0
onmne-db-02;onmne-db-02:cpu.user.info CPU time spent by normal programs and daemons
onmne-db-02;onmne-db-02:cpu.user.label user
onmne-db-02;onmne-db-02:cpu.user.graph_data_size normal
onmne-db-02;onmne-db-02:cpu.softirq.update_rate 300
onmne-db-02;onmne-db-02:cpu.softirq.draw STACK
onmne-db-02;onmne-db-02:cpu.softirq.type DERIVE
onmne-db-02;onmne-db-02:cpu.softirq.min 0
onmne-db-02;onmne-db-02:cpu.softirq.label softirq
onmne-db-02;onmne-db-02:cpu.softirq.info CPU time spent handling "batched" interrupts
onmne-db-02;onmne-db-02:cpu.softirq.graph_data_size normal
onmne-db-02;onmne-db-02:cpu.idle.update_rate 300
onmne-db-02;onmne-db-02:cpu.idle.draw STACK
onmne-db-02;onmne-db-02:cpu.idle.type DERIVE
onmne-db-02;onmne-db-02:cpu.idle.min 0
onmne-db-02;onmne-db-02:cpu.idle.info Idle CPU time
onmne-db-02;onmne-db-02:cpu.idle.label idle
onmne-db-02;onmne-db-02:cpu.idle.graph_data_size normal
onmne-db-02;onmne-db-02:cpu.steal.graph_data_size normal
onmne-db-02;onmne-db-02:cpu.steal.info The time that a virtual CPU had runnable tasks, but the virtual CPU itself was not running
onmne-db-02;onmne-db-02:cpu.steal.label steal
onmne-db-02;onmne-db-02:cpu.steal.min 0
onmne-db-02;onmne-db-02:cpu.steal.type DERIVE
onmne-db-02;onmne-db-02:cpu.steal.update_rate 300
onmne-db-02;onmne-db-02:cpu.steal.draw STACK
onmne-db-02;onmne-db-02:cpu.irq.draw STACK
onmne-db-02;onmne-db-02:cpu.irq.update_rate 300
onmne-db-02;onmne-db-02:cpu.irq.type DERIVE
onmne-db-02;onmne-db-02:cpu.irq.min 0
onmne-db-02;onmne-db-02:cpu.irq.graph_data_size normal
onmne-db-02;onmne-db-02:cpu.irq.label irq
onmne-db-02;onmne-db-02:cpu.irq.info CPU time spent handling interrupts
onmne-db-02;onmne-db-02:cpu.system.update_rate 300
onmne-db-02;onmne-db-02:cpu.system.draw AREA
onmne-db-02;onmne-db-02:cpu.system.info CPU time spent by the kernel in system activities
onmne-db-02;onmne-db-02:cpu.system.label system
onmne-db-02;onmne-db-02:cpu.system.graph_data_size normal
onmne-db-02;onmne-db-02:cpu.system.min 0
onmne-db-02;onmne-db-02:cpu.system.type DERIVE
onmne-db-02;onmne-db-02:cpu.guest.draw STACK
onmne-db-02;onmne-db-02:cpu.guest.update_rate 300
onmne-db-02;onmne-db-02:cpu.guest.min 0
onmne-db-02;onmne-db-02:cpu.guest.type DERIVE
onmne-db-02;onmne-db-02:cpu.guest.graph_data_size normal
onmne-db-02;onmne-db-02:cpu.guest.label guest
onmne-db-02;onmne-db-02:cpu.guest.info The time spent running a virtual CPU for guest operating systems under the control of the Linux kernel.
onmne-db-02;onmne-db-02:cpu.iowait.draw STACK
onmne-db-02;onmne-db-02:cpu.iowait.update_rate 300
onmne-db-02;onmne-db-02:cpu.iowait.type DERIVE
onmne-db-02;onmne-db-02:cpu.iowait.min 0
onmne-db-02;onmne-db-02:cpu.iowait.graph_data_size normal
onmne-db-02;onmne-db-02:cpu.iowait.info CPU time spent waiting for I/O operations to finish when there is nothing else to do.
onmne-db-02;onmne-db-02:cpu.iowait.label iowait
onmne-db-02;onmne-db-02:cpu.nice.update_rate 300
onmne-db-02;onmne-db-02:cpu.nice.draw STACK
onmne-db-02;onmne-db-02:cpu.nice.graph_data_size normal
onmne-db-02;onmne-db-02:cpu.nice.label nice
onmne-db-02;onmne-db-02:cpu.nice.info CPU time spent by nice(1)d programs
onmne-db-02;onmne-db-02:cpu.nice.type DERIVE
onmne-db-02;onmne-db-02:cpu.nice.min 0
onmne-db-02;onmne-db-02:forks.graph_title Fork rate
onmne-db-02;onmne-db-02:forks.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:forks.graph_vlabel forks / ${graph_period}
onmne-db-02;onmne-db-02:forks.graph_category processes
onmne-db-02;onmne-db-02:forks.graph_info This graph shows the number of forks (new processes started) per second.
onmne-db-02;onmne-db-02:forks.graph_order forks
onmne-db-02;onmne-db-02:forks.forks.update_rate 300
onmne-db-02;onmne-db-02:forks.forks.max 100000
onmne-db-02;onmne-db-02:forks.forks.type DERIVE
onmne-db-02;onmne-db-02:forks.forks.min 0
onmne-db-02;onmne-db-02:forks.forks.info The number of forks per second.
onmne-db-02;onmne-db-02:forks.forks.label forks
onmne-db-02;onmne-db-02:forks.forks.graph_data_size normal
onmne-db-02;onmne-db-02:entropy.graph_title Available entropy
onmne-db-02;onmne-db-02:entropy.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:entropy.graph_vlabel entropy (bytes)
onmne-db-02;onmne-db-02:entropy.graph_scale no
onmne-db-02;onmne-db-02:entropy.graph_category system
onmne-db-02;onmne-db-02:entropy.graph_info This graph shows the amount of entropy available in the system.
onmne-db-02;onmne-db-02:entropy.graph_order entropy
onmne-db-02;onmne-db-02:entropy.entropy.update_rate 300
onmne-db-02;onmne-db-02:entropy.entropy.label entropy
onmne-db-02;onmne-db-02:entropy.entropy.info The number of random bytes available. This is typically used by cryptographic applications.
onmne-db-02;onmne-db-02:entropy.entropy.graph_data_size normal
onmne-db-02;onmne-db-02:swap.graph_title Swap in/out
onmne-db-02;onmne-db-02:swap.graph_args -l 0 --base 1000
onmne-db-02;onmne-db-02:swap.graph_vlabel pages per ${graph_period} in (-) / out (+)
onmne-db-02;onmne-db-02:swap.graph_category system
onmne-db-02;onmne-db-02:swap.graph_order swap_in swap_out
onmne-db-02;onmne-db-02:swap.swap_out.label swap
onmne-db-02;onmne-db-02:swap.swap_out.graph_data_size normal
onmne-db-02;onmne-db-02:swap.swap_out.negative swap_in
onmne-db-02;onmne-db-02:swap.swap_out.min 0
onmne-db-02;onmne-db-02:swap.swap_out.type DERIVE
onmne-db-02;onmne-db-02:swap.swap_out.update_rate 300
onmne-db-02;onmne-db-02:swap.swap_out.max 100000
onmne-db-02;onmne-db-02:swap.swap_in.update_rate 300
onmne-db-02;onmne-db-02:swap.swap_in.max 100000
onmne-db-02;onmne-db-02:swap.swap_in.graph no
onmne-db-02;onmne-db-02:swap.swap_in.label swap
onmne-db-02;onmne-db-02:swap.swap_in.graph_data_size normal
onmne-db-02;onmne-db-02:swap.swap_in.type DERIVE
onmne-db-02;onmne-db-02:swap.swap_in.min 0
onmne-db-02;onmne-db-02:open_files.graph_title File table usage
onmne-db-02;onmne-db-02:open_files.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:open_files.graph_vlabel number of open files
onmne-db-02;onmne-db-02:open_files.graph_category system
onmne-db-02;onmne-db-02:open_files.graph_info This graph monitors the Linux open files table.
onmne-db-02;onmne-db-02:open_files.graph_order used max
onmne-db-02;onmne-db-02:open_files.max.info The maximum supported number of open files. Tune by modifying /proc/sys/fs/file-max.
onmne-db-02;onmne-db-02:open_files.max.label max open files
onmne-db-02;onmne-db-02:open_files.max.graph_data_size normal
onmne-db-02;onmne-db-02:open_files.max.update_rate 300
onmne-db-02;onmne-db-02:open_files.used.label open files
onmne-db-02;onmne-db-02:open_files.used.info The number of currently open files.
onmne-db-02;onmne-db-02:open_files.used.graph_data_size normal
onmne-db-02;onmne-db-02:open_files.used.critical 9038904596117680128
onmne-db-02;onmne-db-02:open_files.used.warning 8485502273906394112
onmne-db-02;onmne-db-02:open_files.used.update_rate 300
onmne-db-02;onmne-db-02:if_err_veth51d364c.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-02;onmne-db-02:if_err_veth51d364c.graph_title veth51d364c errors
onmne-db-02;onmne-db-02:if_err_veth51d364c.graph_args --base 1000
onmne-db-02;onmne-db-02:if_err_veth51d364c.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_err_veth51d364c.graph_category network
onmne-db-02;onmne-db-02:if_err_veth51d364c.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth51d364c network interface.
onmne-db-02;onmne-db-02:if_err_veth51d364c.rxdrop.graph no
onmne-db-02;onmne-db-02:if_err_veth51d364c.rxdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_veth51d364c.rxdrop.label drops
onmne-db-02;onmne-db-02:if_err_veth51d364c.rxdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_veth51d364c.rxdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_veth51d364c.trans.update_rate 300
onmne-db-02;onmne-db-02:if_err_veth51d364c.trans.warning 1
onmne-db-02;onmne-db-02:if_err_veth51d364c.trans.type COUNTER
onmne-db-02;onmne-db-02:if_err_veth51d364c.trans.negative rcvd
onmne-db-02;onmne-db-02:if_err_veth51d364c.trans.label errors
onmne-db-02;onmne-db-02:if_err_veth51d364c.trans.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_veth51d364c.collisions.type COUNTER
onmne-db-02;onmne-db-02:if_err_veth51d364c.collisions.update_rate 300
onmne-db-02;onmne-db-02:if_err_veth51d364c.collisions.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_veth51d364c.collisions.label collisions
onmne-db-02;onmne-db-02:if_err_veth51d364c.txdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_veth51d364c.txdrop.label drops
onmne-db-02;onmne-db-02:if_err_veth51d364c.txdrop.negative rxdrop
onmne-db-02;onmne-db-02:if_err_veth51d364c.txdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_veth51d364c.txdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_veth51d364c.rcvd.type COUNTER
onmne-db-02;onmne-db-02:if_err_veth51d364c.rcvd.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_veth51d364c.rcvd.label errors
onmne-db-02;onmne-db-02:if_err_veth51d364c.rcvd.graph no
onmne-db-02;onmne-db-02:if_err_veth51d364c.rcvd.warning 1
onmne-db-02;onmne-db-02:if_err_veth51d364c.rcvd.update_rate 300
onmne-db-02;onmne-db-02:if_vethf5e6391.graph_order down up down up
onmne-db-02;onmne-db-02:if_vethf5e6391.graph_title vethf5e6391 traffic
onmne-db-02;onmne-db-02:if_vethf5e6391.graph_args --base 1000
onmne-db-02;onmne-db-02:if_vethf5e6391.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_vethf5e6391.graph_category network
onmne-db-02;onmne-db-02:if_vethf5e6391.graph_info This graph shows the traffic of the vethf5e6391 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-02;onmne-db-02:if_vethf5e6391.down.min 0
onmne-db-02;onmne-db-02:if_vethf5e6391.down.type DERIVE
onmne-db-02;onmne-db-02:if_vethf5e6391.down.graph_data_size normal
onmne-db-02;onmne-db-02:if_vethf5e6391.down.cdef down,8,*
onmne-db-02;onmne-db-02:if_vethf5e6391.down.label received
onmne-db-02;onmne-db-02:if_vethf5e6391.down.update_rate 300
onmne-db-02;onmne-db-02:if_vethf5e6391.down.graph no
onmne-db-02;onmne-db-02:if_vethf5e6391.up.update_rate 300
onmne-db-02;onmne-db-02:if_vethf5e6391.up.label bps
onmne-db-02;onmne-db-02:if_vethf5e6391.up.info Traffic of the vethf5e6391 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-02;onmne-db-02:if_vethf5e6391.up.graph_data_size normal
onmne-db-02;onmne-db-02:if_vethf5e6391.up.cdef up,8,*
onmne-db-02;onmne-db-02:if_vethf5e6391.up.negative down
onmne-db-02;onmne-db-02:if_vethf5e6391.up.min 0
onmne-db-02;onmne-db-02:if_vethf5e6391.up.type DERIVE
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.graph_title veth3aa50f8 errors
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.graph_args --base 1000
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.graph_category network
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.graph_info This graph shows the amount of errors, packet drops, and collisions on the veth3aa50f8 network interface.
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.rxdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.rxdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.rxdrop.label drops
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.rxdrop.graph no
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.rxdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.trans.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.trans.label errors
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.trans.negative rcvd
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.trans.type COUNTER
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.trans.warning 1
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.trans.update_rate 300
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.collisions.type COUNTER
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.collisions.update_rate 300
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.collisions.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.collisions.label collisions
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.txdrop.negative rxdrop
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.txdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.txdrop.label drops
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.txdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.txdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.rcvd.type COUNTER
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.rcvd.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.rcvd.label errors
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.rcvd.warning 1
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.rcvd.update_rate 300
onmne-db-02;onmne-db-02:if_err_veth3aa50f8.rcvd.graph no
onmne-db-02;onmne-db-02:if_err_docker0.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-02;onmne-db-02:if_err_docker0.graph_title docker0 errors
onmne-db-02;onmne-db-02:if_err_docker0.graph_args --base 1000
onmne-db-02;onmne-db-02:if_err_docker0.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_err_docker0.graph_category network
onmne-db-02;onmne-db-02:if_err_docker0.graph_info This graph shows the amount of errors, packet drops, and collisions on the docker0 network interface.
onmne-db-02;onmne-db-02:if_err_docker0.collisions.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_docker0.collisions.label collisions
onmne-db-02;onmne-db-02:if_err_docker0.collisions.update_rate 300
onmne-db-02;onmne-db-02:if_err_docker0.collisions.type COUNTER
onmne-db-02;onmne-db-02:if_err_docker0.trans.update_rate 300
onmne-db-02;onmne-db-02:if_err_docker0.trans.warning 1
onmne-db-02;onmne-db-02:if_err_docker0.trans.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_docker0.trans.label errors
onmne-db-02;onmne-db-02:if_err_docker0.trans.negative rcvd
onmne-db-02;onmne-db-02:if_err_docker0.trans.type COUNTER
onmne-db-02;onmne-db-02:if_err_docker0.rxdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_docker0.rxdrop.label drops
onmne-db-02;onmne-db-02:if_err_docker0.rxdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_docker0.rxdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_docker0.rxdrop.graph no
onmne-db-02;onmne-db-02:if_err_docker0.rcvd.label errors
onmne-db-02;onmne-db-02:if_err_docker0.rcvd.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_docker0.rcvd.type COUNTER
onmne-db-02;onmne-db-02:if_err_docker0.rcvd.warning 1
onmne-db-02;onmne-db-02:if_err_docker0.rcvd.update_rate 300
onmne-db-02;onmne-db-02:if_err_docker0.rcvd.graph no
onmne-db-02;onmne-db-02:if_err_docker0.txdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_docker0.txdrop.negative rxdrop
onmne-db-02;onmne-db-02:if_err_docker0.txdrop.label drops
onmne-db-02;onmne-db-02:if_err_docker0.txdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_docker0.txdrop.update_rate 300
onmne-db-02;onmne-db-02:df_inode.graph_title Inode usage in percent
onmne-db-02;onmne-db-02:df_inode.graph_args --upper-limit 100 -l 0
onmne-db-02;onmne-db-02:df_inode.graph_vlabel %
onmne-db-02;onmne-db-02:df_inode.graph_scale no
onmne-db-02;onmne-db-02:df_inode.graph_category disk
onmne-db-02;onmne-db-02:df_inode.graph_order overlay _dev _sys_fs_cgroup shm _dev_mapper_ubuntu_vL _rootfs_dev _rootfs_dev_shm _rootfs_run _rootfs_run_lock _dev_sda1
onmne-db-02;onmne-db-02:df_inode.shm.warning 92
onmne-db-02;onmne-db-02:df_inode.shm.update_rate 300
onmne-db-02;onmne-db-02:df_inode.shm.critical 98
onmne-db-02;onmne-db-02:df_inode.shm.graph_data_size normal
onmne-db-02;onmne-db-02:df_inode.shm.label /dev/shm
onmne-db-02;onmne-db-02:df_inode._rootfs_run_lock.warning 92
onmne-db-02;onmne-db-02:df_inode._rootfs_run_lock.update_rate 300
onmne-db-02;onmne-db-02:df_inode._rootfs_run_lock.critical 98
onmne-db-02;onmne-db-02:df_inode._rootfs_run_lock.label /rootfs/run/lock
onmne-db-02;onmne-db-02:df_inode._rootfs_run_lock.graph_data_size normal
onmne-db-02;onmne-db-02:df_inode._sys_fs_cgroup.label /sys/fs/cgroup
onmne-db-02;onmne-db-02:df_inode._sys_fs_cgroup.graph_data_size normal
onmne-db-02;onmne-db-02:df_inode._sys_fs_cgroup.update_rate 300
onmne-db-02;onmne-db-02:df_inode._sys_fs_cgroup.warning 92
onmne-db-02;onmne-db-02:df_inode._sys_fs_cgroup.critical 98
onmne-db-02;onmne-db-02:df_inode._dev.graph_data_size normal
onmne-db-02;onmne-db-02:df_inode._dev.label /dev
onmne-db-02;onmne-db-02:df_inode._dev.update_rate 300
onmne-db-02;onmne-db-02:df_inode._dev.warning 92
onmne-db-02;onmne-db-02:df_inode._dev.critical 98
onmne-db-02;onmne-db-02:df_inode._rootfs_dev_shm.update_rate 300
onmne-db-02;onmne-db-02:df_inode._rootfs_dev_shm.warning 92
onmne-db-02;onmne-db-02:df_inode._rootfs_dev_shm.critical 98
onmne-db-02;onmne-db-02:df_inode._rootfs_dev_shm.label /rootfs/dev/shm
onmne-db-02;onmne-db-02:df_inode._rootfs_dev_shm.graph_data_size normal
onmne-db-02;onmne-db-02:df_inode._rootfs_run.warning 92
onmne-db-02;onmne-db-02:df_inode._rootfs_run.update_rate 300
onmne-db-02;onmne-db-02:df_inode._rootfs_run.critical 98
onmne-db-02;onmne-db-02:df_inode._rootfs_run.label /rootfs/run
onmne-db-02;onmne-db-02:df_inode._rootfs_run.graph_data_size normal
onmne-db-02;onmne-db-02:df_inode.overlay.critical 98
onmne-db-02;onmne-db-02:df_inode.overlay.update_rate 300
onmne-db-02;onmne-db-02:df_inode.overlay.warning 92
onmne-db-02;onmne-db-02:df_inode.overlay.label /
onmne-db-02;onmne-db-02:df_inode.overlay.graph_data_size normal
onmne-db-02;onmne-db-02:df_inode._dev_sda1.critical 98
onmne-db-02;onmne-db-02:df_inode._dev_sda1.warning 92
onmne-db-02;onmne-db-02:df_inode._dev_sda1.update_rate 300
onmne-db-02;onmne-db-02:df_inode._dev_sda1.label /rootfs/boot
onmne-db-02;onmne-db-02:df_inode._dev_sda1.graph_data_size normal
onmne-db-02;onmne-db-02:df_inode._dev_mapper_ubuntu_vL.critical 98
onmne-db-02;onmne-db-02:df_inode._dev_mapper_ubuntu_vL.update_rate 300
onmne-db-02;onmne-db-02:df_inode._dev_mapper_ubuntu_vL.warning 92
onmne-db-02;onmne-db-02:df_inode._dev_mapper_ubuntu_vL.label /rootfs
onmne-db-02;onmne-db-02:df_inode._dev_mapper_ubuntu_vL.graph_data_size normal
onmne-db-02;onmne-db-02:df_inode._rootfs_dev.graph_data_size normal
onmne-db-02;onmne-db-02:df_inode._rootfs_dev.label /rootfs/dev
onmne-db-02;onmne-db-02:df_inode._rootfs_dev.warning 92
onmne-db-02;onmne-db-02:df_inode._rootfs_dev.update_rate 300
onmne-db-02;onmne-db-02:df_inode._rootfs_dev.critical 98
onmne-db-02;onmne-db-02:df.graph_title Disk usage in percent
onmne-db-02;onmne-db-02:df.graph_args --upper-limit 100 -l 0
onmne-db-02;onmne-db-02:df.graph_vlabel %
onmne-db-02;onmne-db-02:df.graph_scale no
onmne-db-02;onmne-db-02:df.graph_category disk
onmne-db-02;onmne-db-02:df.graph_order overlay _dev _sys_fs_cgroup shm _dev_mapper_ubuntu_vL _rootfs_dev_shm _rootfs_run _rootfs_run_lock _dev_sda1
onmne-db-02;onmne-db-02:df._rootfs_dev_shm.warning 92
onmne-db-02;onmne-db-02:df._rootfs_dev_shm.update_rate 300
onmne-db-02;onmne-db-02:df._rootfs_dev_shm.critical 98
onmne-db-02;onmne-db-02:df._rootfs_dev_shm.label /rootfs/dev/shm
onmne-db-02;onmne-db-02:df._rootfs_dev_shm.graph_data_size normal
onmne-db-02;onmne-db-02:df._dev.warning 92
onmne-db-02;onmne-db-02:df._dev.update_rate 300
onmne-db-02;onmne-db-02:df._dev.critical 98
onmne-db-02;onmne-db-02:df._dev.graph_data_size normal
onmne-db-02;onmne-db-02:df._dev.label /dev
onmne-db-02;onmne-db-02:df._rootfs_run.update_rate 300
onmne-db-02;onmne-db-02:df._rootfs_run.warning 92
onmne-db-02;onmne-db-02:df._rootfs_run.critical 98
onmne-db-02;onmne-db-02:df._rootfs_run.graph_data_size normal
onmne-db-02;onmne-db-02:df._rootfs_run.label /rootfs/run
onmne-db-02;onmne-db-02:df._dev_sda1.warning 92
onmne-db-02;onmne-db-02:df._dev_sda1.update_rate 300
onmne-db-02;onmne-db-02:df._dev_sda1.critical 98
onmne-db-02;onmne-db-02:df._dev_sda1.graph_data_size normal
onmne-db-02;onmne-db-02:df._dev_sda1.label /rootfs/boot
onmne-db-02;onmne-db-02:df.overlay.graph_data_size normal
onmne-db-02;onmne-db-02:df.overlay.label /
onmne-db-02;onmne-db-02:df.overlay.critical 98
onmne-db-02;onmne-db-02:df.overlay.warning 92
onmne-db-02;onmne-db-02:df.overlay.update_rate 300
onmne-db-02;onmne-db-02:df._dev_mapper_ubuntu_vL.label /rootfs
onmne-db-02;onmne-db-02:df._dev_mapper_ubuntu_vL.graph_data_size normal
onmne-db-02;onmne-db-02:df._dev_mapper_ubuntu_vL.critical 98
onmne-db-02;onmne-db-02:df._dev_mapper_ubuntu_vL.update_rate 300
onmne-db-02;onmne-db-02:df._dev_mapper_ubuntu_vL.warning 92
onmne-db-02;onmne-db-02:df.shm.critical 98
onmne-db-02;onmne-db-02:df.shm.update_rate 300
onmne-db-02;onmne-db-02:df.shm.warning 92
onmne-db-02;onmne-db-02:df.shm.graph_data_size normal
onmne-db-02;onmne-db-02:df.shm.label /dev/shm
onmne-db-02;onmne-db-02:df._rootfs_run_lock.critical 98
onmne-db-02;onmne-db-02:df._rootfs_run_lock.warning 92
onmne-db-02;onmne-db-02:df._rootfs_run_lock.update_rate 300
onmne-db-02;onmne-db-02:df._rootfs_run_lock.label /rootfs/run/lock
onmne-db-02;onmne-db-02:df._rootfs_run_lock.graph_data_size normal
onmne-db-02;onmne-db-02:df._sys_fs_cgroup.update_rate 300
onmne-db-02;onmne-db-02:df._sys_fs_cgroup.warning 92
onmne-db-02;onmne-db-02:df._sys_fs_cgroup.critical 98
onmne-db-02;onmne-db-02:df._sys_fs_cgroup.graph_data_size normal
onmne-db-02;onmne-db-02:df._sys_fs_cgroup.label /sys/fs/cgroup
onmne-db-02;onmne-db-02:interrupts.graph_title Interrupts and context switches
onmne-db-02;onmne-db-02:interrupts.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:interrupts.graph_vlabel interrupts & ctx switches / ${graph_period}
onmne-db-02;onmne-db-02:interrupts.graph_category system
onmne-db-02;onmne-db-02:interrupts.graph_info This graph shows the number of interrupts and context switches on the system. These are typically high on a busy system.
onmne-db-02;onmne-db-02:interrupts.graph_order intr ctx
onmne-db-02;onmne-db-02:interrupts.ctx.update_rate 300
onmne-db-02;onmne-db-02:interrupts.ctx.max 100000
onmne-db-02;onmne-db-02:interrupts.ctx.min 0
onmne-db-02;onmne-db-02:interrupts.ctx.type DERIVE
onmne-db-02;onmne-db-02:interrupts.ctx.graph_data_size normal
onmne-db-02;onmne-db-02:interrupts.ctx.info A context switch occurs when a multitasking operatings system suspends the currently running process, and starts executing another.
onmne-db-02;onmne-db-02:interrupts.ctx.label context switches
onmne-db-02;onmne-db-02:interrupts.intr.graph_data_size normal
onmne-db-02;onmne-db-02:interrupts.intr.label interrupts
onmne-db-02;onmne-db-02:interrupts.intr.info Interrupts are events that alter sequence of instructions executed by a processor. They can come from either hardware (exceptions, NMI, IRQ) or software.
onmne-db-02;onmne-db-02:interrupts.intr.min 0
onmne-db-02;onmne-db-02:interrupts.intr.type DERIVE
onmne-db-02;onmne-db-02:interrupts.intr.update_rate 300
onmne-db-02;onmne-db-02:interrupts.intr.max 100000
onmne-db-02;onmne-db-02:if_veth51d364c.graph_order down up down up
onmne-db-02;onmne-db-02:if_veth51d364c.graph_title veth51d364c traffic
onmne-db-02;onmne-db-02:if_veth51d364c.graph_args --base 1000
onmne-db-02;onmne-db-02:if_veth51d364c.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_veth51d364c.graph_category network
onmne-db-02;onmne-db-02:if_veth51d364c.graph_info This graph shows the traffic of the veth51d364c network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-02;onmne-db-02:if_veth51d364c.down.type DERIVE
onmne-db-02;onmne-db-02:if_veth51d364c.down.min 0
onmne-db-02;onmne-db-02:if_veth51d364c.down.label received
onmne-db-02;onmne-db-02:if_veth51d364c.down.cdef down,8,*
onmne-db-02;onmne-db-02:if_veth51d364c.down.graph_data_size normal
onmne-db-02;onmne-db-02:if_veth51d364c.down.update_rate 300
onmne-db-02;onmne-db-02:if_veth51d364c.down.graph no
onmne-db-02;onmne-db-02:if_veth51d364c.up.label bps
onmne-db-02;onmne-db-02:if_veth51d364c.up.info Traffic of the veth51d364c interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-02;onmne-db-02:if_veth51d364c.up.graph_data_size normal
onmne-db-02;onmne-db-02:if_veth51d364c.up.cdef up,8,*
onmne-db-02;onmne-db-02:if_veth51d364c.up.min 0
onmne-db-02;onmne-db-02:if_veth51d364c.up.negative down
onmne-db-02;onmne-db-02:if_veth51d364c.up.type DERIVE
onmne-db-02;onmne-db-02:if_veth51d364c.up.update_rate 300
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.graph_order down up down up
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.graph_title br-b9e24676d4d2 traffic
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.graph_args --base 1000
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.graph_category network
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.graph_info This graph shows the traffic of the br-b9e24676d4d2 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.up.update_rate 300
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.up.label bps
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.up.info Traffic of the br-b9e24676d4d2 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.up.graph_data_size normal
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.up.cdef up,8,*
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.up.type DERIVE
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.up.min 0
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.up.negative down
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.down.graph no
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.down.update_rate 300
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.down.min 0
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.down.type DERIVE
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.down.cdef down,8,*
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.down.graph_data_size normal
onmne-db-02;onmne-db-02:if_br_b9e24676d4d2.down.label received
onmne-db-02;onmne-db-02:open_inodes.graph_title Inode table usage
onmne-db-02;onmne-db-02:open_inodes.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:open_inodes.graph_vlabel number of open inodes
onmne-db-02;onmne-db-02:open_inodes.graph_category system
onmne-db-02;onmne-db-02:open_inodes.graph_info This graph monitors the Linux open inode table.
onmne-db-02;onmne-db-02:open_inodes.graph_order used max
onmne-db-02;onmne-db-02:open_inodes.max.update_rate 300
onmne-db-02;onmne-db-02:open_inodes.max.label inode table size
onmne-db-02;onmne-db-02:open_inodes.max.info The size of the system inode table. This is dynamically adjusted by the kernel.
onmne-db-02;onmne-db-02:open_inodes.max.graph_data_size normal
onmne-db-02;onmne-db-02:open_inodes.used.label open inodes
onmne-db-02;onmne-db-02:open_inodes.used.info The number of currently open inodes.
onmne-db-02;onmne-db-02:open_inodes.used.graph_data_size normal
onmne-db-02;onmne-db-02:open_inodes.used.update_rate 300
onmne-db-02;onmne-db-02:threads.graph_title Number of threads
onmne-db-02;onmne-db-02:threads.graph_vlabel number of threads
onmne-db-02;onmne-db-02:threads.graph_category processes
onmne-db-02;onmne-db-02:threads.graph_info This graph shows the number of threads.
onmne-db-02;onmne-db-02:threads.graph_order threads
onmne-db-02;onmne-db-02:threads.threads.update_rate 300
onmne-db-02;onmne-db-02:threads.threads.info The current number of threads.
onmne-db-02;onmne-db-02:threads.threads.label threads
onmne-db-02;onmne-db-02:threads.threads.graph_data_size normal
onmne-db-02;onmne-db-02:processes.graph_title Processes
onmne-db-02;onmne-db-02:processes.graph_info This graph shows the number of processes
onmne-db-02;onmne-db-02:processes.graph_category processes
onmne-db-02;onmne-db-02:processes.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:processes.graph_vlabel Number of processes
onmne-db-02;onmne-db-02:processes.graph_order sleeping stopped zombie dead paging uninterruptible runnable processes dead paging sleeping uninterruptible zombie stopped runnable processes
onmne-db-02;onmne-db-02:processes.dead.graph_data_size normal
onmne-db-02;onmne-db-02:processes.dead.info The number of dead processes.
onmne-db-02;onmne-db-02:processes.dead.label dead
onmne-db-02;onmne-db-02:processes.dead.colour ff0000
onmne-db-02;onmne-db-02:processes.dead.update_rate 300
onmne-db-02;onmne-db-02:processes.dead.draw STACK
onmne-db-02;onmne-db-02:processes.stopped.draw STACK
onmne-db-02;onmne-db-02:processes.stopped.update_rate 300
onmne-db-02;onmne-db-02:processes.stopped.colour cc0000
onmne-db-02;onmne-db-02:processes.stopped.label stopped
onmne-db-02;onmne-db-02:processes.stopped.info The number of stopped or traced processes.
onmne-db-02;onmne-db-02:processes.stopped.graph_data_size normal
onmne-db-02;onmne-db-02:processes.processes.draw LINE1
onmne-db-02;onmne-db-02:processes.processes.update_rate 300
onmne-db-02;onmne-db-02:processes.processes.colour c0c0c0
onmne-db-02;onmne-db-02:processes.processes.label total
onmne-db-02;onmne-db-02:processes.processes.info The total number of processes.
onmne-db-02;onmne-db-02:processes.processes.graph_data_size normal
onmne-db-02;onmne-db-02:processes.sleeping.graph_data_size normal
onmne-db-02;onmne-db-02:processes.sleeping.label sleeping
onmne-db-02;onmne-db-02:processes.sleeping.info The number of sleeping processes.
onmne-db-02;onmne-db-02:processes.sleeping.colour 0022ff
onmne-db-02;onmne-db-02:processes.sleeping.update_rate 300
onmne-db-02;onmne-db-02:processes.sleeping.draw AREA
onmne-db-02;onmne-db-02:processes.zombie.draw STACK
onmne-db-02;onmne-db-02:processes.zombie.update_rate 300
onmne-db-02;onmne-db-02:processes.zombie.colour 990000
onmne-db-02;onmne-db-02:processes.zombie.label zombie
onmne-db-02;onmne-db-02:processes.zombie.info The number of defunct (zombie) processes (process terminated and parent not waiting).
onmne-db-02;onmne-db-02:processes.zombie.graph_data_size normal
onmne-db-02;onmne-db-02:processes.paging.draw STACK
onmne-db-02;onmne-db-02:processes.paging.colour 00aaaa
onmne-db-02;onmne-db-02:processes.paging.update_rate 300
onmne-db-02;onmne-db-02:processes.paging.graph_data_size normal
onmne-db-02;onmne-db-02:processes.paging.info The number of paging processes (<2.6 kernels only).
onmne-db-02;onmne-db-02:processes.paging.label paging
onmne-db-02;onmne-db-02:processes.uninterruptible.draw STACK
onmne-db-02;onmne-db-02:processes.uninterruptible.colour ffa500
onmne-db-02;onmne-db-02:processes.uninterruptible.update_rate 300
onmne-db-02;onmne-db-02:processes.uninterruptible.graph_data_size normal
onmne-db-02;onmne-db-02:processes.uninterruptible.label uninterruptible
onmne-db-02;onmne-db-02:processes.uninterruptible.info The number of uninterruptible processes (usually IO).
onmne-db-02;onmne-db-02:processes.runnable.graph_data_size normal
onmne-db-02;onmne-db-02:processes.runnable.label runnable
onmne-db-02;onmne-db-02:processes.runnable.info The number of runnable processes (on the run queue).
onmne-db-02;onmne-db-02:processes.runnable.colour 22ff22
onmne-db-02;onmne-db-02:processes.runnable.update_rate 300
onmne-db-02;onmne-db-02:processes.runnable.draw STACK
onmne-db-02;onmne-db-02:if_err_vethe422dce.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-02;onmne-db-02:if_err_vethe422dce.graph_title vethe422dce errors
onmne-db-02;onmne-db-02:if_err_vethe422dce.graph_args --base 1000
onmne-db-02;onmne-db-02:if_err_vethe422dce.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_err_vethe422dce.graph_category network
onmne-db-02;onmne-db-02:if_err_vethe422dce.graph_info This graph shows the amount of errors, packet drops, and collisions on the vethe422dce network interface.
onmne-db-02;onmne-db-02:if_err_vethe422dce.collisions.type COUNTER
onmne-db-02;onmne-db-02:if_err_vethe422dce.collisions.update_rate 300
onmne-db-02;onmne-db-02:if_err_vethe422dce.collisions.label collisions
onmne-db-02;onmne-db-02:if_err_vethe422dce.collisions.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_vethe422dce.trans.type COUNTER
onmne-db-02;onmne-db-02:if_err_vethe422dce.trans.negative rcvd
onmne-db-02;onmne-db-02:if_err_vethe422dce.trans.label errors
onmne-db-02;onmne-db-02:if_err_vethe422dce.trans.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_vethe422dce.trans.update_rate 300
onmne-db-02;onmne-db-02:if_err_vethe422dce.trans.warning 1
onmne-db-02;onmne-db-02:if_err_vethe422dce.rxdrop.graph no
onmne-db-02;onmne-db-02:if_err_vethe422dce.rxdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_vethe422dce.rxdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_vethe422dce.rxdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_vethe422dce.rxdrop.label drops
onmne-db-02;onmne-db-02:if_err_vethe422dce.rcvd.type COUNTER
onmne-db-02;onmne-db-02:if_err_vethe422dce.rcvd.label errors
onmne-db-02;onmne-db-02:if_err_vethe422dce.rcvd.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_vethe422dce.rcvd.warning 1
onmne-db-02;onmne-db-02:if_err_vethe422dce.rcvd.update_rate 300
onmne-db-02;onmne-db-02:if_err_vethe422dce.rcvd.graph no
onmne-db-02;onmne-db-02:if_err_vethe422dce.txdrop.label drops
onmne-db-02;onmne-db-02:if_err_vethe422dce.txdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_vethe422dce.txdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_vethe422dce.txdrop.negative rxdrop
onmne-db-02;onmne-db-02:if_err_vethe422dce.txdrop.update_rate 300
onmne-db-02;onmne-db-02:users.graph_title Logged in users
onmne-db-02;onmne-db-02:users.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:users.graph_vlabel Users
onmne-db-02;onmne-db-02:users.graph_scale no
onmne-db-02;onmne-db-02:users.graph_category system
onmne-db-02;onmne-db-02:users.graph_printf %3.0lf
onmne-db-02;onmne-db-02:users.graph_order tty pty pts X other
onmne-db-02;onmne-db-02:users.tty.label tty
onmne-db-02;onmne-db-02:users.tty.graph_data_size normal
onmne-db-02;onmne-db-02:users.tty.update_rate 300
onmne-db-02;onmne-db-02:users.tty.colour 00FF00
onmne-db-02;onmne-db-02:users.tty.draw AREASTACK
onmne-db-02;onmne-db-02:users.X.graph_data_size normal
onmne-db-02;onmne-db-02:users.X.info Users logged in on an X display
onmne-db-02;onmne-db-02:users.X.label X displays
onmne-db-02;onmne-db-02:users.X.colour 000000
onmne-db-02;onmne-db-02:users.X.update_rate 300
onmne-db-02;onmne-db-02:users.X.draw AREASTACK
onmne-db-02;onmne-db-02:users.pty.draw AREASTACK
onmne-db-02;onmne-db-02:users.pty.colour 0000FF
onmne-db-02;onmne-db-02:users.pty.update_rate 300
onmne-db-02;onmne-db-02:users.pty.graph_data_size normal
onmne-db-02;onmne-db-02:users.pty.label pty
onmne-db-02;onmne-db-02:users.other.update_rate 300
onmne-db-02;onmne-db-02:users.other.colour FF0000
onmne-db-02;onmne-db-02:users.other.label Other users
onmne-db-02;onmne-db-02:users.other.info Users logged in by indeterminate method
onmne-db-02;onmne-db-02:users.other.graph_data_size normal
onmne-db-02;onmne-db-02:users.pts.colour 00FFFF
onmne-db-02;onmne-db-02:users.pts.update_rate 300
onmne-db-02;onmne-db-02:users.pts.draw AREASTACK
onmne-db-02;onmne-db-02:users.pts.graph_data_size normal
onmne-db-02;onmne-db-02:users.pts.label pts
onmne-db-02;onmne-db-02:if_docker0.graph_order down up down up
onmne-db-02;onmne-db-02:if_docker0.graph_title docker0 traffic
onmne-db-02;onmne-db-02:if_docker0.graph_args --base 1000
onmne-db-02;onmne-db-02:if_docker0.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_docker0.graph_category network
onmne-db-02;onmne-db-02:if_docker0.graph_info This graph shows the traffic of the docker0 network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-02;onmne-db-02:if_docker0.up.update_rate 300
onmne-db-02;onmne-db-02:if_docker0.up.info Traffic of the docker0 interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-02;onmne-db-02:if_docker0.up.label bps
onmne-db-02;onmne-db-02:if_docker0.up.graph_data_size normal
onmne-db-02;onmne-db-02:if_docker0.up.cdef up,8,*
onmne-db-02;onmne-db-02:if_docker0.up.min 0
onmne-db-02;onmne-db-02:if_docker0.up.negative down
onmne-db-02;onmne-db-02:if_docker0.up.type DERIVE
onmne-db-02;onmne-db-02:if_docker0.down.min 0
onmne-db-02;onmne-db-02:if_docker0.down.type DERIVE
onmne-db-02;onmne-db-02:if_docker0.down.label received
onmne-db-02;onmne-db-02:if_docker0.down.cdef down,8,*
onmne-db-02;onmne-db-02:if_docker0.down.graph_data_size normal
onmne-db-02;onmne-db-02:if_docker0.down.graph no
onmne-db-02;onmne-db-02:if_docker0.down.update_rate 300
onmne-db-02;onmne-db-02:if_err_vethf5e6391.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-02;onmne-db-02:if_err_vethf5e6391.graph_title vethf5e6391 errors
onmne-db-02;onmne-db-02:if_err_vethf5e6391.graph_args --base 1000
onmne-db-02;onmne-db-02:if_err_vethf5e6391.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_err_vethf5e6391.graph_category network
onmne-db-02;onmne-db-02:if_err_vethf5e6391.graph_info This graph shows the amount of errors, packet drops, and collisions on the vethf5e6391 network interface.
onmne-db-02;onmne-db-02:if_err_vethf5e6391.collisions.update_rate 300
onmne-db-02;onmne-db-02:if_err_vethf5e6391.collisions.type COUNTER
onmne-db-02;onmne-db-02:if_err_vethf5e6391.collisions.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_vethf5e6391.collisions.label collisions
onmne-db-02;onmne-db-02:if_err_vethf5e6391.rxdrop.graph no
onmne-db-02;onmne-db-02:if_err_vethf5e6391.rxdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_vethf5e6391.rxdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_vethf5e6391.rxdrop.label drops
onmne-db-02;onmne-db-02:if_err_vethf5e6391.rxdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_vethf5e6391.trans.type COUNTER
onmne-db-02;onmne-db-02:if_err_vethf5e6391.trans.negative rcvd
onmne-db-02;onmne-db-02:if_err_vethf5e6391.trans.label errors
onmne-db-02;onmne-db-02:if_err_vethf5e6391.trans.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_vethf5e6391.trans.warning 1
onmne-db-02;onmne-db-02:if_err_vethf5e6391.trans.update_rate 300
onmne-db-02;onmne-db-02:if_err_vethf5e6391.rcvd.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_vethf5e6391.rcvd.label errors
onmne-db-02;onmne-db-02:if_err_vethf5e6391.rcvd.type COUNTER
onmne-db-02;onmne-db-02:if_err_vethf5e6391.rcvd.graph no
onmne-db-02;onmne-db-02:if_err_vethf5e6391.rcvd.warning 1
onmne-db-02;onmne-db-02:if_err_vethf5e6391.rcvd.update_rate 300
onmne-db-02;onmne-db-02:if_err_vethf5e6391.txdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_vethf5e6391.txdrop.label drops
onmne-db-02;onmne-db-02:if_err_vethf5e6391.txdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_vethf5e6391.txdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_vethf5e6391.txdrop.negative rxdrop
onmne-db-02;onmne-db-02:proc_pri.graph_title Processes priority
onmne-db-02;onmne-db-02:proc_pri.graph_order low high locked high low locked
onmne-db-02;onmne-db-02:proc_pri.graph_category processes
onmne-db-02;onmne-db-02:proc_pri.graph_info This graph shows number of processes at each priority
onmne-db-02;onmne-db-02:proc_pri.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:proc_pri.graph_vlabel Number of processes
onmne-db-02;onmne-db-02:proc_pri.locked.label locked in memory
onmne-db-02;onmne-db-02:proc_pri.locked.info The number of processes that have pages locked into memory (for real-time and custom IO)
onmne-db-02;onmne-db-02:proc_pri.locked.graph_data_size normal
onmne-db-02;onmne-db-02:proc_pri.locked.draw STACK
onmne-db-02;onmne-db-02:proc_pri.locked.update_rate 300
onmne-db-02;onmne-db-02:proc_pri.low.update_rate 300
onmne-db-02;onmne-db-02:proc_pri.low.draw AREA
onmne-db-02;onmne-db-02:proc_pri.low.label low priority
onmne-db-02;onmne-db-02:proc_pri.low.info The number of low-priority processes (tasks)
onmne-db-02;onmne-db-02:proc_pri.low.graph_data_size normal
onmne-db-02;onmne-db-02:proc_pri.high.info The number of high-priority processes (tasks)
onmne-db-02;onmne-db-02:proc_pri.high.label high priority
onmne-db-02;onmne-db-02:proc_pri.high.graph_data_size normal
onmne-db-02;onmne-db-02:proc_pri.high.update_rate 300
onmne-db-02;onmne-db-02:proc_pri.high.draw STACK
onmne-db-02;onmne-db-02:munin_stats.graph_title Munin processing time
onmne-db-02;onmne-db-02:munin_stats.graph_info This graph shows the run time of the four different processes making up a munin-master run.  Munin-master is run from cron every 5 minutes and we want each of the programmes in munin-master to complete before the next instance starts.  Especially munin-update and munin-graph are time consuming and their run time bears watching. If munin-update uses too long time to run please see the munin-update graph to determine which host is slowing it down.  If munin-graph is running too slow you need to get clever (email the munin-users mailing list) unless you can buy a faster computer with better disks to run munin on.
onmne-db-02;onmne-db-02:munin_stats.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:munin_stats.graph_scale yes
onmne-db-02;onmne-db-02:munin_stats.graph_vlabel seconds
onmne-db-02;onmne-db-02:munin_stats.graph_category munin
onmne-db-02;onmne-db-02:munin_stats.graph_order update graph html limits
onmne-db-02;onmne-db-02:munin_stats.html.update_rate 300
onmne-db-02;onmne-db-02:munin_stats.html.draw AREASTACK
onmne-db-02;onmne-db-02:munin_stats.html.label munin html
onmne-db-02;onmne-db-02:munin_stats.html.graph_data_size normal
onmne-db-02;onmne-db-02:munin_stats.limits.label munin limits
onmne-db-02;onmne-db-02:munin_stats.limits.graph_data_size normal
onmne-db-02;onmne-db-02:munin_stats.limits.update_rate 300
onmne-db-02;onmne-db-02:munin_stats.limits.draw AREASTACK
onmne-db-02;onmne-db-02:munin_stats.update.graph_data_size normal
onmne-db-02;onmne-db-02:munin_stats.update.label munin update
onmne-db-02;onmne-db-02:munin_stats.update.critical 285
onmne-db-02;onmne-db-02:munin_stats.update.draw AREASTACK
onmne-db-02;onmne-db-02:munin_stats.update.warning 240
onmne-db-02;onmne-db-02:munin_stats.update.update_rate 300
onmne-db-02;onmne-db-02:munin_stats.graph.graph_data_size normal
onmne-db-02;onmne-db-02:munin_stats.graph.label munin graph
onmne-db-02;onmne-db-02:munin_stats.graph.critical 285
onmne-db-02;onmne-db-02:munin_stats.graph.draw AREASTACK
onmne-db-02;onmne-db-02:munin_stats.graph.update_rate 300
onmne-db-02;onmne-db-02:munin_stats.graph.warning 240
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.graph_order rcvd trans rcvd trans rxdrop txdrop collisions
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.graph_title br-b9e24676d4d2 errors
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.graph_args --base 1000
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.graph_vlabel packets in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.graph_category network
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.graph_info This graph shows the amount of errors, packet drops, and collisions on the br-b9e24676d4d2 network interface.
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.rcvd.graph no
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.rcvd.warning 1
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.rcvd.update_rate 300
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.rcvd.type COUNTER
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.rcvd.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.rcvd.label errors
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.txdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.txdrop.label drops
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.txdrop.negative rxdrop
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.txdrop.type COUNTER
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.txdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.collisions.type COUNTER
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.collisions.update_rate 300
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.collisions.label collisions
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.collisions.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.trans.type COUNTER
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.trans.negative rcvd
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.trans.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.trans.label errors
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.trans.warning 1
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.trans.update_rate 300
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.rxdrop.update_rate 300
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.rxdrop.graph no
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.rxdrop.graph_data_size normal
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.rxdrop.label drops
onmne-db-02;onmne-db-02:if_err_br_b9e24676d4d2.rxdrop.type COUNTER
onmne-db-02;onmne-db-02:uptime.graph_title Uptime
onmne-db-02;onmne-db-02:uptime.graph_args --base 1000 -l 0
onmne-db-02;onmne-db-02:uptime.graph_scale no
onmne-db-02;onmne-db-02:uptime.graph_vlabel uptime in days
onmne-db-02;onmne-db-02:uptime.graph_category system
onmne-db-02;onmne-db-02:uptime.graph_order uptime
onmne-db-02;onmne-db-02:uptime.uptime.label uptime
onmne-db-02;onmne-db-02:uptime.uptime.graph_data_size normal
onmne-db-02;onmne-db-02:uptime.uptime.draw AREA
onmne-db-02;onmne-db-02:uptime.uptime.update_rate 300
onmne-db-02;onmne-db-02:if_vethe422dce.graph_order down up down up
onmne-db-02;onmne-db-02:if_vethe422dce.graph_title vethe422dce traffic
onmne-db-02;onmne-db-02:if_vethe422dce.graph_args --base 1000
onmne-db-02;onmne-db-02:if_vethe422dce.graph_vlabel bits in (-) / out (+) per ${graph_period}
onmne-db-02;onmne-db-02:if_vethe422dce.graph_category network
onmne-db-02;onmne-db-02:if_vethe422dce.graph_info This graph shows the traffic of the vethe422dce network interface. Please note that the traffic is shown in bits per second, not bytes. IMPORTANT: On 32-bit systems the data source for this plugin uses 32-bit counters, which makes the plugin unreliable and unsuitable for most 100-Mb/s (or faster) interfaces, where traffic is expected to exceed 50 Mb/s over a 5 minute period.  This means that this plugin is unsuitable for most 32-bit production environments. To avoid this problem, use the ip_ plugin instead.  There should be no problems on 64-bit systems running 64-bit kernels.
onmne-db-02;onmne-db-02:if_vethe422dce.down.min 0
onmne-db-02;onmne-db-02:if_vethe422dce.down.type DERIVE
onmne-db-02;onmne-db-02:if_vethe422dce.down.label received
onmne-db-02;onmne-db-02:if_vethe422dce.down.cdef down,8,*
onmne-db-02;onmne-db-02:if_vethe422dce.down.graph_data_size normal
onmne-db-02;onmne-db-02:if_vethe422dce.down.update_rate 300
onmne-db-02;onmne-db-02:if_vethe422dce.down.graph no
onmne-db-02;onmne-db-02:if_vethe422dce.up.negative down
onmne-db-02;onmne-db-02:if_vethe422dce.up.type DERIVE
onmne-db-02;onmne-db-02:if_vethe422dce.up.min 0
onmne-db-02;onmne-db-02:if_vethe422dce.up.info Traffic of the vethe422dce interface. Unable to determine interface speed. Please install ethtool, wireless-tools, mii-tool or whatever is appropriate for the interface.
onmne-db-02;onmne-db-02:if_vethe422dce.up.label bps
onmne-db-02;onmne-db-02:if_vethe422dce.up.graph_data_size normal
onmne-db-02;onmne-db-02:if_vethe422dce.up.cdef up,8,*
onmne-db-02;onmne-db-02:if_vethe422dce.up.update_rate 300
